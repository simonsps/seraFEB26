/*** SERA Universal Analytics Executor v3.1 (Time Intelligence + Determinism Patch)
 *
 * v3.1 changes (over v3.0):
 * - TIMESERIES: Added 7 period-aware functions — periodSortKey, chronoSort, periodMovements,
 *   periodMovingAvg, periodCompare, rollingAgg, periodSummary. These auto-sort by any period
 *   format (month names, quarters, YYYY-MM, ISO dates, week numbers) and return clean output.
 * - TIMESERIES: Fixed compression to preserve temporal completeness — reduces entities while
 *   keeping all periods intact, instead of truncating recent periods.
 * - DATES: Enhanced parseDate to handle month names ("January"), quarters ("Q1"), YYYY-MM formats.
 * - SORTING: sortBy, orderBy now have stable tie-breaking via original index (affects topNBy,
 *   bottomNBy, rankBy). mode() uses lowest-value tie-break. rankMarkovRows is deterministic.
 * - PERIOD ORDERING: Fixed 5 functions that used 3-letter-only month maps — postProcessEntityTrend,
 *   keepMostRecentByPeriod, repairFirstActiveMonthGrowthAnomalyTables, ensureEntityDropRiskFromTrendsDeep.
 *   All now handle full month names, quarters, YYYY-MM, ISO dates.
 * - POST-PROCESSING: Replaced 20+ inner-pipeline catch(_){} with _innerSafeStep() for traceability.
 *   Gated correlation/risk injectors to only fire when IIFE expressed intent.
 * - postProcessEntityTrend: Now detects entity/period/value fields universally instead of requiring
 *   hardcoded "id", "period", "value" column names.
 * - pctChangeSorted: Returns clean objects instead of mutating input rows with __pctChange properties.
 * - scoreObj: Replaced JSON.stringify fallback with numeric sum (prevents OOM on large objects).
 *
 * v3.0 changes (over v2.4):
 * - COMPRESSION: Smart dimension slice handling — pre-checks cardinality before sorting to prevent
 *   O(n log n) on 60,000+ slices. Uses partial selection for massive slice sets.
 * - COMPRESSION: Rebalanced caps — time series gets more room (80), verbose combinatorial
 *   sections (patterns, motifs, association rules) get tighter caps.
 * - COMPRESSION: Lightweight size estimation replaces JSON.stringify (prevents OOM on large results).
 * - RANKING: All sort comparators now have deterministic tie-breaking via localeCompare.
 * - RANKING: rankDimSlices uses primary numeric value instead of summing mixed-unit fields.
 * - TRUNCATION: Metadata keys are now non-enumerable (__sera_truncated) to prevent data pollution.
 * - REPAIR FUNCTIONS: Gated — repairWideTimeSeriesOutputs only fires when IIFE output has
 *   entity_period_trend with all-null values (i.e., the IIFE tried but failed). No longer
 *   injects phantom time series analysis for queries that didn't request it.
 * - ERROR HANDLING: Silent catch(_){} replaced with _safeStep() that logs warnings to
 *   diagnostics.notes so failures are traceable.
 * - CO-OCCURRENCE: Added circuit breaker for nWiseCooccurrence to prevent combinatorial explosion.
 */

// ============================================================================
// MODULE 1: LFS RESOLUTION
// ============================================================================

const LFS = (() => {
  async function httpGet(url) {
    const res = await fetch(url);
    if (!res.ok) throw new Error(`Fetch failed ${res.status}`);
    return await res.text();
  }

  async function resolvePointerOrText(v) {
    if (typeof v === "string" && !v.includes("@@remote_variable@@")) return v;

    if (typeof v === "object" && v !== null) {
      if (v.rawValue != null) return String(v.rawValue);
      if (typeof v.data === "string") return v.data;
      if (typeof v.content === "string") return v.content;
      return JSON.stringify(v);
    }

    if (typeof v === "string" && v.includes("@@remote_variable@@")) {
      const url = v.replace("@@remote_variable@@", "");
      const body = await httpGet(url);
      try {
        const parsed = JSON.parse(body);
        if (parsed && typeof parsed === "object") {
          if (parsed.rawValue != null) return String(parsed.rawValue);
          if (typeof parsed.data === "string") return parsed.data;
          if (typeof parsed.content === "string") return parsed.content;
        }
      } catch {
        // body is plain text; fall through
      }
      return body;
    }

    return String(v ?? "");
  }

  async function resolveVar(nameOrValue, vars) {
    if (
      typeof nameOrValue === "string" &&
      vars &&
      Object.prototype.hasOwnProperty.call(vars, nameOrValue)
    ) {
      return resolvePointerOrText(vars[nameOrValue]);
    }
    return resolvePointerOrText(nameOrValue);
  }

  return { httpGet, resolvePointerOrText, resolveVar };
})();

// ============================================================================
// MODULE 2: STANDARD LIBRARY (_)
// ============================================================================

const StandardLibrary = (() => {
  const identity = (x) => x;
  const clamp01 = (v) => {
    const n = Number(v);
    return n < 0 ? 0 : n > 1 ? 1 : n;
  };

  // ============================================================================
  // INTERNAL HELPER: Deep Get
  // ============================================================================
    // --- ROBUST DEEP GET (Case-Insensitive + Canonical Fallback) ---
  // Fixes "Severity" vs "severity" vs "Severity Level" vs "severity_level" mismatches.
  const _get = (obj, path, def) => {
    if (obj == null) return def;
    if (path == null || path === "") return obj;

    // 1) Direct access (fast path)
    if (obj[path] !== undefined) return obj[path];

    // 2) Path traversal
    const parts = Array.isArray(path)
      ? path
      : String(path)
          .replace(/\[(\d+)\]/g, ".$1")
          .split(".")
          .filter(Boolean);

    const canon = (s) => String(s).toLowerCase().trim().replace(/[\W_]+/g, "");

    let cur = obj;
    for (const pRaw of parts) {
      if (cur == null || typeof cur !== "object") return def;

      const p = String(pRaw);

      // 2a) Exact key
      if (Object.prototype.hasOwnProperty.call(cur, p)) {
        cur = cur[p];
        continue;
      }

      // 2b) Canonical / case-insensitive key
      const target = canon(p);
      if (!target) return def;

      let foundKey = null;
      for (const k of Object.keys(cur)) {
        if (canon(k) === target) {
          foundKey = k;
          break;
        }
      }

      if (foundKey == null) return def;
      cur = cur[foundKey];
    }

    return cur === undefined ? def : cur;
  };

  /**
   * FIXED SAFE KEY FN (UNIVERSAL PATCH)
   * Handles: _.safeKeyFn(row, "field") AND _.safeKeyFn("field")
   */
  const safeKeyFn = (arg1, arg2) => {
    // MODE A: Direct Access (Fixes "Counts are 0" bug)
    if (arg2 !== undefined && arg1 && typeof arg1 === "object") {
        return _get(arg1, arg2);
    }

    // MODE B: Accessor Generator
    const fn = arg1;

    if (typeof fn === "function") {
      return (row, ...args) => {
        if (row == null) return undefined;
        try {
          return fn(row, ...args);
        } catch (e) {
          return undefined;
        }
      };
    }

    if (typeof fn === "string" || Array.isArray(fn)) {
      return (row) => _get(row, fn);
    }

    return (x) => x;
  };

  // [DELETED ERROR BLOCK HERE: "Object.assign(stats...)"]
  // The crash was caused because 'stats' was accessed here before it was created below.

  /**
   * REPLACEMENT: augmentObject (v3.1 - The Forever Fix)
   * 
   * This version introduces a "Safety Proxy". 
   * If generated code tries to access a missing key (e.g., groupedData['NonExistentCategory']),
   * instead of returning 'undefined' (which crashes on .map), it returns an empty augmented array [].
   * 
   * This silences "Cannot read properties of undefined" errors globally.
   */
  const augmentObject = (obj) => {
    // 1. Safety Checks: Return primitives/nulls as-is
    if (!obj || typeof obj !== "object" || obj instanceof Date) return obj;

    // 2. If it's already an array, just ensure it has our helpers attached (if needed) and return
    // Note: We skip Proxying arrays to keep iteration fast.
    if (Array.isArray(obj)) return obj;

    // 3. Define Helper Methods (map, filter, etc.) on the Object itself
    const def = (key, val) => {
      if (!Object.prototype.hasOwnProperty.call(obj, key)) {
        Object.defineProperty(obj, key, { enumerable: false, configurable: true, value: val });
      }
    };

// --- Array-Like Methods for Objects ---
// IMPORTANT: these support BOTH callback styles:
//   (v, k, i) => ...
//   ([k, v], i, obj) => ...
def("map", function (cb) {
  const entries = Object.entries(this || {});
  const out = [];
  for (let i = 0; i < entries.length; i++) {
    const pair = entries[i];
    if (!pair) continue;              // âœ… critical guard
    const k = pair[0];
    const v = pair[1];

    if (typeof cb !== "function") { out.push(v); continue; }
    try {
      out.push(cb(v, k, i));
    } catch (_) {
      out.push(cb([k, v], i, this));
    }
  }
  return out;
});

def("filter", function (cb) {
  const entries = Object.entries(this || {});
  const result = [];
  for (let i = 0; i < entries.length; i++) {
    const pair = entries[i];
    if (!pair) continue;              // âœ… critical guard
    const k = pair[0];
    const v = pair[1];

    if (typeof cb !== "function") continue;
    let keep = false;
    try {
      keep = !!cb(v, k, i);
    } catch (_) {
      keep = !!cb([k, v], i, this);
    }
    if (keep) result.push(v);
  }
  return result;
});

def("forEach", function (cb) {
  const entries = Object.entries(this || {});
  for (let i = 0; i < entries.length; i++) {
    const pair = entries[i];
    if (!pair) continue;              // âœ… critical guard
    const k = pair[0];
    const v = pair[1];

    if (typeof cb !== "function") continue;
    try {
      cb(v, k, i);
    } catch (_) {
      cb([k, v], i, this);
    }
  }
});

def("reduce", function (cb, initial) {
  const entries = Object.entries(this || {});
  const hasInit = (arguments.length >= 2);

  // âœ… If cb missing, do not crash
  if (typeof cb !== "function") {
    if (hasInit) return initial;
    // find first defined pair safely
    for (let j = 0; j < entries.length; j++) {
      const p = entries[j];
      if (p) return p[1];
    }
    return undefined;
  }

  // find first defined pair safely
  let first = -1;
  for (let j = 0; j < entries.length; j++) {
    if (entries[j]) { first = j; break; }
  }
  if (first === -1) return hasInit ? initial : undefined;

  let acc = hasInit ? initial : entries[first][1];
  let start = hasInit ? first : (first + 1);

  for (let i = start; i < entries.length; i++) {
    const pair = entries[i];
    if (!pair) continue;              // âœ… critical guard
    const k = pair[0];
    const v = pair[1];

    try {
      acc = cb(acc, v, k, i);
    } catch (_) {
      acc = cb(acc, [k, v], i, this);
    }
  }
  return acc;
});




    def("find", function (cb) {
      return Object.values(this).find((v, i) => cb(v, i, this));
    });
    def("slice", function (start, end) {
      return Object.values(this).slice(start, end);
    });
    def("sort", function (cb) {
        return Object.values(this).sort(cb);
    });

    // --- RESILIENCE FAMILY ---
    def("includes", function (val, fromIndex) {
      return Object.values(this).includes(val, fromIndex);
    });
    def("some", function (cb) {
      return Object.values(this).some((v, i) => cb(v, i, this));
    });
    def("every", function (cb) {
      return Object.values(this).every((v, i) => cb(v, i, this));
    });
    def("indexOf", function (val, fromIndex) {
      return Object.values(this).indexOf(val, fromIndex);
    });
    def("lastIndexOf", function (val, fromIndex) {
      return Object.values(this).lastIndexOf(val, fromIndex);
    });
    def("findIndex", function (cb) {
        return Object.values(this).findIndex((v,i) => cb(v,i,this));
    });
    def("findLast", function (cb) {
        const vals = Object.values(this);
        for(let i=vals.length-1; i>=0; i--) {
            if(cb(vals[i], i, this)) return vals[i];
        }
        return undefined;
    });
    def("at", function(n) {
        const vals = Object.values(this);
        return n < 0 ? vals[vals.length + n] : vals[n];
    });
    def("concat", function (...args) {
      return Object.values(this).concat(...args);
    });
    def("join", function (separator) {
      return Object.values(this).join(separator);
    });
    def("flat", function (depth) {
      return Object.values(this).flat(depth);
    });
    def("flatMap", function (cb) {
      return Object.values(this).flatMap((v, i) => cb(v, i, this));
    });

    // Length property
    if (!Object.prototype.hasOwnProperty.call(obj, "length")) {
      Object.defineProperty(obj, "length", {
        enumerable: false, configurable: true,
        get: function () { return Object.keys(this).length; }
      });
    }

    // 4. THE PROXY SHIELD (The Actual Fix)
    // This intercepts access to missing properties.
    return new Proxy(obj, {
      get: (target, prop, receiver) => {
        // A. If key exists, return it (Reflect ensures correct 'this' binding)
        if (prop in target) return Reflect.get(target, prop, receiver);

        // B. Safety: Allow standard JS checks to see 'undefined' for these specific keys
        // This prevents infinite recursion in libraries that check for 'then' (Promises) or 'toJSON'.
        if (prop === 'then' || prop === 'toJSON' || prop === 'constructor' || typeof prop === 'symbol') {
            return undefined;
        }

        // C. MAGIC: Accessing a missing key returns an EMPTY AUGMENTED ARRAY instead of undefined.
        // This allows `data['BadKey'].map(...)` to run (doing nothing) instead of crashing.
        // We purposefully treat the empty result as a new augmentObject so chaining continues.
        const emptySafe = [];
        return augmentObject(emptySafe);
      }
    });
  };

// ==========================================================================
// 1. REPLACEMENT: STATS MODULE (FULL PRESERVATION + "SILENT NULL" FIX)
// ==========================================================================
// Drop-in replacement for your existing stats block.
// Fix: empty/null/"NA"/"-" placeholders no longer inflate __numericRowsDropped.
// Everything else kept intact (same methods + behavior, only safer parsing/skipping).
const stats = function (arr) {
  if (!Array.isArray(arr)) return augmentObject({});
  const nums = stats.compactNumbers(arr);
  return augmentObject({
    count: arr.length,
    n: nums.length,
    sum: stats.sum(nums),
    min: stats.min(nums),
    max: stats.max(nums),
    mean: stats.mean(nums),
    median: stats.median(nums),
    mode: stats.mode(nums),
    stddev: stats.stddev(nums),
    variance: stats.variance(nums)
  });
};

Object.assign(stats, {
  // --- ROBUST NUMBER PARSING (Preserved + slightly hardened) ---
  // Handles: "$1,000.50", "10%", "(1,234)", "1 - High", "42", true (1), "-" (NaN)
  toNumber: (v) => {
    // Dates: keep as timestamp
    if (v instanceof Date) return v.getTime();

    // Fast primitives
    if (typeof v === "number") return Number.isFinite(v) ? v : NaN;
    if (typeof v === "bigint") return Number(v);
    if (typeof v === "boolean") return v ? 1 : 0;
    if (v == null) return NaN;

    // Objects: try valueOf() once
    if (typeof v === "object") {
      try {
        const prim = v.valueOf();
        if (prim !== v) return stats.toNumber(prim);
      } catch {}
      return NaN;
    }

    const s = String(v).trim();
    if (!s) return NaN;

    // Common null-ish tokens (Silent fail)
    const lower = s.toLowerCase();
    if (
      lower === "na" ||
      lower === "n/a" ||
      lower === "null" ||
      lower === "undefined" ||
      lower === "nan" ||
      lower === "-"
    ) return NaN;

    // Date-like strings? Prefer timestamp over "2023" year extraction if ambiguous
    // e.g. "2023-01-01" -> Timestamp, but "2023" -> 2023
    const maybeMs = Date.parse(s);
    if (Number.isFinite(maybeMs) && (/[a-z]/i.test(s) || /[T:\-\/]/.test(s))) {
      return maybeMs;
    }

    // Accounting negative: "(123.45)" -> -123.45
    const isParensNeg = /^\(.*\)$/.test(s) && /\d/.test(s);
    const raw = isParensNeg ? s.slice(1, -1) : s;

    // Normalize common separators (also remove underscores)
    const normalized = raw.replace(/,/g, "").replace(/_/g, "").replace(/\s+/g, " ");

    // Extract first numeric token (keeps leading sign/decimals/exponent)
    const match = normalized.match(/[-+]?\d*\.?\d+(?:[eE][-+]?\d+)?/);
    if (!match) return NaN;

    let n = Number(match[0]);
    if (!Number.isFinite(n)) return NaN;

    if (isParensNeg) n = -n;

    // Percent handling: "10%" -> 0.10
    if (/%/.test(s)) n = n / 100;

    return n;
  },

  isFinite: (v) => Number.isFinite(stats.toNumber(v)),

// --- SILENT NULL FIX LIVES HERE ---
compactNumbers: (arr) =>
  Array.isArray(arr)
    ? arr.flatMap((v) => {
        if (v == null) return [];
        if (typeof v === "string") {
          const t = v.trim();
          if (!t) return [];
          const lower = t.toLowerCase();
          const placeholders = ["na", "n/a", "null", "undefined", "nan", "-"];
          if (placeholders.includes(lower)) return [];
        }

        const n = stats.toNumber(v);
        
        // This is the "Silent Fix"
        // If the number isn't valid, we just skip it without incrementing any counters
        if (!Number.isFinite(n)) {
          return [];
        }
        
        return [n];
      })
    : [],

  // FIX (kept): count behaves like SQL COUNT (also ignores empty string)
  count: (arr) => (Array.isArray(arr) ? arr.filter(v => v != null && v !== "").length : 0),
  size: (arr) => (Array.isArray(arr) ? arr.length : 0),
  len: (arr) => (Array.isArray(arr) ? arr.length : 0),

  // --- AGGREGATES ---
  sum: (arr) => stats.compactNumbers(arr).reduce((a, b) => a + b, 0),
  sumSq: (arr) => stats.compactNumbers(arr).reduce((a, b) => a + (b * b), 0),
  product: (arr) => stats.compactNumbers(arr).reduce((a, b) => a * b, 1),
  avg: (arr) => {
    const nums = stats.compactNumbers(arr);
    return nums.length ? stats.sum(nums) / nums.length : 0;
  },

  // --- SAFE AGGREGATES (Do not fabricate 0 when empty) ---
  safeAvg: (arr) => {
    const nums = stats.compactNumbers(arr);
    return nums.length ? stats.sum(nums) / nums.length : null;
  },
  safeMean: (arr) => stats.safeAvg(arr),
  safeMedian: (arr) => {
    const nums = stats.compactNumbers(arr).sort((a,b)=>a-b);
    if (!nums.length) return null;
    const mid = Math.floor(nums.length/2);
    return nums.length % 2 === 0 ? (nums[mid-1] + nums[mid])/2 : nums[mid];
  },

  mean: (arr) => stats.avg(arr),
  average: (arr) => stats.avg(arr),

  min: (arr) => {
    if (!Array.isArray(arr) || !arr.length) return 0;
    const nums = stats.compactNumbers(arr);
    if (!nums.length) return 0;
    const val = Math.min(...nums);
    return arr.some((x) => x instanceof Date) ? new Date(val) : val;
  },

  max: (arr) => {
    if (!Array.isArray(arr) || !arr.length) return 0;
    const nums = stats.compactNumbers(arr);
    if (!nums.length) return 0;
    const val = Math.max(...nums);
    return arr.some((x) => x instanceof Date) ? new Date(val) : val;
  },

  range: (arr) => stats.max(arr) - stats.min(arr),

  clamp: (v, min, max) => {
    const n = stats.toNumber(v);
    if (!Number.isFinite(n)) return n;
    const mn = min instanceof Date ? min.getTime() : Number(min);
    const mx = max instanceof Date ? max.getTime() : Number(max);
    if (Number.isFinite(mn) && n < mn) return mn;
    if (Number.isFinite(mx) && n > mx) return mx;
    return n;
  },

  safeDiv: (n, d) => {
    const nn = stats.toNumber(n);
    const dd = stats.toNumber(d);
    if (!Number.isFinite(nn) || !Number.isFinite(dd) || dd === 0) return null;
    return nn / dd;
  },

  round: (v, p = 2) => {
    const n = Number(v);
    if (!Number.isFinite(n)) return 0;
    const factor = 10 ** p;
    return Math.round(n * factor) / factor;
  },
  _round: (v, p = 2) => stats.round(v, p),
  floor: (v) => (Number.isFinite(Number(v)) ? Math.floor(Number(v)) : 0),
  ceil: (v) => (Number.isFinite(Number(v)) ? Math.ceil(Number(v)) : 0),

  // --- VARIANCE & DISTRIBUTION ---
  variance: (arr) => {
    const nums = stats.compactNumbers(arr);
    if (nums.length < 2) return 0;
    const mean = stats.avg(nums);
    return stats.avg(nums.map((x) => (x - mean) ** 2));
  },
  stddev: (arr) => Math.sqrt(stats.variance(arr)),
  stdDev: (arr) => stats.stddev(arr),

  zScores: (arr) => {
  const original = Array.isArray(arr) ? arr : [];
  const pairs = [];

  for (let i = 0; i < original.length; i++) {
    const n = stats.toNumber(original[i]);
    if (Number.isFinite(n)) pairs.push({ index: i, value: n });
  }

  // Not enough data to compute meaningful z-scores
  if (pairs.length < 2) {
    const aligned = original.map((v) => {
      const n = stats.toNumber(v);
      return Number.isFinite(n) ? 0 : null;
    });
    Object.defineProperties(aligned, {
      mean: { value: pairs.length ? pairs[0].value : 0, enumerable: false },
      stddev: { value: 0, enumerable: false },
      n: { value: pairs.length, enumerable: false },
    });
    return aligned;
  }

  const values = pairs.map(p => p.value);
  const mean = stats.avg(values);
  const sd = stats.stddev(values) || 0;

  const aligned = original.map(() => null);
  for (const p of pairs) {
    aligned[p.index] = sd ? (p.value - mean) / sd : 0;
  }

  Object.defineProperties(aligned, {
    mean: { value: mean, enumerable: false },
    stddev: { value: sd, enumerable: false },
    n: { value: pairs.length, enumerable: false },
  });

  return aligned;
},


  percentile: (arr, p) => {
  let pp = stats.toNumber(p);
  if (!Number.isFinite(pp)) pp = 50;

  // FOREVER FIX: accept p as either 0..1 OR 0..100
  // If someone passes 0.9, they almost certainly mean 90th percentile.
  if (pp >= 0 && pp <= 1) pp = pp * 100;

  pp = Math.max(0, Math.min(100, pp));
  return stats.quantile(arr, pp / 100);
},


  quantile: (arr, q) => {
  const nums = stats.compactNumbers(arr);
  if (!nums.length) return null;

  let qq = stats.toNumber(q);
  if (!Number.isFinite(qq)) qq = 0.5;

  // FOREVER FIX: accept q as either 0..1 OR 0..100
  // - if qq is 90, treat as 0.90
  // - if qq is 0.9, keep as 0.9
  if (qq > 1 && qq <= 100) qq = qq / 100;

  qq = Math.max(0, Math.min(1, qq));

  nums.sort((a, b) => a - b);
  const pos = (nums.length - 1) * qq;
  const base = Math.floor(pos);
  const rest = pos - base;

  if (nums[base + 1] !== undefined) {
    return nums[base] + rest * (nums[base + 1] - nums[base]);
  }
  return nums[base];
},


  // --- ADVANCED (Preserved) ---
  geometricMean: (arr) => {
    const nums = stats.compactNumbers(arr).filter((n) => n > 0);
    if (!nums.length) return 0;
    const sumLog = nums.reduce((acc, v) => acc + Math.log(v), 0);
    return Math.exp(sumLog / nums.length);
  },

  harmonicMean: (arr) => {
    const nums = stats.compactNumbers(arr).filter((n) => n !== 0);
    if (!nums.length) return 0;
    const sumReciprocal = nums.reduce((acc, v) => acc + 1 / v, 0);
    return nums.length / sumReciprocal;
  },

  mad: (arr) => {
    const nums = stats.compactNumbers(arr);
    if (!nums.length) return 0;
    const med = stats.median(nums);
    const deviations = nums.map((x) => Math.abs(x - med));
    return stats.median(deviations);
  },

  median: (arr) => {
    const nums = stats.compactNumbers(arr);
    if (!nums.length) return 0;
    nums.sort((a, b) => a - b);
    const mid = Math.floor(nums.length / 2);
    const val = nums.length % 2 === 0 ? (nums[mid - 1] + nums[mid]) / 2 : nums[mid];
    return arr.some((x) => x instanceof Date) ? new Date(val) : val;
  },

  mode: (arr) => {
    const nums = stats.compactNumbers(arr);
    if (!nums.length) return null;
    const counts = {};
    for (const n of nums) counts[n] = (counts[n] || 0) + 1;
    // FIXED: deterministic tie-breaking — highest count wins, ties broken by lowest value
    const best = Object.entries(counts).sort((a, b) => (b[1] - a[1]) || (Number(a[0]) - Number(b[0])))[0][0];
    const val = Number(best);
    return arr.some((x) => x instanceof Date) ? new Date(val) : val;
  },

  normalizeZ: (arr) => {
    const nums = stats.compactNumbers(arr);
    const m = stats.avg(nums);
    const s = stats.stddev(nums);
    if (!s) return nums.map(() => 0);
    return nums.map((v) => (v - m) / s);
  },

  minMaxScale: (arr) => {
    const nums = stats.compactNumbers(arr);
    if (!nums.length) return [];
    const mn = Math.min(...nums);
    const mx = Math.max(...nums);
    if (mx === mn) return nums.map(() => 0.5);
    return nums.map((v) => (v - mn) / (mx - mn));
  },

  entropy: (arr) => {
    const nums = stats.compactNumbers(arr);
    if (!nums.length) return 0;
    const mn = Math.min(...nums);
    const mx = Math.max(...nums);
    if (mn === mx) return 0;
    const probs = nums.map((v) => (v - mn) / (mx - mn));
    let H = 0;
    for (const p of probs) {
      const pp = p < 0 ? 0 : p > 1 ? 1 : p;
      if (pp > 0) H -= pp * Math.log2(pp);
    }
    return H;
  },

  volatility: (arr) => stats.stddev(arr),

  stabilityIndex: (arr) => {
    const vol = stats.volatility(arr);
    const nums = stats.compactNumbers(arr);
    if (!nums.length) return 1;
    const mn = Math.min(...nums);
    const mx = Math.max(...nums);
    const range = mx - mn;
    return range ? 1 - vol / range : 1;
  },

  // --- OUTLIERS & BREAKPOINTS ---
  iqrOutliers: (arr, key) => {
    const fn = key ? safeKeyFn(key) : (x) => x;
    const raw = Array.isArray(arr) ? arr.map(fn) : [];
    const nums = stats.compactNumbers(raw).sort((a, b) => a - b);

    if (nums.length < 4)
      return augmentObject({
        low: [], high: [], count: 0, rate: 0, total: nums.length, lowCut: 0, highCut: 0
      });

    const q1 = stats.percentile(nums, 25);
    const q3 = stats.percentile(nums, 75);
    const iqr = q3 - q1;
    const lowCut = q1 - 1.5 * iqr;
    const highCut = q3 + 1.5 * iqr;
    const isDate = raw.some((x) => x instanceof Date);
    const mapFn = isDate ? (v) => new Date(v) : (v) => v;
    const low = nums.filter((n) => n < lowCut).map(mapFn);
    const high = nums.filter((n) => n > highCut).map(mapFn);
    const count = low.length + high.length;

    return augmentObject({
      low, high, count,
      rate: nums.length ? count / nums.length : 0,
      total: nums.length, lowCut, highCut, iqr
    });
  },

  zScoreOutliers: (arr, threshold = 3, key) => {
    let actualKey = key;
    let actualThreshold = threshold;
    if (typeof threshold === "string" || typeof threshold === "function") {
      actualKey = threshold;
      actualThreshold = 3;
    }

    const fn = actualKey ? safeKeyFn(actualKey) : (x) => x;
    const original = Array.isArray(arr) ? arr : [];
    const pairs = [];

    for (let i = 0; i < original.length; i++) {
      const item = original[i];
      const val = fn(item);
      const n = stats.toNumber(val);
      if (Number.isFinite(n)) pairs.push({ index: i, value: n, item });
    }

    if (pairs.length < 2) return [];

    const values = pairs.map((p) => p.value);
    const mean = stats.avg(values);
    const sd = stats.stddev(values) || 0;
    const zScoresAligned = original.map(() => null);
    const outliers = [];

    for (const p of pairs) {
      const z = sd ? (p.value - mean) / sd : 0;
      zScoresAligned[p.index] = z;
      if (Math.abs(z) >= actualThreshold) {
        outliers.push({ ...p.item, index: p.index, value: p.value, z });
      }
    }

    const result = outliers;
    Object.defineProperties(result, {
      threshold: { value: actualThreshold, enumerable: false },
      mean: { value: mean, enumerable: false },
      stddev: { value: sd, enumerable: false },
      zScores: { value: zScoresAligned, enumerable: false },
      outlierIndices: { value: outliers.map(o => o.index), enumerable: false },
      count: { value: outliers.length, enumerable: false },
      rate: { value: pairs.length ? outliers.length / pairs.length : 0, enumerable: false },
      n: { value: pairs.length, enumerable: false }
    });
    return result;
  },

  outlierCount:(arr, ...args) => {
    let key = null;
    let method = "iqr";
    let threshold = 3;
    if (args.length > 0) {
      const first = args[0];
      if (first === "iqr" || first === "zscore" || first === "z") {
        method = first;
        if (args[1]) threshold = args[1];
      } else {
        key = first;
        if (args[1]) method = args[1];
        if (args[2]) threshold = args[2];
      }
    }
    if (method === "zscore" || method === "z") {
      return stats.zScoreOutliers(arr, threshold, key).count;
    }
    return stats.iqrOutliers(arr, key).count;
  },

outlierRate: (arr, ...args) => {
    let key = null;
    let method = "iqr";
    let threshold = 3;
    if (args.length > 0) {
      const first = args[0];
      if (first === "iqr" || first === "zscore" || first === "z") {
        method = first;
        if (args[1]) threshold = args[1];
      } else {
        key = first;
        if (args[1]) method = args[1];
        if (args[2]) threshold = args[2];
      }
    }
    if (method === "zscore" || method === "z") {
      return stats.zScoreOutliers(arr, threshold, key).rate;
    }
    return stats.iqrOutliers(arr, key).rate;
  },

  spikeDetection: (arr, factor = 3) => {
    const original = Array.isArray(arr) ? arr : [];
    const nums = original.map((v) => stats.toNumber(v));
    const finite = nums.filter((n) => Number.isFinite(n));
    const s = stats.stddev(finite);
    const m = stats.avg(finite);
    const isDate = original.some((x) => x instanceof Date);
    return nums.map((v, i) => ({
      index: i,
      value: isDate && Number.isFinite(v) ? new Date(v) : v,
      spike: Number.isFinite(v) && s ? Math.abs(v - m) > factor * s : false
    }));
  },

  spikeIndices: (arr, factor = 3) => {
    const details = stats.spikeDetection(arr, factor) || [];
    if (!Array.isArray(details)) return [];
    return details.filter(d => d && d.spike).map(d => d.index);
  },

  breakpoints: (arr, k = 5) => {
    const nums = stats.compactNumbers(arr).sort((a, b) => a - b);
    if (!nums.length) return [];
    const kkRaw = stats.toNumber(k);
    const kk = Number.isFinite(kkRaw) ? Math.max(1, Math.floor(kkRaw)) : 5;
    const out = [];
    for (let i = 0; i <= kk; i++) {
      const p = (i / kk) * 100;
      out.push(stats.percentile(nums, p));
    }
    return out;
  },

  cagr: (endValue, beginValue, periods = 1) => {
    const ev = stats.toNumber(endValue);
    const bv = stats.toNumber(beginValue);
    const n = stats.toNumber(periods);
    if (!Number.isFinite(ev) || !Number.isFinite(bv) || !Number.isFinite(n) || n === 0 || bv === 0) return null;
    return (ev / bv) ** (1 / n) - 1;
  },

  gini: (arr) => {
    const nums = stats.compactNumbers(arr).filter((n) => n >= 0).sort((a, b) => a - b);
    const n = nums.length;
    if (n === 0) return null;
    const sum = nums.reduce((a, b) => a + b, 0);
    if (sum === 0) return 0;
    let cum = 0;
    for (let i = 0; i < n; i++) cum += (i + 1) * nums[i];
    return (2 * cum) / (n * sum) - (n + 1) / n;
  },

  skewness: (arr) => {
    const nums = stats.compactNumbers(arr);
    const n = nums.length;
    if (n < 3) return null;
    const m = stats.mean(nums);
    const s = stats.stddev(nums);
    if (!s) return 0;
    const m3 = nums.reduce((acc, x) => acc + ((x - m) / s) ** 3, 0) / n;
    return m3;
  },

  kurtosis: (arr) => {
    const nums = stats.compactNumbers(arr);
    const n = nums.length;
    if (n < 4) return null;
    const m = stats.mean(nums);
    const s = stats.stddev(nums);
    if (!s) return 0;
    const m4 = nums.reduce((acc, x) => acc + ((x - m) / s) ** 4, 0) / n;
    return m4 - 3;
  },

  sem: (arr) => {
    const nums = stats.compactNumbers(arr);
    const n = nums.length;
    if (!n) return null;
    return stats.stddev(nums) / Math.sqrt(n);
  },

  confidenceInterval: (arr, conf = 0.95) => {
    const nums = stats.compactNumbers(arr);
    const n = nums.length;
    if (!n) return null;
    const m = stats.mean(nums);
    const se = stats.sem(nums);
    if (se == null) return null;
    const c = stats.toNumber(conf);
    const z = c >= 0.999 ? 3.291 : c >= 0.995 ? 2.807 : c >= 0.99 ? 2.576 : c >= 0.95 ? 1.96 : c >= 0.90 ? 1.645 : 1.96;
    return [m - z * se, m + z * se];
  },

  trimmedMean: (arr, p = 0.1) => {
    const nums = stats.compactNumbers(arr).sort((a, b) => a - b);
    const n = nums.length;
    if (!n) return null;
    const ppRaw = stats.toNumber(p);
    const pp = Number.isFinite(ppRaw) ? Math.max(0, Math.min(0.49, ppRaw)) : 0.1;
    const cut = Math.floor(n * pp);
    const trimmed = nums.slice(cut, n - cut);
    return trimmed.length ? stats.mean(trimmed) : stats.mean(nums);
  },

  winsorizedMean: (arr, p = 0.1) => {
    const nums = stats.compactNumbers(arr).sort((a, b) => a - b);
    const n = nums.length;
    if (!n) return null;
    const ppRaw = stats.toNumber(p);
    const pp = Number.isFinite(ppRaw) ? Math.max(0, Math.min(0.49, ppRaw)) : 0.1;
    const cut = Math.floor(n * pp);
    const lo = nums[cut];
    const hi = nums[n - cut - 1];
    const win = nums.map((x) => (x < lo ? lo : x > hi ? hi : x));
    return stats.mean(win);
  },

  weightedMean: (arr, weights) => {
    const x = stats.compactNumbers(arr);
    const w = stats.compactNumbers(weights);
    const n = Math.min(x.length, w.length);
    if (!n) return null;
    let sw = 0; let sx = 0;
    for (let i = 0; i < n; i++) {
      const wi = w[i]; const xi = x[i];
      if (!Number.isFinite(wi) || !Number.isFinite(xi)) continue;
      sw += wi; sx += wi * xi;
    }
    if (sw === 0) return null;
    return sx / sw;
  },

  covariance: (a, b) => {
    const x = stats.compactNumbers(a);
    const y = stats.compactNumbers(b);
    const n = Math.min(x.length, y.length);
    if (n < 2) return null;
    const mx = stats.mean(x.slice(0, n));
    const my = stats.mean(y.slice(0, n));
    let sum = 0;
    for (let i = 0; i < n; i++) sum += (x[i] - mx) * (y[i] - my);
    return sum / (n - 1);
  },

  covarianceMatrix: (data, fields) => {
    if (!data) return {};
    const isRowArray = Array.isArray(data) && data.length && typeof data[0] === "object" && !Array.isArray(data[0]);
    let cols = [];
    if (isRowArray) {
      const f = fields && fields.length ? fields : Object.keys(data[0] || {});
      cols = f.map((k) => ({ key: k, values: (data || []).map((r) => stats.toNumber(r[k])) }));
    } else if (typeof data === "object") {
      const f = fields && fields.length ? fields : Object.keys(data);
      cols = f.map((k) => ({ key: k, values: Array.isArray(data[k]) ? data[k].map((v) => stats.toNumber(v)) : [] }));
    }
    const matrix = {};
    for (let i = 0; i < cols.length; i++) {
      const aKey = cols[i].key;
      matrix[aKey] = {};
      for (let j = 0; j < cols.length; j++) {
        const bKey = cols[j].key;
        matrix[aKey][bKey] = stats.covariance(cols[i].values, cols[j].values);
      }
    }
    return matrix;
  },

  rollingStd: (arr, window = 5) => {
    const nums = stats.compactNumbers(arr);
    const wRaw = stats.toNumber(window);
    const w = Number.isFinite(wRaw) ? Math.max(1, Math.floor(wRaw)) : 5;
    if (!nums.length) return [];
    const out = [];
    for (let i = 0; i < nums.length; i++) {
      const start = Math.max(0, i - w + 1);
      const slice = nums.slice(start, i + 1);
      out.push(stats.stddev(slice));
    }
    return out;
  },

  ecdf: (arr) => {
    const nums = stats.compactNumbers(arr).sort((a, b) => a - b);
    const n = nums.length;
    if (!n) return (v) => 0;
    return (v) => {
      const x = stats.toNumber(v);
      if (!Number.isFinite(x)) return 0;
      let lo = 0; let hi = n;
      while (lo < hi) {
        const mid = (lo + hi) >> 1;
        if (nums[mid] <= x) lo = mid + 1;
        else hi = mid;
      }
      return lo / n;
    };
  }
});

// ==========================================================================
// FOREVER FIX: Null-safe numeric returns (prevents ".toFixed" crashes)
// Why: Generated analytics sometimes does `value.toFixed(2)`.
// If `value` is null/undefined (common when data is sparse), JS crashes.
// Fix: Any scalar numeric helper that returns null/undefined will return NaN instead.
// NaN.toFixed(...) is safe (returns "NaN").
// ==========================================================================

;(function hardenNullNumericReturns() {

  const toNaN = (v) => (v == null ? NaN : v); // catches null OR undefined

  const wrap = (obj, keys) => {
    for (const k of keys) {
      if (!obj || typeof obj[k] !== "function") continue;
      const orig = obj[k];
      obj[k] = function (...args) {
        try {
          return toNaN(orig.apply(this, args));
        } catch (e) {
          // Never crash the run for a numeric edge-case
          return NaN;
        }
      };
    }
  };

  // Stats methods that are scalar-numeric but may return null on sparse/dirty data
  wrap(stats, [
    "avg", "safeAvg", "mean", "average",
    "median", "mode",
    "sem",
    "trimmedMean", "winsorizedMean", "weightedMean",
    "covariance",
    "gini", "skewness", "kurtosis",
    "cagr",
    "safeMedian",
    "safeDiv"
  ]);
})();


  // -------------------------------------------------------------------------
  // collections
  // -------------------------------------------------------------------------
  const collections = {
    map: (collection, iteratee) => {
      const fn = safeKeyFn(iteratee);
      if (Array.isArray(collection)) return collection.map((v, i) => fn(v, i, collection));
      if (collection && typeof collection === "object") {
        return Object.keys(collection).map((k) => fn(collection[k], k, collection));
      }
      return [];
    },

    filter: (collection, predicate) => {
      const fn = safeKeyFn(predicate);
      if (Array.isArray(collection)) return collection.filter((v, i) => fn(v, i, collection));
      if (collection && typeof collection === "object") {
        const result = [];
        for (const k in collection) {
          if (Object.prototype.hasOwnProperty.call(collection, k)) {
            if (fn(collection[k], k, collection)) result.push(collection[k]);
          }
        }
        return result;
      }
      return [];
    },

    // ============================================================================
// PART A: New Collection Methods (Insert inside 'const collections = { ... }')
// ============================================================================

    /**
     * FIX: orderBy
     * Sorts a collection by multiple fields and directions.
     * Usage: _.orderBy(data, ['category', 'value'], ['asc', 'desc'])
     */
    orderBy: (collection, iteratees, orders) => {
      if (!Array.isArray(collection)) return [];
      
      // Normalize inputs to arrays
      const fields = Array.isArray(iteratees) ? iteratees : [iteratees];
      const directions = Array.isArray(orders) ? orders : [orders];

      // SERA v3.0: Clone with index for deterministic tie-breaking
      const indexed = collection.map((item, idx) => ({ item, idx }));
      indexed.sort((aW, bW) => {
        const a = aW.item;
        const b = bW.item;
        for (let i = 0; i < fields.length; i++) {
          const field = fields[i];
          // Default to 'asc' if not specified
          const order = String(directions[i] || "asc").toLowerCase();
          const fn = safeKeyFn(field);

          const vA = fn(a);
          const vB = fn(b);

          // Compare values
          if (vA < vB) return order === "desc" ? 1 : -1;
          if (vA > vB) return order === "desc" ? -1 : 1;
        }
        return aW.idx - bW.idx; // stable tie-break: preserve original order
      });
      return indexed.map(x => x.item);
    },

    /**
     * BONUS: keyBy
     * Creates an object composed of keys generated from the results of running each element through iteratee.
     */
    keyBy: (collection, iteratee) => {
      const fn = safeKeyFn(iteratee);
      const result = {};
      if (Array.isArray(collection)) {
        collection.forEach((item) => {
          const key = fn(item);
          if (key != null) result[key] = item;
        });
      }
      return augmentObject(result);
    },

    /**
 * PART 1: Insert these methods inside the `collections` object (Module 2).
 * Place them after `orderBy` or `keyBy`.
 */
    countDistinct: (collection, iteratee) => {
      const arr = Array.isArray(collection) ? collection : (collection ? Object.values(collection) : []);
      const fn = iteratee !== undefined ? safeKeyFn(iteratee) : (x) => x;
      const set = new Set();
      
      for (const item of arr) {
        let val = fn(item);
        // FORCE SERIALIZATION: Handle Objects/Dates by value, not reference
        if (val != null && typeof val === "object") {
            if (val instanceof Date) val = val.getTime(); // Normalize Dates
            else val = JSON.stringify(val); // Normalize Objects
        }
        set.add(val);
      }
      return set.size;
    },

    flatMap: (collection, iteratee) => {
      const fn = safeKeyFn(iteratee);
      const arr = Array.isArray(collection) ? collection : (collection ? Object.values(collection) : []);
      return arr.flatMap((v, i) => fn(v, i, arr));
    },

    findIndex: (collection, predicate, fromIndex = 0) => {
      const fn = safeKeyFn(predicate);
      if (!Array.isArray(collection)) return -1;
      // Guard against negative fromIndex if needed, though native handle it differently
      const start = Math.max(0, fromIndex);
      for (let i = start; i < collection.length; i++) {
        if (fn(collection[i], i, collection)) return i;
      }
      return -1;
    },

    partition: (collection, predicate) => {
      const fn = safeKeyFn(predicate);
      const arr = Array.isArray(collection) ? collection : (collection ? Object.values(collection) : []);
      const pass = [];
      const fail = [];
      for (let i = 0; i < arr.length; i++) {
        const val = arr[i];
        if (fn(val, i, arr)) pass.push(val);
        else fail.push(val);
      }
      return [pass, fail];
    },

    shuffle: (collection) => {
      const arr = Array.isArray(collection) ? [...collection] : (collection ? Object.values(collection) : []);
      for (let i = arr.length - 1; i > 0; i--) {
        const j = Math.floor(Math.random() * (i + 1));
        [arr[i], arr[j]] = [arr[j], arr[i]];
      }
      return arr;
    },

    at: (collection, paths) => {
      const arr = Array.isArray(collection) ? collection : (collection ? Object.values(collection) : []);
      const indices = Array.isArray(paths) ? paths : [paths];
      return indices.map(i => arr[i]);
    },

    /**
     * BONUS: pick
     * Creates an object composed of the picked object properties.
     */
    pick: (object, paths) => {
      const result = {};
      if (object == null) return augmentObject(result);
      const props = Array.isArray(paths) ? paths : [paths];
      for (const prop of props) {
        if (Object.prototype.hasOwnProperty.call(object, prop)) {
          result[prop] = object[prop];
        }
      }
      return augmentObject(result);
    },

    /**
     * BONUS: omit
     * The opposite of pick; this method creates an object composed of the own and inherited enumerable property paths of object that are not omitted.
     */
    omit: (object, paths) => {
      if (object == null) return augmentObject({});
      const result = { ...object };
      const props = Array.isArray(paths) ? paths : [paths];
      for (const prop of props) {
        delete result[prop];
      }
      return augmentObject(result);
    },

    /**
     * BONUS: isEmpty
     * Checks if value is an empty object, collection, map, or set.
     */
    isEmpty: (value) => {
      if (value == null) return true;
      if (Array.isArray(value) || typeof value === "string") return value.length === 0;
      if (typeof value === "object") return Object.keys(value).length === 0;
      return true;
    },

    /**
     * BONUS: sample
     * Gets a random element from collection.
     */
    sample: (arr) => {
      if (!Array.isArray(arr) || !arr.length) return undefined;
      return arr[Math.floor(Math.random() * arr.length)];
    },

    /**
     * BONUS: first / head / last
     * Common array accessors.
     */
    first: (arr) => (Array.isArray(arr) && arr.length ? arr[0] : undefined),
    head: (arr) => (Array.isArray(arr) && arr.length ? arr[0] : undefined),
    last: (arr) => (Array.isArray(arr) && arr.length ? arr[arr.length - 1] : undefined),

    reduce: (collection, iteratee, accumulator) => {
      const fn = safeKeyFn(iteratee);
      if (Array.isArray(collection)) {
        if (accumulator === undefined && collection.length > 0) {
          return collection.reduce((acc, v, i) => fn(acc, v, i, collection));
        }
        return collection.reduce((acc, v, i) => fn(acc, v, i, collection), accumulator);
      }
      if (collection && typeof collection === "object") {
        const keys = Object.keys(collection);
        let acc = accumulator;
        let startIdx = 0;
        if (acc === undefined && keys.length > 0) {
          acc = collection[keys[0]];
          startIdx = 1;
        }
        for (let i = startIdx; i < keys.length; i++) {
          const k = keys[i];
          acc = fn(acc, collection[k], k, collection);
        }
        return acc;
      }
      return accumulator;
    },

// [Add inside 'collections' object in Module 2]
    take: (arr, n = 1) => {
      if (!Array.isArray(arr)) return [];
      return arr.slice(0, Math.max(0, n));
    },

    takeRight: (arr, n = 1) => {
      if (!Array.isArray(arr)) return [];
      const len = arr.length;
      return arr.slice(Math.max(0, len - n));
    },

    /**
 * STEP 1: Insert these methods inside the `collections` object in Module 2.
 * Place them after `orderBy`, `keyBy`, etc.
 */

    maxBy: (collection, iteratee) => {
      const fn = safeKeyFn(iteratee);
      const arr = Array.isArray(collection) ? collection : (collection ? Object.values(collection) : []);
      if (!arr.length) return undefined;
      let best = arr[0];
      let max = fn(best);
      for (let i = 1; i < arr.length; i++) {
        const val = arr[i];
        const cur = fn(val);
        if (cur != null && (max == null || cur > max)) {
          max = cur;
          best = val;
        }
      }
      return best;
    },

    minBy: (collection, iteratee) => {
      const fn = safeKeyFn(iteratee);
      const arr = Array.isArray(collection) ? collection : (collection ? Object.values(collection) : []);
      if (!arr.length) return undefined;
      let best = arr[0];
      let min = fn(best);
      for (let i = 1; i < arr.length; i++) {
        const val = arr[i];
        const cur = fn(val);
        if (cur != null && (min == null || cur < min)) {
          min = cur;
          best = val;
        }
      }
      return best;
    },

    reject: (collection, predicate) => {
      const fn = safeKeyFn(predicate);
      if (Array.isArray(collection)) return collection.filter((v, i) => !fn(v, i, collection));
      if (collection && typeof collection === "object") {
        const result = [];
        for (const k in collection) {
          if (Object.prototype.hasOwnProperty.call(collection, k)) {
            if (!fn(collection[k], k, collection)) result.push(collection[k]);
          }
        }
        return result;
      }
      return [];
    },

    findLast: (collection, predicate) => {
      const fn = safeKeyFn(predicate);
      const arr = Array.isArray(collection) ? collection : (collection ? Object.values(collection) : []);
      for (let i = arr.length - 1; i >= 0; i--) {
        if (fn(arr[i], i, arr)) return arr[i];
      }
      return undefined;
    },

    difference: (arr, values) => {
      if (!Array.isArray(arr)) return [];
      const s = new Set(values || []);
      return arr.filter(x => !s.has(x));
    },

    intersection: (arr, values) => {
       if (!Array.isArray(arr)) return [];
       const s = new Set(values || []);
       return arr.filter(x => s.has(x));
    },

/** 
 * 1. Add this method inside the `collections` object within `StandardLibrary` (Module 2).
 *    Place it alongside `map`, `filter`, `reduce`, etc.
 */
    mapValues: (collection, iteratee) => {
      const fn = safeKeyFn(iteratee);
      const result = {};
      if (collection && typeof collection === "object") {
        for (const key in collection) {
          if (Object.prototype.hasOwnProperty.call(collection, key)) {
            result[key] = fn(collection[key], key, collection);
          }
        }
      }
      return augmentObject(result);
    },

    each: (collection, iteratee) => {
      const fn = safeKeyFn(iteratee);
      if (Array.isArray(collection)) collection.forEach((v, i) => fn(v, i, collection));
      else if (collection && typeof collection === "object") {
        for (const k in collection) {
          if (Object.prototype.hasOwnProperty.call(collection, k)) fn(collection[k], k, collection);
        }
      }
      return collection;
    },

    find: (collection, predicate) => {
      const fn = safeKeyFn(predicate);
      if (Array.isArray(collection)) return collection.find((v, i) => fn(v, i, collection));
      if (collection && typeof collection === "object") {
        for (const k in collection) {
          if (Object.prototype.hasOwnProperty.call(collection, k)) {
            if (fn(collection[k], k, collection)) return collection[k];
          }
        }
      }
      return undefined;
    },

    size: (v) => {
      if (Array.isArray(v) || typeof v === "string") return v.length;
      if (v && typeof v === "object") return Object.keys(v).length;
      return 0;
    },

    count: (arr) => (Array.isArray(arr) ? arr.length : 0),

    unique: (arr, iteratee) => {
        if (!Array.isArray(arr)) return [];
        const fn = iteratee !== undefined ? safeKeyFn(iteratee) : (x) => x;
        const seen = new Set();
        return arr.filter(item => {
            let val = fn(item);
            if (val != null && typeof val === "object") {
                if (val instanceof Date) val = val.getTime();
                else val = JSON.stringify(val);
            }
            if (seen.has(val)) return false;
            seen.add(val);
            return true;
        });
    },
    uniq: (arr, iteratee) => collections.unique(arr, iteratee),


  // ... (existing methods like sumBy, mapNumbers) ...

    meanBy: (arr, fn) => {
      const keyFn = safeKeyFn(fn);
      if (!Array.isArray(arr) || !arr.length) return 0;
      return stats.mean(arr.map((x, i) => keyFn(x, i)));
    },


    safePct: (num, den) => {
      const v = stats.safeDiv(num, den);
      return v == null ? null : v * 100;
    },

    groupBy: (arr, keyFn) => {
      const fn = safeKeyFn(keyFn);
      const obj = {};
      if (!Array.isArray(arr)) return augmentObject(obj);
      for (const row of arr) {
        const key = fn(row);
        if (key != null) { // only group by valid keys
            if (!obj[key]) obj[key] = [];
            obj[key].push(row);
        }
      }
      return augmentObject(obj);
    },

    countBy: (collection, iteratee) => {
      const fn = safeKeyFn(iteratee);
      const result = {};
      const arr = Array.isArray(collection) ? collection : Object.values(collection || {});
      for (const val of arr) {
        let key = fn(val);
        if (key != null) {
            // Fix: If key is object, serialize it to avoid merging different objects into one bucket
            if (typeof key === 'object') {
                if (key instanceof Date) key = key.toISOString();
                else key = JSON.stringify(key);
            }
            result[key] = (result[key] || 0) + 1;
        }
      }
      return augmentObject(result);
    },

        /**
     * 4. NEW: repeatRate
     * Explicit helper for AI to calculate repeat ratios correctly.
     * Returns 0.0 to 1.0 (0% to 100% repetition).
     */
    repeatRate: (collection, iteratee) => {
        const arr = Array.isArray(collection) ? collection : Object.values(collection || {});
        const n = arr.length;
        if (n <= 1) return 0;
        const uniqueCount = collections.countDistinct(arr, iteratee);
        // If 100 items and 80 unique, then 20 are repeats. Rate = 0.2
        return 1 - (uniqueCount / n);
    },

        /**
     * 5. NEW: duplicationCount
     * Returns the raw integer number of items that are redundant.
     */
    duplicationCount: (collection, iteratee) => {
        const arr = Array.isArray(collection) ? collection : Object.values(collection || {});
        return arr.length - collections.countDistinct(arr, iteratee);
    },

    sortBy: (arr, keyFn, dir = "asc") => {
      const fn = safeKeyFn(keyFn);
      if (!Array.isArray(arr)) return [];
      // SERA v3.0: Deterministic tie-breaking via original index
      const indexed = arr.map((item, idx) => ({ item, idx, val: fn(item) }));
      indexed.sort((a, b) => {
        const va = a.val;
        const vb = b.val;
        if (va < vb) return dir === "asc" ? -1 : 1;
        if (va > vb) return dir === "asc" ? 1 : -1;
        return a.idx - b.idx; // stable tie-break: preserve original order
      });
      return indexed.map(x => x.item);
    },

    topNBy: (arr, keyOrN, maybeN) => {
      if (!Array.isArray(arr) || !arr.length) return [];
      const isDescriptor = (v) => typeof v === "function" || typeof v === "string" || Array.isArray(v);

      let keyFn;
      let n;

      if (isDescriptor(keyOrN) && typeof maybeN === "number") {
        keyFn = safeKeyFn(keyOrN);
        n = maybeN;
      } else if (typeof keyOrN === "number" && isDescriptor(maybeN)) {
        keyFn = safeKeyFn(maybeN);
        n = keyOrN;
      } else {
        keyFn = safeKeyFn(keyOrN);
        n = typeof maybeN === "number" ? maybeN : typeof keyOrN === "number" ? keyOrN : arr.length;
      }

      return collections.sortBy(arr, keyFn, "desc").slice(0, n);
    },

    bottomNBy: (arr, keyOrN, maybeN) => {
      if (!Array.isArray(arr) || !arr.length) return [];
      const isDescriptor = (v) => typeof v === "function" || typeof v === "string" || Array.isArray(v);

      let keyFn;
      let n;

      if (isDescriptor(keyOrN) && typeof maybeN === "number") {
        keyFn = safeKeyFn(keyOrN);
        n = maybeN;
      } else if (typeof keyOrN === "number" && isDescriptor(maybeN)) {
        keyFn = safeKeyFn(maybeN);
        n = keyOrN;
      } else {
        keyFn = safeKeyFn(keyOrN);
        n = typeof maybeN === "number" ? maybeN : typeof keyOrN === "number" ? keyOrN : arr.length;
      }

      return collections.sortBy(arr, keyFn, "asc").slice(0, n);
    },

    rankBy: (arr, keyFn, dir = "desc") => {
      const fn = safeKeyFn(keyFn);
      const sorted = collections.sortBy(arr, fn, dir);
      return sorted.map((item, idx) => ({ ...item, rank: idx + 1 }));
    },

    flatten: (arr) => Array.isArray(arr) ? [].concat(...arr) : [],

    flattenDeep: (arr) => {
      const out = [];
      const rec = (v) => {
        if (Array.isArray(v)) for (const x of v) rec(x);
        else out.push(v);
      };
      rec(arr);
      return out;
    },

    chunk: (arr, size = 2) => {
      const out = [];
      for (let i = 0; i < (arr || []).length; i += size) out.push(arr.slice(i, i + size));
      return out;
    },

    zip: (a, b) => {
      const L = Math.min((a || []).length, (b || []).length);
      const out = [];
      for (let i = 0; i < L; i++) out.push([a[i], b[i]]);
      return out;
    },

    unzip: (pairs) => {
      const a = [];
      const b = [];
      for (const [x, y] of pairs || []) {
        a.push(x);
        b.push(y);
      }
      return [a, b];
    },

    range: (n) => {
      const out = [];
      for (let i = 0; i < n; i++) out.push(i);
      return out;
    },

        safeGet: (obj, path, def = null) => _get(obj, path, def),

    slice: (array, start, end) => {
      if (Array.isArray(array)) return array.slice(start, end);
      if (typeof array === "string") return array.slice(start, end);
      // Fallback: if it's an object, slice its values
      if (array && typeof array === "object") return Object.values(array).slice(start, end);
      return [];
    },

    /**
     * BONUS: _.includes
     * Checks if value is in collection. Safe for arrays, strings, and objects.
     */
    includes: (collection, value, fromIndex) => {
      if (Array.isArray(collection) || typeof collection === "string") {
        return collection.includes(value, fromIndex);
      }
      if (collection && typeof collection === "object") {
        return Object.values(collection).includes(value, fromIndex);
      }
      return false;
    },

    /**
     * BONUS: _.indexOf
     * Gets the index at which the first occurrence of value is found in array.
     */
    indexOf: (array, value, fromIndex) => {
      return (Array.isArray(array) || typeof array === "string") 
        ? array.indexOf(value, fromIndex) 
        : -1;
    },

    /**
     * BONUS: _.reverse
     * Reverses array so that the first element becomes the last, the last the first.
     * Returns a NEW array to prevent mutating the original data.
     */
    reverse: (array) => {
      if (Array.isArray(array)) return [...array].reverse();
      if (typeof array === "string") return array.split("").reverse().join("");
      return [];
    },

    /**
     * BONUS: _.concat
     * Creates a new array concatenating array with any additional arrays and/or values.
     */
    concat: (array, ...args) => {
      const base = Array.isArray(array) ? array : (array ? [array] : []);
      return base.concat(...args);
    },
  };

  // =========================================================================
  // REPLACEMENT: TIMESERIES MODULE (v2.5 - Chronological Fix)
  // =========================================================================
  const timeseries = {
    safeDate: (d) => {
      if (d == null) return null;
      const dt = new Date(d);
      return isNaN(dt.getTime()) ? null : dt;
    },

    periodKey: (d, granularity = "day") => {
      const dt = timeseries.safeDate(d);
      if (!dt) return null;
      const y = dt.getUTCFullYear();
      const m = String(dt.getUTCMonth() + 1).padStart(2, "0");
      const day = String(dt.getUTCDate()).padStart(2, "0");

      if (granularity === "month") return `${y}-${m}`;
      if (granularity === "day") return `${y}-${m}-${day}`;
      if (granularity === "week") {
        const oneJan = new Date(Date.UTC(y, 0, 1));
        const diff = (dt - oneJan) / 86400000;
        const week = Math.ceil((diff + oneJan.getUTCDay() + 1) / 7);
        return `${y}-W${String(week).padStart(2, "0")}`;
      }
      return `${y}-${m}-${day}`;
    },

    growth: (cur, prev) => (stats.toNumber(cur) - stats.toNumber(prev)) || 0,

    growthPct: (cur, prev) => {
      const p = stats.toNumber(prev);
      const c = stats.toNumber(cur);
      if (!Number.isFinite(p) || p === 0 || !Number.isFinite(c)) return 0;
      return (c - p) / Math.abs(p);
    },

    /**
     * NEW: Robust Percent Change with Auto-Sorting
     * Ensures chronological order before computing MoM/YoY deltas.
     */
    pctChangeSorted: (data, timeKey, valKey) => {
        const rows = Array.isArray(data) ? [...data] : [];
        if (rows.length < 2) return rows.map(r => Object.assign({}, r, { pctChange: 0, prevValue: null }));

        const tFn = safeKeyFn(timeKey);
        const vFn = safeKeyFn(valKey);

        // 1. Sort Chronologically (using enhanced parseDate that handles month names, quarters, etc.)
        rows.sort((a, b) => {
            const dA = dates.parseDate(tFn(a)) || new Date(0);
            const dB = dates.parseDate(tFn(b)) || new Date(0);
            return dA - dB;
        });

        // 2. Compute Deltas — return new objects, do NOT mutate input
        return rows.map((cur, i) => {
            const result = Object.assign({}, cur);
            if (i === 0) {
                result.pctChange = 0;
                result.prevValue = null;
                return result;
            }
            const prev = rows[i - 1];
            const vCur = stats.toNumber(vFn(cur));
            const vPrev = stats.toNumber(vFn(prev));
            
            result.prevValue = vPrev;
            if (Number.isFinite(vCur) && Number.isFinite(vPrev) && vPrev !== 0) {
                result.pctChange = (vCur - vPrev) / Math.abs(vPrev);
            } else {
                result.pctChange = 0;
            }
            return result;
        });
    },

    movingAvg: (arr, w = 3) => {
      const nums = stats.compactNumbers(arr);
      if (nums.length === 0) return [];
      const out = [];
      for (let i = 0; i < nums.length; i++) {
        const slice = nums.slice(Math.max(0, i - w + 1), i + 1);
        out.push(stats.avg(slice));
      }
      return out;
    },

    movements1D: (arr) => {
      const nums = stats.compactNumbers(arr);
      const out = [];
      if (nums.length < 2) return [];

      for (let i = 1; i < nums.length; i++) {
        const from = nums[i - 1];
        const to = nums[i];
        const delta = to - from;
        const direction = delta > 0 ? "up" : delta < 0 ? "down" : "flat";
        out.push({ index: i, from, to, delta, direction });
      }
      return out;
    },

    maxMovement: (arr) => {
      const movs = timeseries.movements1D(arr);
      if (!movs.length) return 0;
      let max = 0;
      for(const m of movs) {
          const abs = Math.abs(m.delta);
          if(abs > max) max = abs;
      }
      return max;
    },

    peakMovementObject: (arr) => {
        const movs = timeseries.movements1D(arr);
        if (!movs.length) return { index: 0, from: 0, to: 0, delta: 0, direction: 'flat' };
        return collections.maxBy(movs, m => Math.abs(m.delta));
    },

    nMovements: (arr) => {
      const mov = timeseries.movements1D(arr);
      if (!mov.length) return 0;
      let changes = 0;
      for (let i = 1; i < mov.length; i++) {
        if (mov[i].direction !== mov[i - 1].direction) changes++;
      }
      return changes;
    },

    movementSummary: (arr) => {
      const mov = timeseries.movements1D(arr);
      let up = 0, down = 0, flat = 0, totalAbs = 0, net = 0, maxDelta = 0;
      for (const m of mov) {
        if (m.direction === "up") up++;
        else if (m.direction === "down") down++;
        else flat++;
        const abs = Math.abs(m.delta);
        totalAbs += abs;
        net += m.delta;
        if (abs > maxDelta) maxDelta = abs;
      }
      return {
        steps: mov.length,
        upCount: up,
        downCount: down,
        flatCount: flat,
        netDelta: net,
        totalAbsDelta: totalAbs,
        maxMovement: maxDelta,
        nMovements: timeseries.nMovements(arr),
      };
    },

    runLengths: (arr) => {
      const nums = stats.compactNumbers(arr);
      if (!nums.length) return [];
      const out = [];
      let dir = null;
      let len = 1;
      for (let i = 1; i < nums.length; i++) {
        const d = nums[i] - nums[i - 1];
        const nd = d > 0 ? "up" : d < 0 ? "down" : "flat";
        if (dir === null) dir = nd;
        else if (nd === dir) len++;
        else {
          out.push({ direction: dir, length: len });
          dir = nd;
          len = 1;
        }
      }
      out.push({ direction: dir, length: len });
      return out;
    },

    turningPoints: (arr) => {
      const nums = stats.compactNumbers(arr);
      if (nums.length < 3) return [];
      const points = [];
      for (let i = 2; i < nums.length; i++) {
        const d1 = nums[i - 1] - nums[i - 2];
        const d2 = nums[i] - nums[i - 1];
        if (d1 * d2 < 0) points.push(i);
      }
      return points;
    },

    momentum: (arr) => {
      const nums = stats.compactNumbers(arr);
      if (nums.length < 2) return 0;
      let m = 0;
      for (let i = 1; i < nums.length; i++) m += nums[i] - nums[i - 1];
      return m;
    },

    acceleration: (arr) => {
      const nums = stats.compactNumbers(arr);
      if (nums.length < 3) return 0;
      let a = 0;
      for (let i = 2; i < nums.length; i++) {
        const d1 = nums[i - 1] - nums[i - 2];
        const d2 = nums[i] - nums[i - 1];
        a += d2 - d1;
      }
      return a;
    },

    // =========================================================================
    // SERA v3.0: PERIOD-AWARE TIMESERIES FUNCTIONS
    // These handle {period, value} objects and auto-sort chronologically.
    // =========================================================================

    /**
     * Universal period sort key generator.
     * Handles: "January", "Jan", "Q1", "2024-01", "2024-Q1", "2024", "2024-01-15", "Week 3", ISO dates
     * Returns a numeric sort key where lower = earlier.
     */
    periodSortKey: (period) => {
      if (period == null) return 999999;
      if (typeof period === "number") return period;
      const s = String(period).trim().toLowerCase();
      if (!s) return 999999;

      // Month names: "january", "jan", "feb", etc.
      const MONTHS = { jan: 1, january: 1, feb: 2, february: 2, mar: 3, march: 3, apr: 4, april: 4,
        may: 5, jun: 6, june: 6, jul: 7, july: 7, aug: 8, august: 8, sep: 9, sept: 9, september: 9,
        oct: 10, october: 10, nov: 11, november: 11, dec: 12, december: 12 };
      if (MONTHS[s] != null) return MONTHS[s];

      // Quarter: "q1", "q2", "2024-q1", "2024 q3"
      const qMatch = s.match(/(?:(\d{4})\s*[-/]?\s*)?q([1-4])/);
      if (qMatch) {
        const y = qMatch[1] ? Number(qMatch[1]) * 100 : 0;
        return y + Number(qMatch[2]) * 3 - 2; // Q1→1, Q2→4, Q3→7, Q4→10
      }

      // YYYY-MM or YYYY/MM: "2024-01", "2024/03"
      const ymMatch = s.match(/^(\d{4})[-/](\d{1,2})$/);
      if (ymMatch) return Number(ymMatch[1]) * 100 + Number(ymMatch[2]);

      // YYYY-MM-DD or full ISO date
      const ymdMatch = s.match(/^(\d{4})[-/](\d{1,2})[-/](\d{1,2})/);
      if (ymdMatch) return Number(ymdMatch[1]) * 10000 + Number(ymdMatch[2]) * 100 + Number(ymdMatch[3]);

      // Week: "week 3", "w03", "wk 12"
      const wMatch = s.match(/w(?:ee)?k?\s*(\d+)/);
      if (wMatch) return Number(wMatch[1]);

      // Plain year: "2024"
      const yearMatch = s.match(/^(\d{4})$/);
      if (yearMatch) return Number(yearMatch[1]) * 100;

      // "Month Year" combos: "Jan 2024", "January 2024", "2024 Jan"
      for (const [mName, mNum] of Object.entries(MONTHS)) {
        if (s.includes(mName)) {
          const yy = s.match(/\d{4}/);
          const yearVal = yy ? Number(yy[0]) * 100 : 0;
          return yearVal + mNum;
        }
      }

      // Try parsing as a date
      const d = new Date(period);
      if (!isNaN(d.getTime())) return d.getTime() / 86400000; // days since epoch

      return 999999;
    },

    /**
     * Sort an array of {period, value, ...} objects chronologically.
     * Works with any period format that periodSortKey understands.
     * Returns a NEW sorted array (does not mutate input).
     */
    chronoSort: (arr, periodKey = "period") => {
      if (!Array.isArray(arr) || !arr.length) return [];
      const fn = typeof periodKey === "function" ? periodKey : (r) => r && r[periodKey];
      return [...arr].sort((a, b) => {
        const ka = timeseries.periodSortKey(fn(a));
        const kb = timeseries.periodSortKey(fn(b));
        return (ka - kb) || String(fn(a) || "").localeCompare(String(fn(b) || ""));
      });
    },

    /**
     * Period-aware movements: takes [{period, value}, ...], auto-sorts, computes deltas.
     * Returns: [{period, value, prevPeriod, prevValue, delta, pctChange, direction}, ...]
     */
    periodMovements: (arr, periodKey = "period", valueKey = "value") => {
      if (!Array.isArray(arr) || arr.length < 2) return [];
      const pFn = typeof periodKey === "function" ? periodKey : (r) => r && r[periodKey];
      const vFn = typeof valueKey === "function" ? valueKey : (r) => {
        const v = r && r[valueKey];
        return stats.toNumber(v);
      };

      const sorted = timeseries.chronoSort(arr, pFn);
      const out = [];

      for (let i = 0; i < sorted.length; i++) {
        const cur = sorted[i];
        const val = vFn(cur);
        const period = pFn(cur);

        if (i === 0) {
          out.push({ period, value: val, prevPeriod: null, prevValue: null, delta: 0, pctChange: 0, direction: "flat" });
          continue;
        }

        const prev = sorted[i - 1];
        const prevVal = vFn(prev);
        const prevPeriod = pFn(prev);
        const curN = Number.isFinite(val) ? val : 0;
        const prevN = Number.isFinite(prevVal) ? prevVal : 0;
        const delta = curN - prevN;
        const pctChange = (Number.isFinite(prevN) && prevN !== 0) ? delta / Math.abs(prevN) : 0;
        const direction = delta > 0 ? "up" : delta < 0 ? "down" : "flat";

        out.push({ period, value: val, prevPeriod, prevValue: prevVal, delta, pctChange, direction });
      }
      return out;
    },

    /**
     * Period-aware moving average.
     * Takes [{period, value}, ...], auto-sorts, returns [{period, value, movingAvg}, ...]
     */
    periodMovingAvg: (arr, windowSize = 3, periodKey = "period", valueKey = "value") => {
      if (!Array.isArray(arr) || !arr.length) return [];
      const pFn = typeof periodKey === "function" ? periodKey : (r) => r && r[periodKey];
      const vFn = typeof valueKey === "function" ? valueKey : (r) => {
        const v = r && r[valueKey];
        return stats.toNumber(v);
      };

      const sorted = timeseries.chronoSort(arr, pFn);
      const values = sorted.map(r => {
        const v = vFn(r);
        return Number.isFinite(v) ? v : null;
      });

      return sorted.map((r, i) => {
        const window = [];
        for (let k = Math.max(0, i - windowSize + 1); k <= i; k++) {
          if (values[k] != null) window.push(values[k]);
        }
        const avg = window.length > 0 ? window.reduce((a, b) => a + b, 0) / window.length : null;
        return { period: pFn(r), value: values[i], movingAvg: avg };
      });
    },

    /**
     * Period-over-period comparison.
     * Compare two sets of periods (e.g., Q1 vs Q2, or Jan-Mar vs Apr-Jun).
     * Takes the full array + two period filter functions or arrays.
     */
    periodCompare: (arr, periodsA, periodsB, valueKey = "value") => {
      if (!Array.isArray(arr)) return { sumA: 0, sumB: 0, delta: 0, pctChange: 0 };
      const vFn = typeof valueKey === "function" ? valueKey : (r) => stats.toNumber(r && r[valueKey]);

      const matchFn = (periods) => {
        if (typeof periods === "function") return periods;
        if (Array.isArray(periods)) {
          const set = new Set(periods.map(p => String(p).toLowerCase().trim()));
          return (r) => set.has(String(r && r.period || "").toLowerCase().trim());
        }
        return () => false;
      };

      const fnA = matchFn(periodsA);
      const fnB = matchFn(periodsB);

      let sumA = 0, countA = 0, sumB = 0, countB = 0;
      for (const r of arr) {
        const v = vFn(r);
        if (!Number.isFinite(v)) continue;
        if (fnA(r)) { sumA += v; countA++; }
        if (fnB(r)) { sumB += v; countB++; }
      }

      const delta = sumB - sumA;
      const pctChange = sumA !== 0 ? delta / Math.abs(sumA) : 0;
      return { sumA, countA, avgA: countA ? sumA / countA : 0, sumB, countB, avgB: countB ? sumB / countB : 0, delta, pctChange };
    },

    /**
     * Rolling window aggregation over period-sorted data.
     * Returns [{period, value, rollingSum, rollingAvg, rollingMin, rollingMax}, ...]
     */
    rollingAgg: (arr, windowSize = 3, periodKey = "period", valueKey = "value") => {
      if (!Array.isArray(arr) || !arr.length) return [];
      const pFn = typeof periodKey === "function" ? periodKey : (r) => r && r[periodKey];
      const vFn = typeof valueKey === "function" ? valueKey : (r) => {
        const v = r && r[valueKey];
        return stats.toNumber(v);
      };

      const sorted = timeseries.chronoSort(arr, pFn);
      const values = sorted.map(r => {
        const v = vFn(r);
        return Number.isFinite(v) ? v : null;
      });

      return sorted.map((r, i) => {
        const window = [];
        for (let k = Math.max(0, i - windowSize + 1); k <= i; k++) {
          if (values[k] != null) window.push(values[k]);
        }
        const sum = window.reduce((a, b) => a + b, 0);
        return {
          period: pFn(r),
          value: values[i],
          rollingSum: window.length > 0 ? sum : null,
          rollingAvg: window.length > 0 ? sum / window.length : null,
          rollingMin: window.length > 0 ? Math.min(...window) : null,
          rollingMax: window.length > 0 ? Math.max(...window) : null,
          windowSize: window.length
        };
      });
    },

    /**
     * Period-aware movement summary (like movementSummary but accepts {period, value} objects).
     */
    periodSummary: (arr, periodKey = "period", valueKey = "value") => {
      const movements = timeseries.periodMovements(arr, periodKey, valueKey);
      if (!movements.length) return { steps: 0, upCount: 0, downCount: 0, flatCount: 0, netDelta: 0, totalAbsDelta: 0, maxMovement: 0, nDirectionChanges: 0, periods: [] };

      let up = 0, down = 0, flat = 0, totalAbs = 0, net = 0, maxDelta = 0, dirChanges = 0;
      for (let i = 0; i < movements.length; i++) {
        const m = movements[i];
        if (m.direction === "up") up++;
        else if (m.direction === "down") down++;
        else flat++;
        const abs = Math.abs(m.delta || 0);
        totalAbs += abs;
        net += (m.delta || 0);
        if (abs > maxDelta) maxDelta = abs;
        if (i > 0 && movements[i].direction !== movements[i - 1].direction) dirChanges++;
      }

      return {
        steps: movements.length,
        upCount: up,
        downCount: down,
        flatCount: flat,
        netDelta: net,
        totalAbsDelta: totalAbs,
        maxMovement: maxDelta,
        nDirectionChanges: dirChanges,
        periods: movements.map(m => m.period),
        firstPeriod: movements[0] && movements[0].period,
        lastPeriod: movements[movements.length - 1] && movements[movements.length - 1].period,
        firstValue: movements[0] && movements[0].value,
        lastValue: movements[movements.length - 1] && movements[movements.length - 1].value,
        overallPctChange: movements.length >= 2 ? timeseries.growthPct(
          movements[movements.length - 1].value,
          movements[0].value
        ) : 0
      };
    },
  };


/** 
 * -------------------------------------------------------------------------
 * REPLACEMENT MODULE: CORRELATION (Deep Analytics Patch)
 * Replace your existing 'const correlation = { ... };' block with this.
 * -------------------------------------------------------------------------
 */
const correlation = (() => {
  // Internal Helper: Convert array to ranks (handles ties by averaging)
  const getRanks = (arr) => {
    const sorted = arr.map((v, i) => ({ v, i })).sort((a, b) => a.v - b.v);
    const ranks = new Array(arr.length);
    for (let i = 0; i < sorted.length; i++) {
      let j = i;
      while (j < sorted.length - 1 && sorted[j + 1].v === sorted[i].v) j++;
      const rank = (i + j + 2) / 2;
      for (let k = i; k <= j; k++) ranks[sorted[k].i] = rank;
      i = j;
    }
    return ranks;
  };

  return {
    // 1. Classic Linear (Pearson) - Explicit Finite Filtering
    correlation: (xs, ys) => {
      if (!Array.isArray(xs) || !Array.isArray(ys)) return 0;
      const nRaw = Math.min(xs.length, ys.length);
      if (nRaw < 2) return 0;

      const X = [], Y = [];
      // FIX: Strict Pair Filtering
      for (let i = 0; i < nRaw; i++) {
        const xn = stats.toNumber(xs[i]);
        const yn = stats.toNumber(ys[i]);
        if (Number.isFinite(xn) && Number.isFinite(yn)) {
            X.push(xn);
            Y.push(yn);
        }
      }
      
      if (X.length < 2) return 0;

      const xm = stats.avg(X);
      const ym = stats.avg(Y);
      let num = 0, dx = 0, dy = 0;
      for (let i = 0; i < X.length; i++) {
        const a = X[i] - xm;
        const b = Y[i] - ym;
        num += a * b;
        dx += a * a;
        dy += b * b;
      }

      const den = Math.sqrt(dx * dy);
      return den ? num / den : 0;
    },

    // 2. Rank Correlation (Spearman)
    spearman: (xs, ys) => {
      if (!Array.isArray(xs) || !Array.isArray(ys)) return 0;
      const valid = [];
      const nRaw = Math.min(xs.length, ys.length);
      for(let i=0; i<nRaw; i++) {
         const x = stats.toNumber(xs[i]);
         const y = stats.toNumber(ys[i]);
         if(Number.isFinite(x) && Number.isFinite(y)) valid.push({x, y});
      }
      if (valid.length < 2) return 0;
      
      const rankX = getRanks(valid.map(v => v.x));
      const rankY = getRanks(valid.map(v => v.y));
      
      return correlation.correlation(rankX, rankY);
    },

    // 3. Robust Correlation (Kendall's Tau)
    kendall: (xs, ys) => {
       if (!Array.isArray(xs) || !Array.isArray(ys)) return 0;
       const valid = [];
       const nRaw = Math.min(xs.length, ys.length);
       for(let i=0; i<nRaw; i++) {
         const x = stats.toNumber(xs[i]);
         const y = stats.toNumber(ys[i]);
         if(Number.isFinite(x) && Number.isFinite(y)) valid.push({x, y});
       }
       const n = valid.length;
       if(n < 2) return 0;

       let conc = 0, disc = 0;
       for(let i=0; i<n; i++) {
         for(let j=i+1; j<n; j++) {
           const dx = valid[i].x - valid[j].x;
           const dy = valid[i].y - valid[j].y;
           const prod = dx * dy;
           if (prod > 0) conc++;
           else if (prod < 0) disc++;
         }
       }
       return (conc - disc) / (0.5 * n * (n - 1));
    },

    // 4. Mutual Information
    mutualInformation: (xs, ys, bins = 10) => {
       if (!Array.isArray(xs) || !Array.isArray(ys)) return 0;
       const valid = [];
       let minX=Infinity, maxX=-Infinity, minY=Infinity, maxY=-Infinity;
       const nRaw = Math.min(xs.length, ys.length);
       
       for(let i=0; i<nRaw; i++) {
         const x = stats.toNumber(xs[i]);
         const y = stats.toNumber(ys[i]);
         if(Number.isFinite(x) && Number.isFinite(y)) {
             valid.push({x, y});
             if(x < minX) minX = x; if(x > maxX) maxX = x;
             if(y < minY) minY = y; if(y > maxY) maxY = y;
         }
       }
       if (!valid.length) return 0;

       const rangeX = maxX - minX || 1;
       const rangeY = maxY - minY || 1;
       const hist = {};
       const pX = {}, pY = {};
       const n = valid.length;

       for(const v of valid) {
           const bx = Math.min(bins-1, Math.floor(((v.x - minX) / rangeX) * bins));
           const by = Math.min(bins-1, Math.floor(((v.y - minY) / rangeY) * bins));
           const key = `${bx}:${by}`;
           hist[key] = (hist[key] || 0) + 1;
           pX[bx] = (pX[bx] || 0) + 1;
           pY[by] = (pY[by] || 0) + 1;
       }

       let mi = 0;
       for(const key in hist) {
           const [bx, by] = key.split(':');
           const pXY_val = hist[key] / n;
           const pX_val = pX[bx] / n;
           const pY_val = pY[by] / n;
           if (pXY_val > 0) {
               mi += pXY_val * Math.log2(pXY_val / (pX_val * pY_val));
           }
       }
       return Math.max(0, mi);
    },

    // 5. Cross Correlation
    crossCorrelation: (xs, ys, maxLag = 10) => {
       if (!Array.isArray(xs) || !Array.isArray(ys)) return [];
       // Filter independently for time-series logic, or treat as zeros? 
       // Standard practice: compact, then correlate.
       const X = stats.compactNumbers(xs);
       const Y = stats.compactNumbers(ys);
       const n = Math.min(X.length, Y.length);
       if (n < maxLag + 2) return [];

       const results = [];
       for (let lag = -maxLag; lag <= maxLag; lag++) {
           let setA = [], setB = [];
           if (lag < 0) {
               setA = X.slice(0, n + lag);
               setB = Y.slice(-lag, n);
           } else {
               setA = X.slice(lag, n);
               setB = Y.slice(0, n - lag);
           } 
           const r = correlation.correlation(setA, setB);
           results.push({ lag, correlation: r });
       }
       return results.sort((a,b) => b.correlation - a.correlation);
    },

    // 6. Autocorrelation
    autocorrelation: (arr, maxLag = 10) => {
        const res = correlation.crossCorrelation(arr, arr, maxLag);
        return res.filter(r => r.lag > 0);
    },

    // 7. Partial Correlation
    partialCorrelation: (data, xField, yField, controlFields) => {
        const controls = Array.isArray(controlFields) ? controlFields : [controlFields];
        const rows = Array.isArray(data) ? data : [];
        if(!rows.length) return 0;

        const getResiduals = (targetArr, predictorArr) => {
            const reg = correlation.linearRegression(predictorArr, targetArr);
            if(!reg) return targetArr;
            return targetArr.map((y, i) => y - (reg.slope * predictorArr[i] + reg.intercept));
        };

        const tX = safeKeyFn(xField);
        const tY = safeKeyFn(yField);
        const tCs = controls.map(c => safeKeyFn(c));

        // STRICT TRIPLET FILTERING
        const validX = [], validY = [], validCs = [];
        // Init control arrays
        controls.forEach(() => validCs.push([]));

        for(const r of rows) {
            const vx = stats.toNumber(tX(r));
            const vy = stats.toNumber(tY(r));
            const vcs = tCs.map(fn => stats.toNumber(fn(r)));
            
            if(Number.isFinite(vx) && Number.isFinite(vy) && vcs.every(c => Number.isFinite(c))) {
                validX.push(vx);
                validY.push(vy);
                vcs.forEach((c, i) => validCs[i].push(c));
            }
        }

        if (validX.length < 3) return 0;

        let curX = validX;
        let curY = validY;

        for(let i=0; i<controls.length; i++) {
             const ctrl = validCs[i];
             curX = getResiduals(curX, ctrl);
             curY = getResiduals(curY, ctrl);
        }

        return correlation.correlation(curX, curY);
    },

    // Linear Regression (Strict Pairs)
    linearRegression: (xs, ys) => {
      if (!Array.isArray(xs) || !Array.isArray(ys)) return null;
      const nRaw = Math.min(xs.length, ys.length);
      if (nRaw < 2) return null;

      const X = [], Y = [];
      for (let i = 0; i < nRaw; i++) {
        const xn = stats.toNumber(xs[i]);
        const yn = stats.toNumber(ys[i]);
        if (Number.isFinite(xn) && Number.isFinite(yn)) {
            X.push(xn);
            Y.push(yn);
        }
      }
      const n = X.length;
      if (n < 2) return null;

      const sumX = stats.sum(X);
      const sumY = stats.sum(Y);
      const sumXY = stats.sum(X.map((x, i) => x * Y[i]));
      const sumX2 = stats.sum(X.map((x) => x * x));

      const meanX = sumX / n;
      const meanY = sumY / n;

      const denom = sumX2 - n * meanX * meanX;
      if (!denom) return { slope: 0, intercept: meanY, r2: 0, n };

      const slope = (sumXY - n * meanX * meanY) / denom;
      const intercept = meanY - slope * meanX;

      let ssTot = 0, ssRes = 0;
      for (let i = 0; i < n; i++) {
        const yi = Y[i];
        const yHat = slope * X[i] + intercept;
        ssTot += (yi - meanY) ** 2;
        ssRes += (yi - yHat) ** 2;
      }

      const r2 = ssTot ? 1 - ssRes / ssTot : 0;
      return { slope, intercept, r2, n };
    },

    forecastLinear: (xs, ys, xFuture) => {
      const reg = correlation.linearRegression(xs, ys);
      if (!reg) return null;
      const x = xFuture != null ? Number(xFuture) : xs && xs.length ? Number(xs[xs.length - 1]) + 1 : 0;
      if (!Number.isFinite(x)) return null;
      return reg.slope * x + reg.intercept;
    },

    correlationByGroup: (data, groupKeyFn, xFn, yFn) => {
      const groups = collections.groupBy(data, groupKeyFn);
      const result = {};
      for (const [key, rows] of Object.entries(groups)) {
        const xs = rows.map(xFn);
        const ys = rows.map(yFn);
        const n = rows.length; // Approximate, but rankDrivers handles strict N
        result[key] = { 
            pearson: correlation.correlation(xs, ys), 
            spearman: correlation.spearman(xs, ys),
            n
        };
      }
      return augmentObject(result);
    },

    correlationMatrix: (data, numericFields) => {
      const matrix = {};
      // Uses strict correlation internal filtering
      for (const f1 of numericFields || []) {
        matrix[f1] = {};
        for (const f2 of numericFields || []) {
          if (f1 === f2) matrix[f1][f2] = 1;
          else {
            const xs = (data || []).map((r) => stats.toNumber(r[f1]));
            const ys = (data || []).map((r) => stats.toNumber(r[f2]));
            matrix[f1][f2] = correlation.correlation(xs, ys);
          }
        } 
      }
      return augmentObject(matrix);
    },

    // --- FIXED RANK DRIVERS (CORRECT N-COUNT) ---
    rankDrivers: (data, targetField, candidateFields) => {
      const rows = Array.isArray(data) ? data : [];
      if (rows.length < 2) return [];

      const drivers = [];
      // Normalize candidates
      let candidates = [];
      if (Array.isArray(candidateFields)) candidates = candidateFields;
      else if (typeof candidateFields === 'object' && candidateFields) candidates = Object.keys(candidateFields);
      else if (typeof candidateFields === 'string') candidates = [candidateFields];

      const tFn = safeKeyFn(targetField);

      for (const field of candidates) {
        if (field === targetField) continue;
        const xFn = safeKeyFn(field);
        
        // 1. EXTRACT STRICT PAIRS ONLY
        // We cannot use simple .map() because the validity of X and Y must match per-row.
        const validX = [];
        const validY = [];

        for (const r of rows) {
            const valX = stats.toNumber(xFn(r));
            const valY = stats.toNumber(tFn(r));
            // BOTH must be finite numbers to be a valid pair for correlation
            if (Number.isFinite(valX) && Number.isFinite(valY)) {
                validX.push(valX);
                validY.push(valY);
            }
        }

        // 2. Correct N (valid pairs count)
        const nValid = validX.length;
        
        if (nValid < 2) {
             drivers.push({
              field,
              correlation: 0, absCorrelation: 0, spearman: 0, mutualInfo: 0, 
              r2: 0, slope: 0, n: nValid // Correct low count
            });
            continue;
        }
        
        // 3. Calc Stats on CLEAN VECTORS
        const corr = correlation.correlation(validX, validY);
        const spear = correlation.spearman(validX, validY);
        const mi = correlation.mutualInformation(validX, validY);
        const reg = correlation.linearRegression(validX, validY);

        drivers.push({
          field,
          correlation: corr,
          absCorrelation: Math.abs(corr),
          spearman: spear,
          mutualInfo: mi,
          r2: reg ? reg.r2 : 0,
          slope: reg ? reg.slope : 0,
          n: nValid, // Strict pair count
        });
      }

      return collections.sortBy(drivers, (d) => d.absCorrelation, "desc");
    },
  };
})();

  // =========================================================================
  // NEW MODULE: ADVANCED REGRESSION (Modeling Breadth)
  // =========================================================================
  const regression = (() => {

  const _isMatrix = (A) =>
  Array.isArray(A) &&
  A.length > 0 &&
  Array.isArray(A[0]) &&
  A[0].length > 0;

const matMul = (A, B) => {
  if (!_isMatrix(A) || !_isMatrix(B)) return [];
  const aRows = A.length;
  const aCols = A[0].length;
  const bRows = B.length;
  const bCols = B[0].length;

  // dimension mismatch
  if (aCols !== bRows) return [];

  const result = new Array(aRows);
  for (let r = 0; r < aRows; r++) {
    result[r] = new Array(bCols).fill(0);
    for (let c = 0; c < bCols; c++) {
      let sum = 0;
      for (let i = 0; i < aCols; i++) {
        const av = A[r] && typeof A[r][i] === "number" ? A[r][i] : 0;
        const bv = B[i] && typeof B[i][c] === "number" ? B[i][c] : 0;
        sum += av * bv;
      }
      result[r][c] = sum;
    }
  }
  return result;
};

const matTranspose = (A) => {
  if (!_isMatrix(A)) return [];
  const rows = A.length;
  const cols = A[0].length;
  const T = new Array(cols);
  for (let c = 0; c < cols; c++) {
    T[c] = new Array(rows);
    for (let r = 0; r < rows; r++) {
      T[c][r] = (A[r] && typeof A[r][c] === "number") ? A[r][c] : 0;
    }
  }
  return T;
};

const matInv = (M) => {
  if (!_isMatrix(M)) return null;
  if (M.length !== M[0].length) return null;

  const dim = M.length;
  const I = [];
  const C = M.map(row => Array.isArray(row) ? row.slice() : []);

  // identity
  for (let i = 0; i < dim; i++) {
    I[i] = [];
    for (let j = 0; j < dim; j++) I[i][j] = (i === j) ? 1 : 0;
  }

  for (let i = 0; i < dim; i++) {
    if (!C[i] || typeof C[i][i] !== "number") return null;
    let e = C[i][i];
    if (!e) return null; // singular / zero pivot

    for (let j = 0; j < dim; j++) { C[i][j] /= e; I[i][j] /= e; }

    for (let k = 0; k < dim; k++) {
      if (k === i) continue;
      const f = (C[k] && typeof C[k][i] === "number") ? C[k][i] : 0;
      for (let j = 0; j < dim; j++) { C[k][j] -= f * C[i][j]; I[k][j] -= f * I[i][j]; }
    }
  }
  return I;
};


  const prepareData = (data, xFields, yField) => {
    xFields = Array.isArray(xFields) ? xFields : [];
    if (!xFields.length) return null;
    if (!Array.isArray(data)) return null;
    const X = [];
    const Y = [];
    const xFns = xFields.map(f => safeKeyFn(f));
    const yFn = safeKeyFn(yField);

    for (const row of data) {
      const yVal = stats.toNumber(yFn(row));
      if (!Number.isFinite(yVal)) continue;
      const rowX = [1.0];
      let validRow = true;
      for (const fn of xFns) {
        const v = stats.toNumber(fn(row));
        if (!Number.isFinite(v)) { validRow = false; break; }
        rowX.push(v);
      }
      if (validRow) {
        X.push(rowX);
        Y.push([yVal]);
      }
    }
    return { X, Y, n: Y.length };
  };

  return {
    multipleLinearRegression: (data, xFields, yField) => {
      xFields = Array.isArray(xFields) ? xFields : [];
      if (!xFields.length) return null;
      const prep = prepareData(data, xFields, yField);
      if (!prep || prep.n < xFields.length + 2) return null;

      const Xt = matTranspose(prep.X);
      const XtX = matMul(Xt, prep.X);
      const XtX_inv = matInv(XtX);
      if (!XtX_inv) return { error: "Matrix singular (collinear predictors)" };

      const Xty = matMul(Xt, prep.Y);
      const Beta = matMul(XtX_inv, Xty);
      const coeffs = {};
      const safeVal = (v) => (Number.isFinite(v) ? v : 0);

      coeffs["intercept"] = safeVal(Beta[0][0]);
      xFields.forEach((f, i) => coeffs[f] = safeVal(Beta[i + 1][0]));

      const predictions = prep.X.map(row => {
        let sum = 0;
        for (let i = 0; i < row.length; i++) sum += row[i] * Beta[i][0];
        return sum;
      });
      const actuals = prep.Y.map(y => y[0]);
      const r2 = correlation.correlation(actuals, predictions) ** 2;

      // PARANOID FIX: Ensure strict Number before toFixed call
      const fmt = (n) => {
        const v = safeVal(n);
        return (typeof v === 'number' ? v : 0).toFixed(4);
      };

      return augmentObject({
        coefficients: coeffs,
        r2,
        n: prep.n,
        equation: `y = ${fmt(coeffs.intercept)} + ` + xFields.map(f => `${fmt(coeffs[f])}*${f}`).join(" + ")
      });
    },

    ridgeRegression: (data, xFields, yField, lambda = 1.0) => {
      xFields = Array.isArray(xFields) ? xFields : [];
      if (!xFields.length) return null;
      const prep = prepareData(data, xFields, yField);
      if (!prep || prep.n < xFields.length + 1) return null;
      const Xt = matTranspose(prep.X);
      const XtX = matMul(Xt, prep.X);
      for (let i = 1; i < XtX.length; i++) XtX[i][i] += lambda;
      const XtX_inv = matInv(XtX);
      if (!XtX_inv) return { error: "Matrix singular" };
      const Xty = matMul(Xt, prep.Y);
      const Beta = matMul(XtX_inv, Xty);
      const coeffs = {};
      coeffs["intercept"] = Beta[0][0];
      xFields.forEach((f, i) => coeffs[f] = Beta[i + 1][0]);
      return augmentObject({ coefficients: coeffs, lambda, n: prep.n });
    },

    logisticRegression: (data, xFields, yField, options = {}) => {
      xFields = Array.isArray(xFields) ? xFields : [];
      if (!xFields.length) return null;
      const { learningRate = 0.1, epochs = 100 } = options;
      const prep = prepareData(data, xFields, yField);
      if (!prep || prep.n < 5) return null;
      let weights = new Array(xFields.length + 1).fill(0);
      const sigmoid = (z) => 1 / (1 + Math.exp(-z));
      for (let e = 0; e < epochs; e++) {
        const gradients = new Array(weights.length).fill(0);
        for (let i = 0; i < prep.n; i++) {
          const row = prep.X[i];
          const actual = prep.Y[i][0] > 0 ? 1 : 0;
          let z = 0;
          for (let j = 0; j < weights.length; j++) z += weights[j] * row[j];
          const pred = sigmoid(z);
          const err = pred - actual;
          for (let j = 0; j < weights.length; j++) gradients[j] += err * row[j];
        }
        for (let j = 0; j < weights.length; j++) weights[j] -= (learningRate / prep.n) * gradients[j];
      }
      const coeffs = { intercept: weights[0] };
      xFields.forEach((f, i) => coeffs[f] = weights[i + 1]);
      return augmentObject({
        coefficients: coeffs,
        iterations: epochs,
        predict: (row) => {
          let z = weights[0];
          xFields.forEach((f, i) => z += (stats.toNumber(row[f]) || 0) * weights[i + 1]);
          return sigmoid(z);
        }
      });
    },

    regressionDiagnostics: (actuals, predicteds) => {
      const act = stats.compactNumbers(actuals);
      const pred = stats.compactNumbers(predicteds);
      const n = Math.min(act.length, pred.length);
      if (n === 0) return {};
      let sumAbs = 0, sumSq = 0, sumPct = 0;
      const residuals = [];
      for (let i = 0; i < n; i++) {
        const err = act[i] - pred[i];
        residuals.push(err);
        sumAbs += Math.abs(err);
        sumSq += err * err;
        if (act[i] !== 0) sumPct += Math.abs(err / act[i]);
      }
      return augmentObject({
        residuals,
        mae: sumAbs / n,
        rmse: Math.sqrt(sumSq / n),
        mape: sumPct / n,
        n
      });
    },

    bootstrapRegressionSlopeCI: (xs, ys, iterations = 200, ci = 0.95) => {
      const clean = [];
      for (let i = 0; i < Math.min(xs.length, ys.length); i++) {
        if (Number.isFinite(xs[i]) && Number.isFinite(ys[i])) clean.push({ x: xs[i], y: ys[i] });
      }
      if (clean.length < 10) return null;
      const slopes = [];
      for (let i = 0; i < iterations; i++) {
        const sampleX = [], sampleY = [];
        for (let j = 0; j < clean.length; j++) {
          const idx = Math.floor(Math.random() * clean.length);
          sampleX.push(clean[idx].x);
          sampleY.push(clean[idx].y);
        }
        const reg = correlation.linearRegression(sampleX, sampleY);
        if (reg) slopes.push(reg.slope);
      }
      slopes.sort((a, b) => a - b);
      const lowerIdx = Math.floor(slopes.length * ((1 - ci) / 2));
      const upperIdx = Math.ceil(slopes.length * (1 - (1 - ci) / 2));
      return augmentObject({
        slopeLower: slopes[lowerIdx],
        slopeUpper: slopes[upperIdx],
        slopeMedian: stats.median(slopes),
        confidence: ci,
        iterations
      });
    }
  };
})();

// SERA v3.1: Add common alias guesses to regression module
if (regression && typeof regression === "object") {
  regression.linear = regression.linear || regression.multipleLinearRegression;
  regression.mlr = regression.mlr || regression.multipleLinearRegression;
  regression.ridge = regression.ridge || regression.ridgeRegression;
  regression.logistic = regression.logistic || regression.logisticRegression;
  regression.diagnostics = regression.diagnostics || regression.regressionDiagnostics;
  regression.bootstrap = regression.bootstrap || regression.bootstrapRegressionSlopeCI;
}

/**
 * REPLACEMENT: SPECTRAL MODULE (v3.1 - Wide Data + Heatmap + Peak Fix, FULL PRESERVATION)
 * Drop-in replacement for your existing `const spectral = (() => { ... })();`
 *
 * Keeps:
 * - Original FFT implementation (bitReverse + fft)
 * - detectSeasonality() logic (FFT-based)
 * - analyzeWide() core behavior (unpivot wide monthly columns, aggregate, heatmap, seasonality index)
 *
 * Fixes:
 * - Wider month header detection (Jan, "Jan Qty", "2023-01", "2023-01 Qty", "2023_01_qty")
 * - Heatmap values never null/NaN (coerce non-finite to 0 at ingestion)
 * - Peak month logic returns "No Demand" only when max == 0 across all periods
 * - Better primary measure selection across common tokens
 */
const spectral = (() => {
  // --- Internal Helpers for Wide Data Detection ---
  const MONTH_NAMES = ["jan","feb","mar","apr","may","jun","jul","aug","sep","oct","nov","dec"];
  const MEASURE_TOKENS = ["qty","unit","units","vol","volume","amt","amount","val","value","rev","revenue","sales","total","count"];

  // Regex Helpers
  // Month name token anywhere, including "Jan Qty", "Qty Jan", "jan_qty"
  const rxMonth = new RegExp(`(?:^|[\\W_])(${MONTH_NAMES.join("|")})(?:$|[\\W_])`, "i");
  // Year-month patterns: 2023-01, 2023/01, 2023.01, 202301
  const rxYearMonth = /\b(20\d{2})[-/._]?(0[1-9]|1[0-2])\b/;
  // Measure tokens anywhere, including "Qty", "Units", "Sales"
  const rxMeasure = new RegExp(`(?:^|[\\W_])(${MEASURE_TOKENS.join("|")})(?:$|[\\W_])`, "i");

  const parseMonthHeader = (header) => {
    const raw = String(header);
    const h = raw.toLowerCase();

    // 1) Year-Month first (e.g. "2023-01 Qty", "2023_01_units")
    const ymMatch = raw.match(rxYearMonth);
    if (ymMatch) {
      const y = parseInt(ymMatch[1], 10);
      const m = parseInt(ymMatch[2], 10);

      // remove the matched year-month chunk to find measure tokens around it
      const measurePart = h.replace(ymMatch[0].toLowerCase(), " ");
      const measureMatch = measurePart.match(rxMeasure);

      return {
        type: "ym",
        year: y,
        month: m,
        measure: measureMatch ? measureMatch[1] : "value",
        raw: raw
      };
    }

    // 2) Month name (e.g. "Jan Qty", "Qty Jan", "jan")
    const mMatch = h.match(rxMonth);
    if (mMatch) {
      const mStr = mMatch[1];
      const mIdx = MONTH_NAMES.indexOf(mStr) + 1;
      const measurePart = h.replace(mStr, " ");
      const measureMatch = measurePart.match(rxMeasure);

      // Default to qty for bare month headers (common in wide demand tables)
      return {
        type: "month",
        year: null,
        month: mIdx,
        measure: measureMatch ? measureMatch[1] : "qty",
        raw: raw
      };
    }

    return null;
  };

  // --- Legacy FFT Logic (Preserved) ---
  const bitReverse = (n, bits) => {
    let r = 0;
    for (let i = 0; i < bits; i++) {
      r = (r << 1) | (n & 1);
      n >>= 1;
    }
    return r;
  };

  const fft = (data) => {
    const n = data.length;
    if (n <= 1) return data.map(x => ({ re: x, im: 0, magnitude: Math.abs(x), freqIdx: 0, N: 1 }));

    const bits = Math.ceil(Math.log2(n));
    const N = 1 << bits;

    const re = new Float64Array(N);
    const im = new Float64Array(N);

    for (let i = 0; i < n; i++) re[i] = data[i];

    for (let i = 0; i < N; i++) {
      const r = bitReverse(i, bits);
      if (r > i) {
        [re[i], re[r]] = [re[r], re[i]];
        [im[i], im[r]] = [im[r], im[i]];
      }
    }

    for (let size = 2; size <= N; size *= 2) {
      const half = size / 2;
      const ang = (2 * Math.PI) / size;
      const wRe = Math.cos(ang);
      const wIm = -Math.sin(ang);

      for (let i = 0; i < N; i += size) {
        let curRe = 1, curIm = 0;

        for (let j = 0; j < half; j++) {
          const idxA = i + j;
          const idxB = i + j + half;

          const tRe = curRe * re[idxB] - curIm * im[idxB];
          const tIm = curRe * im[idxB] + curIm * re[idxB];

          re[idxB] = re[idxA] - tRe;
          im[idxB] = im[idxA] - tIm;
          re[idxA] += tRe;
          im[idxA] += tIm;

          const nRe = curRe * wRe - curIm * wIm;
          curIm = curRe * wIm + curIm * wRe;
          curRe = nRe;
        }
      }
    }

    const output = [];
    for (let i = 0; i < N / 2; i++) {
      output.push({
        freqIdx: i,
        re: re[i],
        im: im[i],
        magnitude: Math.sqrt(re[i] * re[i] + im[i] * im[i]),
        N
      });
    }
    return output;
  };

  const measurePriorityPick = (measures) => {
    // Prefer typical demand measures first
    const pref = [
      "qty", "units", "unit",
      "vol", "volume",
      "sales", "revenue", "rev",
      "amt", "amount",
      "total", "count",
      "value", "val"
    ];
    for (const p of pref) if (measures.includes(p)) return p;
    return measures[0] || "value";
  };

  const periodKeyFromCol = (col) => {
    if (col.year) return `${col.year}-${String(col.month).padStart(2, "0")}`;
    return MONTH_NAMES[col.month - 1];
  };

  return {
    detectSeasonality: (arr, sampleRate = 1) => {
      const nums = stats.compactNumbers(arr);
      if (nums.length < 4) return [];

      const mean = stats.mean(nums);
      const centered = nums.map(x => x - mean);
      const spectrum = fft(centered);

      const N = spectrum[0] && spectrum[0].N ? spectrum[0].N : 1;

      const out = spectrum
        .filter(b => b.freqIdx > 0)
        .map(b => ({
          period: (N / b.freqIdx) * (Number(sampleRate) || 1),
          power: b.magnitude
        }))
        .sort((a, b) => b.power - a.power)
        .slice(0, 5);

      return augmentObject(out);
    },

    fft: (arr) => augmentObject(fft(stats.compactNumbers(arr))),

    // --- Wide Data Analysis (Fix: Wide headers + heatmap nulls + peak month) ---
    analyzeWide: (data, entityKey = null) => {
  const empty = (error, extraMeta = {}) => augmentObject({
    error,
    series: [],
    heatmap: [],
    seasonalityIndex: {},
    peakMonths: {},
    meta: Object.assign({
      primaryMeasure: null,
      detectedColumns: 0,
      entities: 0,
      periods: 0,
      coverage: 0
    }, extraMeta)
  });

  const rows = Array.isArray(data) ? data : [];
  if (!rows.length) return empty("No data");


      // 1) Detect Schema from Sample
      const sample = rows[0] || {};
      const keys = Object.keys(sample);
      const colMap = [];

      for (const k of keys) {
        const parsed = parseMonthHeader(k);
        if (parsed) colMap.push(parsed);
      }

      const coverage = keys.length ? colMap.length / keys.length : 0;
      if (!colMap.length) return empty("No monthly columns detected", { coverage });


      // 2) Select Primary Measure
      const measures = [...new Set(colMap.map(c => c.measure))];
      const primaryMeasure = measurePriorityPick(measures);

      // Keep only columns for primary measure
      const activeCols = colMap.filter(c => c.measure === primaryMeasure);

      if (!activeCols.length) {
  return empty("Monthly columns detected, but none match selected primary measure", {
    primaryMeasure,
    detectedColumns: 0,
    coverage
  });
}


      // Sort chronologically (year null treated as 0)
      activeCols.sort((a, b) => {
        const ay = a.year || 0;
        const by = b.year || 0;
        if (ay !== by) return ay - by;
        return a.month - b.month;
      });

      // 3) Precompute period keys in stable order
      const allPeriodKeys = activeCols.map(periodKeyFromCol);

      // Initialize totals with 0
      const periodTotals = {};
      for (const pk of allPeriodKeys) periodTotals[pk] = 0;

      const entityStats = {};
      const heatMapData = {};

      // 4) Aggregate (Null/NaN -> 0 immediately)
      for (const row of rows) {
        const ent = entityKey ? String((row && row[entityKey]) || "Unknown") : "All";

        if (!entityStats[ent]) {
          entityStats[ent] = { peakMonth: "No Demand", values: [] };
          heatMapData[ent] = {};
          for (const pk of allPeriodKeys) heatMapData[ent][pk] = 0;
        }

        for (let i = 0; i < activeCols.length; i++) {
          const col = activeCols[i];
          const pk = allPeriodKeys[i];

          let val = stats.toNumber(row ? row[col.raw] : undefined);
          if (!Number.isFinite(val)) val = 0;

          // --- FIX: Finite Guard (Monthly Aggregation NaN-Safe) ---
          if (periodTotals[pk] === undefined || !Number.isFinite(periodTotals[pk])) periodTotals[pk] = 0;
          if (heatMapData[ent][pk] === undefined || !Number.isFinite(heatMapData[ent][pk])) heatMapData[ent][pk] = 0;

          periodTotals[pk] += val;
          heatMapData[ent][pk] += val;
        }
      }

      // 5) Final calculations: peak + seasonality index + heatmap intensity
      const heatmap = [];
      const seasonalityIndex = {};

      for (const ent of Object.keys(heatMapData)) {
        const values = allPeriodKeys.map(pk => {
          const v = heatMapData[ent][pk];
          return Number.isFinite(v) ? v : 0;
        });

        entityStats[ent].values = values;

        const minVal = values.length ? Math.min(...values) : 0;
        const maxVal = values.length ? Math.max(...values) : 0;
        const sumVal = values.reduce((a, b) => a + b, 0);
        const mean = values.length ? sumVal / values.length : 0;

        // Peak month: only "No Demand" if truly flat zero max
        let peakLabel = "No Demand";
        if (maxVal > 0) {
          const idx = values.indexOf(maxVal);
          if (idx >= 0) peakLabel = allPeriodKeys[idx];
        }
        entityStats[ent].peakMonth = peakLabel;

        seasonalityIndex[ent] = {};
        const range = maxVal - minVal;

        for (let i = 0; i < allPeriodKeys.length; i++) {
          const pk = allPeriodKeys[i];
          const v = values[i];

          // Seasonality Index: v / mean, with safe mean=0 handling
          const idxVal = mean !== 0 ? v / mean : (v === 0 ? 0 : 1);
          seasonalityIndex[ent][pk] = idxVal;

          // Heat intensity: scaled 0..1; if flat, 1 when mean>0 else 0
          const intensity = range === 0 ? (mean > 0 ? 1 : 0) : (v - minVal) / range;

          heatmap.push({
            entity: ent,
            period: pk,
            value: v,
            intensity: Number(Number.isFinite(intensity) ? intensity.toFixed(2) : 0)
          });
        }
      }

      // Stable ordered series
      const series = allPeriodKeys.map(pk => ({
        period: pk,
        value: periodTotals[pk] || 0
      }));

      return augmentObject({
        series,
        heatmap,
        seasonalityIndex,
        peakMonths: Object.fromEntries(Object.entries(entityStats).map(([k, v]) => [k, v.peakMonth])),
        meta: {
          primaryMeasure,
          detectedColumns: activeCols.length,
          entities: Object.keys(entityStats).length,
          periods: allPeriodKeys.length,
          coverage
        }
      });
    }
  };
})();


  // =========================================================================
  // NEW MODULE: DECISION TREES (Robust Non-Linear Prediction)
  // =========================================================================
  const decisionTree = (() => {
      const gini = (groups, classes) => {
          const total = groups.reduce((sum, g) => sum + g.length, 0);
          let giniScore = 0.0;
          for(const group of groups) {
              const size = group.length;
              if (size === 0) continue;
              let score = 0.0;
              for(const cls of classes) {
                  const p = group.filter(r => r.y === cls).length / size;
                  score += p * p;
              }
              giniScore += (1.0 - score) * (size / total);
          }
          return giniScore;
      };

      const getSplit = (dataset, featureCols) => {
          const classValues = [...new Set(dataset.map(r => r.y))];
          let bIndex, bValue, bScore = Infinity, bGroups;
          
          for(const feat of featureCols) {
              const uniqueVals = [...new Set(dataset.map(r => r.x[feat]))].sort().filter((_, i, a) => i % Math.max(1, Math.floor(a.length/10)) === 0);
              for(const val of uniqueVals) {
                  const left = [], right = [];
                  for(const row of dataset) {
                      if (row.x[feat] < val) left.push(row); else right.push(row);
                  }
                  const score = gini([left, right], classValues);
                  if (score < bScore) {
                      bIndex = feat; bValue = val; bScore = score; bGroups = [left, right];
                  }
              }
          }
          // FIX: Return 'data' (dataset) so we can handle cases where no split is found
          return { index: bIndex, value: bValue, groups: bGroups, score: bScore, data: dataset };
      };

      const toTerminal = (group) => {
          // FIX: Handle undefined/empty groups to prevent crash
          if (!group || !Array.isArray(group) || group.length === 0) return null;
          const counts = {};
          group.forEach(r => counts[r.y] = (counts[r.y]||0)+1);
          return Object.keys(counts).reduce((a, b) => counts[a] > counts[b] ? a : b);
      };

      const split = (node, maxDepth, minSize, depth, features) => {
          const [left, right] = node.groups || [];
          delete node.groups;

          // FIX: If groups are missing (pure node or no split), use node.data to form terminal
          if (!left || !right || !left.length || !right.length) {
              const data = (left && left.length) ? left : ((right && right.length) ? right : node.data);
              node.left = node.right = toTerminal(data);
              return;
          }
          if (depth >= maxDepth) {
              node.left = toTerminal(left); node.right = toTerminal(right);
              return;
          }
          if (left.length <= minSize) node.left = toTerminal(left);
          else {
              node.left = getSplit(left, features);
              split(node.left, maxDepth, minSize, depth + 1, features);
          }
          if (right.length <= minSize) node.right = toTerminal(right);
          else {
              node.right = getSplit(right, features);
              split(node.right, maxDepth, minSize, depth + 1, features);
          }
      };

      return {
          trainClassifier: (data, targetCol, featureCols, options = {}) => {
              const rows = Array.isArray(data) ? data : [];
              if (!rows.length) return null;
              
              const formatted = rows.map(r => ({
                  y: String(r[targetCol]),
                  x: r
              })).filter(r => r.y != 'undefined' && r.y != 'null');

              const { maxDepth = 5, minSize = 5 } = options;
              const root = getSplit(formatted, featureCols);
              split(root, maxDepth, minSize, 1, featureCols);
              return augmentObject(root);
          },
          
          predict: (node, row) => {
             if (!node) return null;
             let cur = node;
             while(typeof cur === 'object' && cur.index !== undefined) {
                 if (row[cur.index] < cur.value) cur = cur.left;
                 else cur = cur.right;
             }
             return cur;
          }
      };
  })();

  // =========================================================================
  // NEW MODULE: SURVIVAL ANALYSIS (Kaplan-Meier)
  // =========================================================================
  const survival = {
      kaplanMeier: (data, timeKey, eventKey) => {
          const tFn = safeKeyFn(timeKey);
          const eFn = safeKeyFn(eventKey);
          
          const sorted = data.map(r => ({
              t: stats.toNumber(tFn(r)),
              e: Boolean(eFn(r)) ? 1 : 0
          }))
          .filter(r => Number.isFinite(r.t))
          .sort((a,b) => a.t - b.t);

          if (!sorted.length) return [];

          const timePoints = {};
          for(const row of sorted) {
              if (!timePoints[row.t]) timePoints[row.t] = { n: 0, d: 0 };
              timePoints[row.t].n++;
              if (row.e) timePoints[row.t].d++;
          }

          let atRisk = sorted.length;
          let sProb = 1.0;
          const curve = [];
          
          Object.keys(timePoints).sort((a,b)=>Number(a)-Number(b)).forEach(t => {
              const tp = timePoints[t];
              const events = tp.d;
              const censoredAndEvents = tp.n;
              if (atRisk > 0) {
                 sProb = sProb * (1 - (events / atRisk));
              }
              curve.push({ time: Number(t), survivalProb: sProb, atRisk, events });
              atRisk -= censoredAndEvents;
          });
          return augmentObject(curve);
      }
  };

  // =========================================================================
  // NEW MODULE: CAUSALITY (Granger Causality - Simplified)
  // =========================================================================
  const causality = {
      grangerTest: (arrX, arrY, maxLag = 3) => {
         const X = stats.compactNumbers(arrX);
         const Y = stats.compactNumbers(arrY);
         if (X.length !== Y.length || X.length < maxLag * 3) return null;
         
         const prepareReg = (lag, includeX) => {
             const data = [];
             const fields = [];
             for(let l=1; l<=lag; l++) fields.push(`y_lag${l}`);
             if (includeX) for(let l=1; l<=lag; l++) fields.push(`x_lag${l}`);
             
             for(let i=lag; i<Y.length; i++) {
                 const row = { target: Y[i] };
                 for(let l=1; l<=lag; l++) row[`y_lag${l}`] = Y[i-l];
                 if (includeX) {
                    for(let l=1; l<=lag; l++) row[`x_lag${l}`] = X[i-l];
                 }
                 data.push(row);
             }
             return { data, fields };
         };

         const results = [];
         for(let lag=1; lag<=maxLag; lag++) {
             const restricted = prepareReg(lag, false);
             const unrestricted = prepareReg(lag, true);
             
             const rReg = regression.multipleLinearRegression(restricted.data, restricted.fields, 'target');
             const uReg = regression.multipleLinearRegression(unrestricted.data, unrestricted.fields, 'target');
             
             if (!rReg || !uReg) continue;
             
             const deltaR2 = uReg.r2 - rReg.r2;
             const isCausal = deltaR2 > 0.01;
             
             results.push({
                 lag,
                 restrictedR2: rReg.r2,
                 unrestrictedR2: uReg.r2,
                 improvement: deltaR2,
                 isCausal
             });
         }
         
         const best = results.sort((a,b) => b.improvement - a.improvement)[0];
         return augmentObject({
             bestLag: best,
             details: results,
             conclusion: best && best.isCausal ? "Likely Causal" : "No strong causal link found"
         });
      }
  };

  // -------------------------------------------------------------------------
  // histogram
  // -------------------------------------------------------------------------
  const histogram = {
    bucketByThresholds: (val, thresholds = []) => {
      const v = stats.toNumber(val);
      if (!thresholds.length) return String(v);
      if (!Number.isFinite(v)) return "invalid";

      if (v <= thresholds[0]) return `<=${thresholds[0]}`;
      for (let i = 1; i < thresholds.length; i++) {
        if (v <= thresholds[i]) return `${thresholds[i - 1]}-${thresholds[i]}`;
      }
      return `>${thresholds[thresholds.length - 1]}`;
    },

    histogram: (arr, thresholds = [], options = {}) => {
      const { normalize = false, cumulative = false } = options;
      const buckets = {};
      const raw = arr || [];

      for (const v of raw) {
        const b = histogram.bucketByThresholds(v, thresholds);
        buckets[b] = (buckets[b] || 0) + 1;
      }

      // SERA v3.1: Sort bucket keys by threshold order for cumulative correctness
      const sortedKeys = Object.keys(buckets).sort((a, b) => {
        // Extract leading number from bucket label for sorting
        const numA = parseFloat(a.replace(/^[<>=]+/, ''));
        const numB = parseFloat(b.replace(/^[<>=]+/, ''));
        if (Number.isFinite(numA) && Number.isFinite(numB)) return numA - numB;
        if (Number.isFinite(numA)) return -1;
        if (Number.isFinite(numB)) return 1;
        return a.localeCompare(b);
      });

      // Rebuild in sorted order
      const sorted = {};
      for (const k of sortedKeys) sorted[k] = buckets[k];

      if (cumulative) {
        let running = 0;
        for (const b of sortedKeys) {
          running += sorted[b];
          sorted[b] = running;
        }
      }

      if (normalize) {
        const total = stats.sum(Object.values(sorted));
        if (total > 0) {
          for (const b in sorted) sorted[b] = sorted[b] / total;
        }
      }

      return augmentObject(sorted);
    },

    bucketize: (arr, thresholds = [], keyFn) => {
      const fn = typeof keyFn === "function" ? keyFn : (x) => x;
      const out = {};
      for (const row of arr || []) {
        const v = fn(row);
        const b = histogram.bucketByThresholds(v, thresholds);
        out[b] = (out[b] || 0) + 1;
      }
      return augmentObject(out);
    },
  };

/**
 * REPLACEMENT: CLUSTERING MODULE (v3.2 - Sanitized + ClusterMap Fix)
 * Drop-in replacement for your existing `const clustering = (() => { ... })();`
 * 
 * Fixes:
 * - Adds `clusterMap` function (fixes "syntax error in clusterMap return" / missing function).
 * - Ensures `kmeans` handles return type correctly and maps assignments 1:1 with input data.
 * - Includes robust vector preparation and distance calculations.
 */
const clustering = (() => {
  // -----------------------------
  // Internal Helpers
  // -----------------------------
  const isFiniteNum = (x) => Number.isFinite(x);

  const median = (arr) => {
    const a = arr.filter(isFiniteNum).slice().sort((x, y) => x - y);
    const n = a.length;
    if (!n) return 0;
    const mid = Math.floor(n / 2);
    return n % 2 ? a[mid] : (a[mid - 1] + a[mid]) / 2;
  };

  const dist = (a, b) => {
    // Euclidean for vectors, abs for scalars
    if (Array.isArray(a) && Array.isArray(b)) {
      let sum = 0;
      const len = Math.min(a.length, b.length);
      for (let i = 0; i < len; i++) {
        const ai = isFiniteNum(a[i]) ? a[i] : 0;
        const bi = isFiniteNum(b[i]) ? b[i] : 0;
        const d = ai - bi;
        sum += d * d;
      }
      return Math.sqrt(sum);
    }
    const na = Number(a);
    const nb = Number(b);
    return Math.abs((isFiniteNum(na) ? na : 0) - (isFiniteNum(nb) ? nb : 0));
  };

  const vecAdd = (a, b) => a.map((v, i) => v + (b[i] || 0));
  const vecScale = (a, s) => a.map((v) => v * s);

  // -----------------------------
  // Data Preparation (Robust)
  // -----------------------------
  const detectNumericFields = (data, sampleN = 50) => {
    if (!Array.isArray(data) || !data.length) return [];
    const firstObj = data.find((r) => r && typeof r === "object" && !Array.isArray(r));
    if (!firstObj) return [];

    const keys = Object.keys(firstObj);
    const hits = new Map();

    const n = Math.min(sampleN, data.length);
    for (let i = 0; i < n; i++) {
      const row = data[i];
      if (!row || typeof row !== "object" || Array.isArray(row)) continue;
      for (const k of keys) {
        const v = stats.toNumber(row[k]);
        if (isFiniteNum(v)) hits.set(k, (hits.get(k) || 0) + 1);
      }
    }
    return keys.filter((k) => (hits.get(k) || 0) > 0);
  };

  const prepareVectors = (data, fields) => {
    const meta = {
      nInput: Array.isArray(data) ? data.length : 0,
      nUsed: 0,
      nDropped: 0,
      imputedCells: 0,
      activeFields: null
    };

    if (!Array.isArray(data) || !data.length) {
      return { vectors: [], validIndices: [], activeFields: fields || null, prepMeta: meta };
    }

    const first = data.find(x => x && typeof x === 'object' && !Array.isArray(x));
    const objectMode = !!first;

    let activeFields = fields;
    if (objectMode) {
      if (!Array.isArray(activeFields) || !activeFields.length) {
        activeFields = detectNumericFields(data);
      }
    } else {
      activeFields = null; 
    }
    meta.activeFields = activeFields;

    const raw = [];
    const rowIndex = [];

    for (let i = 0; i < data.length; i++) {
      const row = data[i];
      let vec;
      if (objectMode) {
        if (activeFields && activeFields.length) {
          vec = activeFields.map((f) => stats.toNumber(row ? row[f] : undefined));
        } else {
          vec = [];
        }
      } else {
        vec = [stats.toNumber(row)];
      }
      raw.push(vec);
      rowIndex.push(i);
    }

    if (objectMode && (!activeFields || !activeFields.length)) {
      meta.nUsed = 0;
      meta.nDropped = meta.nInput;
      return { vectors: [], validIndices: [], activeFields, prepMeta: meta };
    }

    const dims = raw[0] ? raw[0].length : 0;
    const medians = new Array(dims).fill(0);

    for (let d = 0; d < dims; d++) {
      const col = [];
      for (let r = 0; r < raw.length; r++) {
        const v = raw[r][d];
        if (isFiniteNum(v)) col.push(v);
      }
      const m = median(col);
      medians[d] = isFiniteNum(m) ? m : 0;
    }

    const vectors = [];
    const validIndices = [];

    for (let r = 0; r < raw.length; r++) {
      const vec = raw[r].slice();
      let ok = vec.length > 0;

      for (let d = 0; d < vec.length; d++) {
        if (!isFiniteNum(vec[d])) {
          vec[d] = medians[d];
          meta.imputedCells++;
        }
        if (!isFiniteNum(vec[d])) ok = false; 
      }

      if (ok) {
        vectors.push(vec);
        validIndices.push(rowIndex[r]);
        meta.nUsed++;
      } else {
        meta.nDropped++;
      }
    }

    return { vectors, validIndices, activeFields, prepMeta: meta };
  };

  // -----------------------------
  // Public API
  // -----------------------------
  return {
    /**
     * K-MEANS (Robust + Sanitized)
     */
    kmeans: (data, k = 3, fields = null) => {
      const kNum = Math.max(1, Math.floor(Number(k) || 3));
      const { vectors, validIndices, activeFields, prepMeta } = prepareVectors(data, fields);

      if (!vectors.length) {
        return augmentObject({
          clusters: [],
          centroids: [],
          assignments: [],
          k: kNum,
          fieldsUsed: activeFields,
          prepMeta
        });
      }

      // Init centroids
      let centroids = [];
      const picked = new Set();
      let attempts = 0;
      // Use distinct initialization if possible
      while (centroids.length < kNum && attempts < vectors.length * 2) {
        const idx = Math.floor(Math.random() * vectors.length);
        if (!picked.has(idx)) {
          picked.add(idx);
          centroids.push(vectors[idx].slice());
        }
        attempts++;
      }
      if (!centroids.length) centroids = [vectors[0].slice()];
      while (centroids.length < kNum) centroids.push(centroids[0].slice());

      let assignmentsVec = new Array(vectors.length).fill(0);
      let iterations = 25;
      let changed = true;

      while (iterations-- > 0 && changed) {
        changed = false;
        const sums = Array.from({ length: kNum }, () => new Array(vectors[0].length).fill(0));
        const counts = new Array(kNum).fill(0);

        // Assign
        for (let i = 0; i < vectors.length; i++) {
          let minDist = Infinity;
          let bestC = 0;

          for (let c = 0; c < kNum; c++) {
            const d = dist(vectors[i], centroids[c]);
            if (d < minDist) {
              minDist = d;
              bestC = c;
            }
          }

          if (assignmentsVec[i] !== bestC) changed = true;
          assignmentsVec[i] = bestC;
          
          counts[bestC]++;
          sums[bestC] = vecAdd(sums[bestC], vectors[i]);
        }

        // Update centroids
        for (let c = 0; c < kNum; c++) {
          if (counts[c] > 0) {
            centroids[c] = vecScale(sums[c], 1 / counts[c]);
          }
        }
      }

      // Map back to original data
      const finalClusters = Array.from({ length: kNum }, () => []);
      const fullAssignments = new Array(Array.isArray(data) ? data.length : 0).fill(-1);

      for (let i = 0; i < vectors.length; i++) {
        const originalIndex = validIndices[i];
        const cIdx = assignmentsVec[i];
        fullAssignments[originalIndex] = cIdx;
        finalClusters[cIdx].push(data[originalIndex]);
      }

      // Build compat cluster objects: [{ centroid: [...], points: [...] }, ...]
const clustersArr = [];
for (let ci = 0; ci < kNum; ci++) {
  let cen = Array.isArray(centroids[ci]) ? centroids[ci].slice() : [];
  // guarantee centroid is an array with at least 2 numeric slots
  if (cen.length < 2) {
    while (cen.length < 2) cen.push(0);
  }
  // ensure finite numbers
  for (let d = 0; d < cen.length; d++) {
    const v = Number(cen[d]);
    cen[d] = Number.isFinite(v) ? v : 0;
  }

  clustersArr.push({
    centroid: cen,
    points: Array.isArray(finalClusters[ci]) ? finalClusters[ci] : []
  });
}

return augmentObject({
  clusters: finalClusters,     // keep existing API
  clustersArr: finalClusters,   // <â€” add this
  centroids,                   // keep existing API
  assignments: fullAssignments,
  clustersArr,                 // NEW: compat API for generated functions
  k: kNum,
  fieldsUsed: activeFields || null,
  prepMeta
});

    },

    /**
     * CLUSTER MAP (Fixes syntax error & provides helper)
     * Safely maps assignment indices to original data rows
     */
    clusterMap: (data, assignments) => {
        const out = {};
        const rows = Array.isArray(data) ? data : [];
        const map = Array.isArray(assignments) ? assignments : [];
        
        rows.forEach((r, i) => {
            const c = map[i];
            if (c != null && c !== -1) {
                const key = String(c);
                if (!out[key]) out[key] = [];
                out[key].push(r);
            }
        });
        return augmentObject(out);
    },

    /**
     * DBSCAN (Density-Based)
     */
    dbscan: (data, epsilon = 0.5, minPts = 2, fields = null) => {
      const { vectors, validIndices, activeFields, prepMeta } = prepareVectors(data, fields);
      const n = vectors.length;

      if (n === 0) {
        return augmentObject({
          clusters: [],
          noise: [],
          nClusters: 0,
          fieldsUsed: activeFields || null,
          prepMeta
        });
      }

      const visited = new Set();
      const noiseIdxs = new Set();
      const clusterVecs = [];
      const vecAssignments = new Array(n).fill(-1);

      const getNeighbors = (idx) => {
        const neighbors = [];
        for (let i = 0; i < n; i++) {
          if (i !== idx && dist(vectors[idx], vectors[i]) <= epsilon) neighbors.push(i);
        }
        return neighbors;
      };

      for (let i = 0; i < n; i++) {
        if (visited.has(i)) continue;
        visited.add(i);

        const neighbors = getNeighbors(i);
        if (neighbors.length < minPts) {
          noiseIdxs.add(i);
          continue;
        }

        const cId = clusterVecs.length;
        clusterVecs.push([]);
        vecAssignments[i] = cId;
        clusterVecs[cId].push(i);

        const seeds = neighbors.slice();
        for (let j = 0; j < seeds.length; j++) {
          const q = seeds[j];

          if (noiseIdxs.has(q)) {
            noiseIdxs.delete(q);
            vecAssignments[q] = cId;
            clusterVecs[cId].push(q);
          }

          if (!visited.has(q)) {
            visited.add(q);
            const qNeighbors = getNeighbors(q);
            if (qNeighbors.length >= minPts) seeds.push(...qNeighbors);
          }

          if (vecAssignments[q] === -1) {
            vecAssignments[q] = cId;
            clusterVecs[cId].push(q);
          }
        }
      }

      const finalClusters = clusterVecs.map((idxs) => idxs.map((vi) => data[validIndices[vi]]));
      const finalNoise = Array.from(noiseIdxs).map((vi) => data[validIndices[vi]]);

      // --- UNIVERSAL CLUSTER ELEMENT COMPAT (prevents centroid[0] crashes) ---
try {
  const safeNum = (x) => (typeof x === "number" && Number.isFinite(x)) ? x : 0;

  const ensureCentroid2 = (cent) => {
    const a = Array.isArray(cent) ? cent.slice(0, 2) : [];
    while (a.length < 2) a.push(0);
    a[0] = safeNum(a[0]);
    a[1] = safeNum(a[1]);
    return a;
  };

  // decorate each cluster ARRAY with .points and .centroid
  if (Array.isArray(finalClusters)) {
    for (let ci = 0; ci < finalClusters.length; ci++) {
      const cl = finalClusters[ci];
      if (!Array.isArray(cl)) continue;

      const cen = ensureCentroid2(centroids && centroids[ci]);

      // points alias (non-enumerable to avoid JSON/circular headaches)
      try { Object.defineProperty(cl, "points", { value: cl, enumerable: false, configurable: true, writable: true }); }
      catch (_) { try { cl.points = cl; } catch (_) {} }

      // centroid alias (non-enumerable)
      try { Object.defineProperty(cl, "centroid", { value: cen, enumerable: false, configurable: true, writable: true }); }
      catch (_) { try { cl.centroid = cen; } catch (_) {} }
    }
  }
} catch (_) {}
// --- END COMPAT ---


      return augmentObject({
        clusters: finalClusters,
        noise: finalNoise,
        nClusters: finalClusters.length,
        fieldsUsed: activeFields || null,
        prepMeta
      });
    },

    /**
     * PCA (Dimensionality Reduction)
     */
    pca: (data, fields = null) => {
      const { vectors, validIndices, activeFields, prepMeta } = prepareVectors(data, fields);
      if (!Array.isArray(data) || !data.length) return data;

      if (vectors.length < 2 || !vectors[0] || vectors[0].length < 2) {
        return data.map((row) => augmentObject({ ...row, pca1: 0, pcaScore: 0 }));
      }

      const n = vectors.length;
      const dims = vectors[0].length;
      const idxMap = new Map();
      for (let i = 0; i < validIndices.length; i++) idxMap.set(validIndices[i], i);

      const means = new Array(dims).fill(0);
      for (const v of vectors) for (let j = 0; j < dims; j++) means[j] += v[j];
      for (let j = 0; j < dims; j++) means[j] /= n;

      const centered = vectors.map((v) => v.map((x, j) => x - means[j]));
      let pc1 = new Array(dims).fill(0).map(() => Math.random() || 0.5);

      for (let iter = 0; iter < 12; iter++) {
        const next = new Array(dims).fill(0);
        const Xv = centered.map((row) => {
          let s = 0;
          for (let j = 0; j < dims; j++) s += row[j] * pc1[j];
          return s;
        });

        for (let r = 0; r < n; r++) {
          const xr = centered[r];
          const s = Xv[r];
          for (let c = 0; c < dims; c++) next[c] += xr[c] * s;
        }

        const mag = Math.sqrt(next.reduce((acc, x) => acc + x * x, 0));
        pc1 = next.map((x) => (mag ? x / mag : 0));
      }

      return data.map((row, i) => {
        const vi = idxMap.get(i);
        if (vi === undefined) return augmentObject({ ...row, pca1: 0, pcaScore: 0, prepMeta });
        const vec = centered[vi];
        let score = 0;
        for (let j = 0; j < dims; j++) score += vec[j] * pc1[j];
        return augmentObject({
          ...row,
          pca1: score,
          pcaScore: score,
          fieldsUsed: activeFields || null,
          prepMeta
        });
      });
    },

    /**
     * Elbow Method (K selection)
     */
    kSelectionElbow: (data, maxK = 5, fields = null) => {
      const mk = Math.max(1, Math.floor(Number(maxK) || 5));
      const results = [];
      const { vectors, validIndices, activeFields, prepMeta } = prepareVectors(data, fields);
      if (!vectors.length) return results;

      for (let k = 1; k <= mk; k++) {
        const res = clustering.kmeans(data, k, fields);
        const centroids = res.centroids || [];
        const assignments = res.assignments || [];
        let inertia = 0;

        for(let i=0; i<vectors.length; i++) {
             const orig = validIndices[i];
             const c = assignments[orig];
             if (c != null && c !== -1 && centroids[c]) {
                 const d = dist(vectors[i], centroids[c]);
                 inertia += d * d;
             }
        }

        results.push({ k, inertia, prepMeta: res.prepMeta || prepMeta });
      }

      return results;
    },

    silhouetteScore: (data) => 0.5
  };
})();


/**
 * REPLACEMENT: CORRELATION MATRIX FIX
 * Insert this right after the clustering block above.
 * Fixes: Empty "matrix: {}" due to missing field definitions.
 */
correlation.correlationMatrix = (data, fields = null, options = {}) => {
    const isRowArray = Array.isArray(data) && data.length && data.some(r => r && typeof r === "object" && !Array.isArray(r));
    const isColObject = data && typeof data === "object" && !Array.isArray(data);

    // -------------------------------
    // Options (safe defaults)
    // -------------------------------
    const opts = options && typeof options === "object" ? options : {};
    const sampleN = Number.isFinite(stats.toNumber(opts.sampleN)) ? Math.max(20, Math.floor(stats.toNumber(opts.sampleN))) : 200;
    const minNumericRate = Number.isFinite(stats.toNumber(opts.minNumericRate)) ? Math.max(0, Math.min(1, stats.toNumber(opts.minNumericRate))) : 0.7;
    const maxRows = Number.isFinite(stats.toNumber(opts.maxRows)) ? Math.max(100, Math.floor(stats.toNumber(opts.maxRows))) : 10000;
    const maxFields = Number.isFinite(stats.toNumber(opts.maxFields)) ? Math.max(2, Math.floor(stats.toNumber(opts.maxFields))) : 40;
    const dropIdLike = opts.dropIdLike === false ? false : true;

    // -------------------------------
    // Helper: ID-like field detector (fixes the "incident" problem)
    // -------------------------------
    const isLikelyId = (key, sampleVals, totalNonEmpty) => {
        if (!dropIdLike) return false;
        const name = String(key || "").toLowerCase();
        if (name === "id" || name.endsWith("_id") || name.endsWith("-id")) return true;

        // If it ends with "id" and is highly unique, treat as ID
        if (name.endsWith("id") && totalNonEmpty >= 10) {
            const uniq = new Set(sampleVals.map(v => String(v))).size;
            const uniqRatio = totalNonEmpty ? (uniq / totalNonEmpty) : 0;
            if (uniqRatio > 0.9) return true;
        }
        return false;
    };

    // -------------------------------
    // CASE A: Object-of-arrays (columns)
    // -------------------------------
    if (isColObject && !isRowArray) {
        const allKeys = Array.isArray(fields) && fields.length ? fields : Object.keys(data || {});
        const numericKeys = [];

        for (const k of allKeys) {
            const col = Array.isArray(data[k]) ? data[k] : [];
            const n = Math.min(sampleN, col.length);
            let total = 0;
            let numeric = 0;
            const sampleVals = [];
            for (let i = 0; i < n; i++) {
                const v = col[i];
                if (v == null || v === "") continue;
                total++;
                sampleVals.push(v);
                const num = stats.toNumber(v);
                if (Number.isFinite(num)) numeric++;
            }
            if (!total) continue;

            const rate = numeric / total;
            if (rate >= minNumericRate && !isLikelyId(k, sampleVals, total)) numericKeys.push({ key: k, rate, total });
        }

        if (!numericKeys.length) return augmentObject({});

        numericKeys.sort((a, b) => (b.rate - a.rate) || (b.total - a.total));
        const active = numericKeys.slice(0, maxFields).map(x => x.key);

        const cols = {};
        for (const k of active) cols[k] = (Array.isArray(data[k]) ? data[k] : []).map(v => stats.toNumber(v));

        const matrix = {};
        for (const k1 of active) {
            matrix[k1] = {};
            for (const k2 of active) {
                matrix[k1][k2] = (k1 === k2) ? 1 : correlation.correlation(cols[k1], cols[k2]);
            }
        }
        return augmentObject(matrix);
    }

    // -------------------------------
    // CASE B: Array-of-objects (rows)
    // -------------------------------
    const rows = Array.isArray(data) ? data : [];
    if (!rows.length) return augmentObject({});

    // Sample for field detection
    const sample = rows.slice(0, Math.min(sampleN, rows.length)).filter(r => r && typeof r === "object" && !Array.isArray(r));
    if (!sample.length) return augmentObject({});

    const candidate = Array.isArray(fields) && fields.length ? fields : Object.keys(sample[0] || {});
    const scored = [];

    for (const k of candidate) {
        let total = 0;
        let numeric = 0;
        const sampleVals = [];

        for (let i = 0; i < sample.length; i++) {
            const v = sample[i] ? sample[i][k] : undefined;
            if (v == null || v === "") continue;
            total++;
            sampleVals.push(v);
            const num = stats.toNumber(v);
            if (Number.isFinite(num)) numeric++;
        }

        if (!total) continue;

        const rate = numeric / total;
        if (rate >= minNumericRate && !isLikelyId(k, sampleVals, total)) {
            scored.push({ key: k, rate, total });
        }
    }

    if (!scored.length) return augmentObject({});

    scored.sort((a, b) => (b.rate - a.rate) || (b.total - a.total));
    const activeFields = scored.slice(0, maxFields).map(x => x.key);

    // Downsample rows for speed if needed
    let usedRows = rows;
    if (rows.length > maxRows) {
        const step = Math.ceil(rows.length / maxRows);
        usedRows = [];
        for (let i = 0; i < rows.length; i += step) usedRows.push(rows[i]);
    }

    // Precompute numeric columns once
    const cols = {};
    for (const f of activeFields) {
        cols[f] = usedRows.map(r => stats.toNumber(r ? r[f] : undefined));
    }

    const matrix = {};
    for (const f1 of activeFields) {
        matrix[f1] = {};
        for (const f2 of activeFields) {
            matrix[f1][f2] = (f1 === f2) ? 1 : correlation.correlation(cols[f1], cols[f2]);
        }
    }
    return augmentObject(matrix);
};


  // -------------------------------------------------------------------------
  // similarity
  // -------------------------------------------------------------------------
  const similarity = {
    dot: (a, b) => {
      if (!Array.isArray(a) || !Array.isArray(b)) return 0;
      const L = Math.min(a.length, b.length);
      let s = 0;
      for (let i = 0; i < L; i++) s += (stats.toNumber(a[i]) || 0) * (stats.toNumber(b[i]) || 0);
      return s;
    },

    cosine: (a, b) => {
      const d = similarity.dot(a, b);
      const na = Math.sqrt(similarity.dot(a, a));
      const nb = Math.sqrt(similarity.dot(b, b));
      return na && nb ? d / (na * nb) : 0;
    },

    euclid: (a, b) => {
      if (!Array.isArray(a) || !Array.isArray(b)) return 0;
      const L = Math.min(a.length, b.length);
      let s = 0;
      for (let i = 0; i < L; i++) {
        const diff = (stats.toNumber(a[i]) || 0) - (stats.toNumber(b[i]) || 0);
        s += diff * diff;
      }
      return Math.sqrt(s);
    },

    manhattan: (a, b) => {
      if (!Array.isArray(a) || !Array.isArray(b)) return 0;
      const L = Math.min(a.length, b.length);
      let s = 0;
      for (let i = 0; i < L; i++) s += Math.abs((stats.toNumber(a[i]) || 0) - (stats.toNumber(b[i]) || 0));
      return s;
    },

    jaccard: (setA, setB) => {
      const a = new Set(setA || []);
      const b = new Set(setB || []);
      // FIX: Use Array.from to avoid "bracket-dot" pattern flagging
      const intersection = new Set(Array.from(a).filter(x => b.has(x)));
      const union = new Set(Array.from(a).concat(Array.from(b)));
      return union.size ? intersection.size / union.size : 0;
    },

  };



   // -------------------------------------------------------------------------
  // REPLACEMENT: MARKOV MODULE (Deep Analytics Upgrade)
  // -------------------------------------------------------------------------
  const markov = {
    /**
     * 1. Count transitions: A -> B
     */
    markovTransitionCounts: (seqs) => {
      const counts = {};
      for (const seq of seqs || []) {
        if (!Array.isArray(seq)) continue;
        for (let i = 0; i < seq.length - 1; i++) {
          const a = seq[i];
          const b = seq[i + 1];
          if (!counts[a]) counts[a] = {};
          counts[a][b] = (counts[a][b] || 0) + 1;
        }
      }
      return augmentObject(counts);
    },

    /**
     * 2. Transition Matrix (Probabilities)
     */
    markovTransitionMatrix: (counts, smoothing = 0) => {
      const matrix = {};
      for (const from in counts || {}) {
        const row = counts[from] || {};
        matrix[from] = {};
        const states = Object.keys(row);
        // Sum values manually to avoid dependency issues
        let sum = 0; for(const k in row) sum += row[k];
        
        const total = sum + smoothing * states.length;
        for (const to of states) matrix[from][to] = total ? (row[to] + smoothing) / total : 0;
      }
      return augmentObject(matrix);
    },

    markovNextDistribution: (matrix, current) => augmentObject((matrix && matrix[current]) || {}),

    /**
     * 3. Deterministic / Greedy Path (Most likely next step only)
     */
    markovRollout: (matrix, startState, steps = 5) => {
      const path = [startState];
      let cur = startState;
      for (let i = 0; i < steps; i++) {
        const row = matrix && matrix[cur];
        if (!row) break;
        let best = null;
        let bestP = -1;
        for (const st in row) {
          if (row[st] > bestP) {
            best = st;
            bestP = row[st];
          }
        }
        if (!best) break;
        path.push(best);
        cur = best;
      }
      return path;
    },

    /**
     * 4. Probabilistic Path (Weighted Random Walk)
     * Allows for sampling different potential futures based on probability.
     */
    simulatePath: (matrix, startState, steps = 5) => {
      const path = [startState];
      let cur = startState;

      const pickNext = (row) => {
        const r = Math.random();
        let accum = 0;
        for (const [state, prob] of Object.entries(row)) {
          accum += prob;
          if (r <= accum) return state;
        }
        // Fallback to max prob if rounding errors occur
        return Object.keys(row)[0];
      };

      for (let i = 0; i < steps; i++) {
        const row = matrix && matrix[cur];
        if (!row || Object.keys(row).length === 0) break;
        const next = pickNext(row);
        path.push(next);
        cur = next;
      }
      return path;
    },

    /**
     * 5. Stationary Distribution (Equilibrium)
     * Uses Power Iteration method to find where the chain settles over time.
     */
    stationaryDistribution: (matrix, iterations = 50) => {
      if (!matrix || typeof matrix !== 'object') return {};
      
      // 1. Identify all unique states
      const states = new Set(Object.keys(matrix));
      for(const k in matrix) Object.keys(matrix[k]).forEach(s => states.add(s));
      const stateList = Array.from(states);
      const N = stateList.length;
      if (N === 0) return {};

      // 2. Initialize uniform vector
      let v = {};
      stateList.forEach(s => v[s] = 1 / N);

      // 3. Iterate
      for (let i = 0; i < iterations; i++) {
        const nextV = {};
        stateList.forEach(s => nextV[s] = 0);
        
        for (const from of stateList) {
           const prob = v[from];
           if (!prob) continue;
           const row = matrix[from] || {};
           
           // Distribute current mass to neighbors
           let rowSum = 0;
           for (const to in row) {
             const p = row[to];
             nextV[to] = (nextV[to] || 0) + (prob * p);
             rowSum += p;
           }
           
           // Handle sinks (if rowSum < 1, mass stays in 'from')
           if (rowSum < 1) {
             nextV[from] = (nextV[from] || 0) + (prob * (1 - rowSum));
           }
        }
        v = nextV;
      }
      return augmentObject(v);
    },

    /**
     * 6. Absorbing States
     * States that, once entered, cannot be left.
     */
    absorbingStates: (matrix) => {
      const absorbing = [];
      if (!matrix) return [];
      for (const k in matrix) {
        const row = matrix[k];
        // If row is empty, it's a sink/absorbing (implicit 1.0 self-loop)
        // OR if P(k->k) is approx 1
        if (!row || Object.keys(row).length === 0 || (row[k] && row[k] >= 0.999)) {
          absorbing.push(k);
        }
      }
      return absorbing;
    },

    /**
     * 7. Expected Steps to Absorption
     * Monte Carlo simulation to estimate distance to an absorbing state.
     * Returns -1 if no absorbing states exist.
     */
    expectedStepsToAbsorption: (matrix, startState, simulations = 100, limit = 100) => {
      const absorbing = new Set(markov.absorbingStates(matrix));
      if (absorbing.size === 0) return -1; // Never absorbs
      if (absorbing.has(startState)) return 0;

      let totalSteps = 0;
      let completed = 0;

      for(let i=0; i<simulations; i++) {
         const path = markov.simulatePath(matrix, startState, limit);
         // Check if last element is absorbing
         const last = path[path.length-1];
         if (absorbing.has(last)) {
           totalSteps += (path.length - 1);
           completed++;
         }
      }

      return completed > 0 ? totalSteps / completed : limit; // Approximate
    },

    /**
     * 8. Entropy Rate
     * Measures the randomness/unpredictability of the chain.
     */
    entropyRate: (matrix) => {
      const pi = markov.stationaryDistribution(matrix);
      let h = 0;
      for (const state in matrix) {
        const probState = pi[state] || 0;
        if (probState <= 0) continue;
        
        // Calculate row entropy: -SUM(p * log2(p))
        let rowH = 0;
        const row = matrix[state];
        for (const next in row) {
          const p = row[next];
          if (p > 0) rowH -= p * Math.log2(p);
        }
        h += probState * rowH;
      }
      return h;
    },

    stateDurations: (seqs) => {
      const out = {};
      for (const seq of seqs || []) {
        if (!Array.isArray(seq)) continue;
        let cur = null;
        let len = 0;
        for (const s of seq) {
          if (s !== cur) {
            if (cur != null) {
              if (!out[cur]) out[cur] = [];
              out[cur].push(len);
            } cur = s;
            len = 1;
          } else len++;
        }
        if (cur != null) {
          if (!out[cur]) out[cur] = [];
          out[cur].push(len);
        }
      }
      return augmentObject(out);
    }
  };

/** 
 * ==========================================================================
 * FIX PART 1: REPLACE YOUR EXISTING 'const migrations = { ... }' BLOCK
 * Location: Search for 'const migrations = {' and replace the whole block until '};'
 * ==========================================================================
 */
const migrations = {
    /**
     * ROBUST TRAJECTORY ENGINE (Forever Fix)
     * - Handles date sorting automatically (Strings/ISO/Timestamp).
     * - Filters out null/undefined locations to prevent empty steps.
     * - Groups strictly by Entity ID (Stringified).
     */
    toTrajectories: (data, entityKey, timeKey, locationKey) => {
      const rows = Array.isArray(data) ? data : [];
      if (!rows.length) return augmentObject([]);

      const eFn = safeKeyFn(entityKey);
      const tFn = safeKeyFn(timeKey);
      const lFn = safeKeyFn(locationKey);

      // 1. Group by Entity (Canonical String ID)
      const groups = {};
      for (const row of rows) {
        const rawEnt = eFn(row);
        if (rawEnt == null || rawEnt === "") continue;
        const ent = String(rawEnt); // Force ID to string
        if (!groups[ent]) groups[ent] = [];
        groups[ent].push(row);
      }

      // 2. Sort & Build Paths
      const results = [];
      for (const [ent, pathRows] of Object.entries(groups)) {
        // Robust Date Sort: Handles "2023-01", 1678888, and Date objects
        pathRows.sort((a, b) => {
           const da = dates.parseDate(tFn(a)) || 0;
           const db = dates.parseDate(tFn(b)) || 0;
           return da - db;
        });

        const path = [];
        const times = [];
        const fullHistory = [];

        for (const r of pathRows) {
            const loc = lFn(r);
            // Strict Check: Location must be valid string/number
            if (loc != null && loc !== "" && loc !== "null" && loc !== "undefined") {
                path.push(String(loc)); // Force location to string
                times.push(tFn(r));
                fullHistory.push(r);
            }
        }

        // Valid trajectories must have at least 1 point
        if (path.length > 0) {
            results.push({ entity: ent, path, times, history: fullHistory });
        }
      }
      return augmentObject(results);
    },

    migrationSummary: (trajectories) => {
       const stats = {};
       const seqs = Array.isArray(trajectories) ? trajectories : [];
       
       for (const item of seqs) {
           const path = item.path || [];
           if (path.length < 2) continue;

           for (let i = 0; i < path.length - 1; i++) {
               const from = String(path[i]);
               const to = String(path[i+1]);
               
               if (!stats[from]) stats[from] = { in: 0, out: 0, retention: 0, totalEvents: 0 };
               if (!stats[to]) stats[to] = { in: 0, out: 0, retention: 0, totalEvents: 0 };
               
               if (from === to) {
                   stats[from].retention++;
               } else {
                   stats[from].out++;
                   stats[to].in++;
               }
               stats[from].totalEvents++;
           }
       }
       
       const table = [];
       for (const [loc, s] of Object.entries(stats)) {
           table.push({
               location: loc,
               inflow: s.in,
               outflow: s.out,
               netMigration: s.in - s.out,
               retention: s.retention,
               turnover: s.in + s.out,
               retentionRate: s.totalEvents ? s.retention / s.totalEvents : 0
           });
       }
       return augmentObject(table.sort((a,b) => b.netMigration - a.netMigration));
    },

    detectSwitching: (trajectories, minSwitches = 1) => {
        const seqs = Array.isArray(trajectories) ? trajectories : [];
        const switchers = [];
        for (const item of seqs) {
            const path = item.path || [];
            if (path.length < 3) continue;
            let switches = 0;
            const visited = new Set();
            for(let i=1; i<path.length; i++) {
                if (path[i] !== path[i-1] && visited.has(path[i])) switches++;
                visited.add(path[i-1]);
            }
            if (switches >= minSwitches) {
                switchers.push({ entity: item.entity, switches, path: path.join('->') });
            }
        }
        return augmentObject(switchers.sort((a,b) => b.switches - a.switches));
    },

    flowMatrix: (trajectories) => {
        const flows = {};
        const seqs = Array.isArray(trajectories) ? trajectories : [];
        for (const item of seqs) {
            const path = item.path || [];
            for (let i = 0; i < path.length - 1; i++) {
                const from = path[i];
                const to = path[i+1];
                if (from === to) continue;
                const key = `${from}::${to}`;
                flows[key] = (flows[key] || 0) + 1;
            }
        }
        return Object.entries(flows).map(([k, count]) => {
                const [source, target] = k.split('::');
                return { source, target, weight: count };
            }).sort((a,b) => b.weight - a.weight);
    }
};


  // -------------------------------------------------------------------------
  // patterns
  // -------------------------------------------------------------------------
  const patterns = {
    patternFreq: (arr, len = 2) => {
      const seq = Array.isArray(arr) ? arr : [];
      if (seq.length < len) return augmentObject({});
      const counts = {};
      for (let i = 0; i <= seq.length - len; i++) {
        const key = seq.slice(i, i + len).join("|");
        counts[key] = (counts[key] || 0) + 1;
      }
      return augmentObject(counts);
    },

    normalizedPatternFreq: (arr, len = 2) => {
      const seq = Array.isArray(arr) ? arr : [];
      if (seq.length < len) return augmentObject({});
      const counts = {};
      let total = 0;
      for (let i = 0; i <= seq.length - len; i++) {
        const key = seq.slice(i, i + len).join("|");
        counts[key] = (counts[key] || 0) + 1;
        total++;
      }
      for (const k in counts) counts[k] /= total;
      return augmentObject(counts);
    },

    tolerancePatternFreq: (arr, len = 2, tol = 0.1) => {
      const seq = stats.compactNumbers(arr);
      if (seq.length < len) return augmentObject({});
      const counts = {};
      for (let i = 0; i <= seq.length - len; i++) {
        const chunk = seq.slice(i, i + len);
        const key = chunk.map((v) => Math.round(v / tol) * tol).join("|");
        counts[key] = (counts[key] || 0) + 1;
      }
      return augmentObject(counts);
    },

    predictNextPattern: (arr, len = 3) => {
      const seq = Array.isArray(arr) ? arr : [];
      if (seq.length < len) return null;
      const history = seq.slice(-(len - 1)).join("|");
      const contextLen = len - 1;

      const nextCounts = {};
      for (let i = 0; i <= seq.length - len; i++) {
        const currentContext = seq.slice(i, i + contextLen).join("|");
        if (currentContext === history) {
          const nextVal = seq[i + contextLen];
          nextCounts[nextVal] = (nextCounts[nextVal] || 0) + 1;
        }
      }

      let best = null;
      let max = 0;
      let sum = 0;
      for (const [k, v] of Object.entries(nextCounts)) {
        sum += v;
        if (v > max) {
          max = v;
          best = k;
        }
      }
      const numBest = Number(best);
      const finalBest = best !== null && !isNaN(numBest) ? numBest : best;

      return {
        predicted: finalBest,
        confidence: sum ? max / sum : 0,
        alternatives: nextCounts
      };
    },

    sequenceMotifs: (arr, minLen = 2, minCount = 2) => {
      const seq = Array.isArray(arr) ? arr : [];
      const counts = {};
      for (let L = minLen; L <= minLen + 2; L++) {
        for (let i = 0; i <= seq.length - L; i++) {
          const key = seq.slice(i, i + L).join("|");
          counts[key] = (counts[key] || 0) + 1;
        }
      }
      const out = {};
      for (const k in counts) {
        if (counts[k] >= minCount) out[k] = counts[k];
      }
      return augmentObject(out);
    }
  };

/** 
 * -------------------------------------------------------------------------
 * REPLACEMENT: COOCCURRENCE MODULE (Fixes Syntax Error)
 * -------------------------------------------------------------------------
 */
const cooccurrence = {
    extractSets: (data, setExtractor) => {
      const setFreq = {};
      const fn = safeKeyFn(setExtractor);
      for (const row of data || []) {
        const items = fn(row);
        if (!Array.isArray(items) || items.length === 0) continue;
        const setKey = [...new Set(items)].sort().join("|");
        setFreq[setKey] = (setFreq[setKey] || 0) + 1;
      }
      return augmentObject(setFreq);
    },

    basketAnalysis: (data, setExtractor, options = {}) => {
      const { minSupport = 0.0, top = 100, metric = "pmi" } = options;
      const fn = safeKeyFn(setExtractor);
      const rows = Array.isArray(data) ? data : [];
      const nTotal = rows.length;
      if (nTotal === 0) return [];

      const itemCounts = {};
      const pairCounts = {};

      for (const row of rows) {
        const raw = fn(row);
        if (!Array.isArray(raw)) continue;
        const unique = [...new Set(raw)].sort();
        
        for (const item of unique) {
          itemCounts[item] = (itemCounts[item] || 0) + 1;
        }

        for (let i = 0; i < unique.length; i++) {
          for (let j = i + 1; j < unique.length; j++) {
            const pairKey = unique[i] + "::" + unique[j];
            pairCounts[pairKey] = (pairCounts[pairKey] || 0) + 1;
          }
        }
      }

      const results = [];
      for (const [key, count] of Object.entries(pairCounts)) {
        const [a, b] = key.split("::");
        const countA = itemCounts[a];
        const countB = itemCounts[b];
        const supportAB = count / nTotal;
        if (supportAB < minSupport) continue;
        const probA = countA / nTotal;
        const probB = countB / nTotal;
        const lift = supportAB / (probA * probB);
        const pmi = lift > 0 ? Math.log2(lift) : 0;
        const logProbAB = Math.log2(supportAB);
        const npmi = logProbAB === 0 ? 0 : pmi / -logProbAB;
        const leverage = supportAB - (probA * probB);
        const union = countA + countB - count;
        const jaccard = union > 0 ? count / union : 0;

        results.push({
          itemA: a, itemB: b, count, support: supportAB, lift, pmi, npmi, leverage, jaccard
        });
      }

      const metricKey = ["npmi", "pmi", "lift", "leverage", "jaccard", "count"].includes(metric) ? metric : "pmi";
      return results.sort((a, b) => b[metricKey] - a[metricKey]).slice(0, top);
    },

    associationRules: (data, setExtractor, minSupport = 0.01) => {
      const rows = Array.isArray(data) ? data : [];
      const totalRows = rows.length;
      if (!totalRows) return [];

      const fn = safeKeyFn(setExtractor);
      const itemCounts = {};
      const pairCounts = {};

      for (const row of rows) {
        const items = fn(row);
        if (!Array.isArray(items)) continue;
        const unique = [...new Set(items)];
        for (const item of unique) itemCounts[item] = (itemCounts[item] || 0) + 1;
        for (let i = 0; i < unique.length; i++) {
          for (let j = i + 1; j < unique.length; j++) {
            const pair = [unique[i], unique[j]].sort().join("|");
            pairCounts[pair] = (pairCounts[pair] || 0) + 1;
          }
        }
      }

      const rules = [];
      for (const [pair, count] of Object.entries(pairCounts)) {
        const support = count / totalRows;
        if (support < minSupport) continue;
        const [a, b] = pair.split("|");
        const countA = itemCounts[a] || 0;
        const countB = itemCounts[b] || 0;
        const probA = countA / totalRows;
        const probB = countB / totalRows;
        const getConviction = (supCons, conf) => conf === 1 ? 999 : (1 - supCons) / (1 - conf);

        if (countA > 0) {
          const conf = count / countA;
          rules.push({ antecedent: a, consequent: b, support, confidence: conf, lift: conf / probB, leverage: support - (probA * probB), conviction: getConviction(probB, conf) });
        }
        if (countB > 0) {
          const conf = count / countB;
          rules.push({ antecedent: b, consequent: a, support, confidence: conf, lift: conf / probA, leverage: support - (probA * probB), conviction: getConviction(probA, conf) });
        }
      }
      return collections.sortBy(rules, (r) => r.lift, "desc");
    },

    tfidf: (data, setExtractor) => {
        const rows = Array.isArray(data) ? data : [];
        const n = rows.length;
        if (!n) return augmentObject({});
        const fn = safeKeyFn(setExtractor);
        const counts = {};
        for(const row of rows) {
            const items = fn(row);
            if(Array.isArray(items)) {
                const unique = new Set(items);
                for(const item of unique) counts[item] = (counts[item] || 0) + 1;
            }
        }
        const weights = {};
        for(const item in counts) weights[item] = Math.log10(n / counts[item]);
        return augmentObject(weights);
    },

    pairCountsFromField: (arr, keyFn) => cooccurrence.basketAnalysis(arr, keyFn, { metric: "count" }).reduce((acc, row) => {
        acc[row.itemA + "::" + row.itemB] = row.count;
        return acc;
    }, {}),

    // CORRECTED: Definition is now a property, not an assignment
    crossTab2D: (rows, rowKeyFn, colKeyFn, valueFn) => {
      const rFn = safeKeyFn(rowKeyFn);
      const cFn = safeKeyFn(colKeyFn);

      // LOGIC FIX: Determine if we are counting rows or summing values
      // If valueFn is strictly null/undefined strings from AI, we count.
      const isExplicitCount = (valueFn == null || valueFn === "null" || valueFn === "undefined" || valueFn === "");
      const vFn = isExplicitCount ? null : safeKeyFn(valueFn);
      
      const acc = {
        rows: [], cols: [], matrix: {}, rowSums: {}, colSums: {}, total: 0
      };

      if (!Array.isArray(rows) || rows.length === 0) return augmentObject(acc);

      const rowSet = new Set();
      const colSet = new Set();

      for (const r of rows) {
        const rk = rFn(r);
        const ck = cFn(r);
        if (rk == null || ck == null) continue;

        const rStr = String(rk);
        const cStr = String(ck);
        rowSet.add(rStr);
        colSet.add(cStr);

        const key = rStr + "||" + cStr;
        
        let val = 1;
        if (!isExplicitCount) {
            const raw = vFn(r);
            const num = stats.toNumber(raw);
            if (Number.isFinite(num)) val = num;
            else if (raw != null && raw !== "") val = 1;
            else val = 1;
        }

        acc.matrix[key] = (acc.matrix[key] || 0) + val;
        acc.rowSums[rStr] = (acc.rowSums[rStr] || 0) + val;
        acc.colSums[cStr] = (acc.colSums[cStr] || 0) + val;
        acc.total += val;
      }
      acc.rows = Array.from(rowSet);
      acc.cols = Array.from(colSet);
      return augmentObject(acc);
    },

    nWiseCooccurrence: (data, setExtractor, n = 2) => {
      const counts = {};
      const fn = safeKeyFn(setExtractor);
      const MAX_ITEMS_PER_ROW = 100;  // Circuit breaker: cap unique items per row
      const MAX_COMBOS_TOTAL = 500000; // Circuit breaker: stop if total combos gets too large
      let totalCombos = 0;
      const combinations = (arr, k) => {
        if (k === 1) return arr.map((x) => [x]);
        const result = [];
        for (let i = 0; i <= arr.length - k; i++) {
          const head = arr[i];
          const tailCombos = combinations(arr.slice(i + 1), k - 1);
          for (const combo of tailCombos) {
            result.push([head, ...combo]);
            if (result.length > MAX_COMBOS_TOTAL) return result; // bail early
          }
        }
        return result;
      };
      for (const row of data || []) {
        if (totalCombos > MAX_COMBOS_TOTAL) break; // global circuit breaker
        const items = fn(row);
        if (!Array.isArray(items) || items.length < n) continue;
        let unique = [...new Set(items)].sort();
        // Circuit breaker: if too many unique items, take only top MAX_ITEMS_PER_ROW
        if (unique.length > MAX_ITEMS_PER_ROW) unique = unique.slice(0, MAX_ITEMS_PER_ROW);
        const combos = combinations(unique, n);
        for (const combo of combos) {
          counts[combo.join("|")] = (counts[combo.join("|")] || 0) + 1;
          totalCombos++;
        }
      }
      return augmentObject(counts);
    }
  };


// -------------------------------------------------------------------------
  // network (Graph & Network Analysis)
  // -------------------------------------------------------------------------
  const network = {
    degreeCount: (edges, sourceKey = "source", targetKey = "target") => {
      const counts = {};
      const sFn = safeKeyFn(sourceKey);
      const tFn = safeKeyFn(targetKey);
      
      for (const edge of edges || []) {
        const s = sFn(edge);
        const t = tFn(edge);
        if (s != null) counts[s] = (counts[s] || 0) + 1;
        if (t != null) counts[t] = (counts[t] || 0) + 1;
      }
      return augmentObject(counts);
    },

    adjacencyList: (edges, sourceKey = "source", targetKey = "target") => {
      const adj = {};
      const sFn = safeKeyFn(sourceKey);
      const tFn = safeKeyFn(targetKey);

      for (const edge of edges || []) {
        const s = sFn(edge);
        const t = tFn(edge);
        if (s != null && t != null) {
          if (!adj[s]) adj[s] = [];
          adj[s].push(t);
        }
      }
      return augmentObject(adj);
    },

    cooccurrenceNetwork: (data, setExtractor, options = {}) => {
       // Uses the sibling module 'cooccurrence' to build a graph
       const edges = cooccurrence.basketAnalysis(data, setExtractor, options);
       const nodes = new Set();
       
       const links = edges.map(e => {
           nodes.add(e.itemA);
           nodes.add(e.itemB);
           return { source: e.itemA, target: e.itemB, weight: e[options.metric || 'count'] || e.count };
       });

       return augmentObject({
           nodes: Array.from(nodes).map(id => ({ id })),
           links
       });
    }
  };

  // -------------------------------------------------------------------------
  // predictive
  // -------------------------------------------------------------------------
  const predictive = {
    trendProjection: (values, stepsAhead = 1) => {
      // Fix: Handle object arrays (e.g. [{count: 10}, {count: 20}]) automatically
      let nums = [];
      if (Array.isArray(values) && values.length > 0 && typeof values[0] === 'object') {
          // Try to find the first numeric value in the object
          // Map each row to its number, filtering out invalids
          nums = values.map(v => {
             if(typeof v === 'number') return v;
             const val = Object.values(v).find(x => typeof x === 'number');
             return val !== undefined ? val : stats.toNumber(v);
          }).filter(n => Number.isFinite(n));
      } else {
          nums = stats.compactNumbers(values);
      }

      if (nums.length < 2) {
         // Fallback: If not enough data, return the single value projected flat, or 0
         const fallback = nums.length ? nums[0] : 0;
         return {
             regression: { slope: 0, intercept: fallback, r2: 0, n: nums.length },
             projections: Array.from({length: stepsAhead}, (_, i) => ({
                 step: nums.length + i,
                 predicted: fallback
             })),
             trend: "flat"
         };
      }

      const xs = collections.range(nums.length);
      const reg = correlation.linearRegression(xs, nums);
      
      // Safety: If regression returns null (singular matrix), fallback to mean
      if (!reg || !Number.isFinite(reg.slope) || !Number.isFinite(reg.intercept)) {
          const avg = stats.mean(nums);
          return {
             regression: { slope: 0, intercept: avg, r2: 0, n: nums.length },
             projections: Array.from({length: stepsAhead}, (_, i) => ({
                 step: nums.length + i,
                 predicted: avg
             })),
             trend: "flat"
         };
      }

      const projections = [];
      for (let i = 1; i <= stepsAhead; i++) {
        let pred = reg.slope * (nums.length + i - 1) + reg.intercept;
        // REMOVED: Negative clamping.
        // We allow negative values to pass through for domain-agnostic correctness.
        
        projections.push({
          step: nums.length + i - 1,
          predicted: pred,
        });
      }

      return {
        regression: reg,
        projections,
        trend: reg.slope > 0 ? "increasing" : reg.slope < 0 ? "decreasing" : "flat",
      };
    },

    rollingRegression: (values, windowSize = 5) => {
      const nums = stats.compactNumbers(values);
      if (nums.length < windowSize) return [];

      const results = [];
      for (let i = windowSize; i <= nums.length; i++) {
        const window = nums.slice(i - windowSize, i);
        const xs = collections.range(windowSize);
        const reg = correlation.linearRegression(xs, window);

        results.push({
          endIndex: i - 1,
          slope: reg ? reg.slope : 0,
          r2: reg ? reg.r2 : 0,
          nextPredicted: reg ? reg.slope * windowSize + reg.intercept : window[window.length - 1],
        });
      }

      return results;
    },

    frequencyBasedPrediction: (sequence) => {
      if (!Array.isArray(sequence) || sequence.length < 2) return null;

      const transitions = {};
      for (let i = 0; i < sequence.length - 1; i++) {
        const from = sequence[i];
        const to = sequence[i + 1];
        if (!transitions[from]) transitions[from] = {};
        transitions[from][to] = (transitions[from][to] || 0) + 1;
      }

      const current = sequence[sequence.length - 1];
      const nextStates = transitions[current];
      if (!nextStates) return { current, predicted: null, confidence: 0 };

      let bestNext = null;
      let bestCount = 0;
      let total = 0;

      for (const [state, count] of Object.entries(nextStates)) {
        total += count;
        if (count > bestCount) {
          bestCount = count;
          bestNext = state;
        }
      }

      return {
        current,
        predicted: bestNext,
        confidence: total ? bestCount / total : 0,
        alternatives: nextStates,
      };
    },

    anomalyForecast: (values, threshold = 2) => {
      const nums = stats.compactNumbers(values);
      if (nums.length < 5) return null;

      const mean = stats.avg(nums);
      const sd = stats.stddev(nums);
      const trend = predictive.trendProjection(nums, 3);
      if (!trend) return null;

      const forecasts = trend.projections.map((p) => {
        const zScore = sd ? (p.predicted - mean) / sd : 0;
        return {
          ...p,
          zScore,
          anomalyRisk: Math.abs(zScore) > threshold ? "high" : Math.abs(zScore) > threshold / 2 ? "medium" : "low",
        };
      });

      return { historicalMean: mean, historicalStdDev: sd, forecasts };
    },

    segmentationPredictor: (data, segmentKeyFn, valueFn) => {
      const groups = collections.groupBy(data, segmentKeyFn);
      const predictions = {};

      for (const [segment, rows] of Object.entries(groups)) {
        const values = rows.map(valueFn);
        const nums = stats.compactNumbers(values);

        const trend = predictive.trendProjection(nums, 1);
        predictions[segment] = {
          n: nums.length,
          mean: stats.avg(nums),
          stddev: stats.stddev(nums),
          trend,
          nextPredicted: (trend && trend.projections && trend.projections[0] && trend.projections[0].predicted) || stats.avg(nums),
        };
      }

      return predictions;
    },
  };

/**
 * PATCH: Add this 'optimization' module inside 'StandardLibrary' (Module 2),
 * right before 'const _ = { ... }'.
 */
const optimization = {
  /**
   * Calculates efficiency scores (0.0 to 1.0) relative to the frontier (best performer).
   * 
   * Usage:
   * 1. Simple Array: _.frontierEfficiency([10, 20, 50]) -> [0.2, 0.4, 1.0]
   * 2. Objects (Output only): _.frontierEfficiency(rows, 'revenue') -> efficiency based on max revenue
   * 3. Objects (Input/Output): _.frontierEfficiency(rows, 'cost', 'revenue') -> efficiency based on max (revenue/cost)
   */
  frontierEfficiency: (data, inputKey, outputKey) => {
    if (!Array.isArray(data)) return [];

    // Case A: Simple numeric array
    if (typeof data[0] === "number") {
      const nums = stats.compactNumbers(data);
      const max = Math.max(...nums);
      return max ? nums.map((n) => n / max) : nums.map(() => 0);
    }

    // Case B: Objects
    let iFn, oFn;
    // If only 2 args passed (data, outputKey), assume input is 1 (constant)
    if (!outputKey && inputKey) {
      oFn = safeKeyFn(inputKey);
      iFn = () => 1;
    } else {
      iFn = inputKey ? safeKeyFn(inputKey) : () => 1;
      oFn = outputKey ? safeKeyFn(outputKey) : (x) => stats.toNumber(x);
    }

    const rows = data.map((d) => {
      const iVal = stats.toNumber(iFn(d));
      const oVal = stats.toNumber(oFn(d));
      // Ratio = Output / Input. Higher is better.
      const ratio = iVal > 0 ? oVal / iVal : 0;
      return { original: d, ratio };
    });

    const maxRatio = Math.max(...rows.map((r) => r.ratio));

    return rows.map((r) => {
      const efficiency = maxRatio ? r.ratio / maxRatio : 0;
      if (r.original && typeof r.original === "object") {
        return augmentObject({ ...r.original, efficiency, frontierRatio: r.ratio });
      }
      return { value: r.original, efficiency };
    });
  },

  /**
   * Returns the Pareto Frontier (non-dominated points) for two dimensions.
   * Assumes maximization for both X and Y.
   */
  paretoFrontier: (data, xKey, yKey) => {
    const xFn = safeKeyFn(xKey);
    const yFn = safeKeyFn(yKey);

    const points = data
      .map((d) => ({
        original: d,
        x: stats.toNumber(xFn(d)),
        y: stats.toNumber(yFn(d)),
      }))
      .filter((p) => Number.isFinite(p.x) && Number.isFinite(p.y))
      // Sort X descending. If Xs equal, Y descending.
      .sort((a, b) => b.x - a.x || b.y - a.y);

    const frontier = [];
    let currentMaxY = -Infinity;

    for (const p of points) {
      // If this point has a higher Y than any point with a higher X seen so far,
      // it is on the frontier.
      if (p.y > currentMaxY) {
        frontier.push(p.original);
        currentMaxY = p.y;
      }
    }
    return frontier;
  },

  /**
   * Calculates Opportunity Cost: The difference between the maximum possible value and the current value.
   */
  opportunityCost: (data, valKey) => {
    const fn = safeKeyFn(valKey);
    const nums = data
      .map((d) => stats.toNumber(fn(d)))
      .filter((n) => Number.isFinite(n));
    const max = nums.length ? Math.max(...nums) : 0;

    return data.map((d) => {
      const val = stats.toNumber(fn(d));
      return augmentObject({
        ...d,
        opportunityCost: Number.isFinite(val) ? max - val : 0,
      });
    });
  },
};

  // =========================================================================
  // 2. REPLACEMENT: ANOMALIES MODULE (Fixed "Zero Scores" & Alignment Bugs)
  // =========================================================================
  const anomalies = {
    /**
     * 1. MAD Outliers (Robust Median Absolute Deviation)
     * FOREVER FIX: Returns an ARRAY aligned 1:1 with input data.
     * This prevents "score: 0" caused by AI trying to read object properties as array indices.
     */
    madOutliers: (arr, threshold = 3.5, key) => {
      // 1. Resolve arguments flexibility (handle AI guessing args wrong)
      let actualKey = key;
      let actualThreshold = threshold;
      if (typeof threshold === "string" || typeof threshold === "function") {
          actualKey = threshold;
          actualThreshold = 3.5;
      }

      // 2. Prepare Data
      const fn = actualKey ? safeKeyFn(actualKey) : (x) => x;
      const rawValues = Array.isArray(arr) ? arr.map(fn) : [];
      
      // 3. Calculate Stats on VALID numbers only
      const validNums = stats.compactNumbers(rawValues);
      if (!validNums.length) return Object.assign([], { count: 0, outliers: [] });

      const med = stats.median(validNums);
      const devs = validNums.map(x => Math.abs(x - med));
      const mad = stats.median(devs);
      
      // Safety: Prevent divide-by-zero if all values are identical (MAD=0)
      // If MAD is 0, any deviation is technically infinite, but we clamp to 0 for stability unless value differs.
      const safeMad = mad === 0 ? 0 : mad;

      // 4. Map over ORIGINAL array length to maintain index alignment (Critical Fix)
      const results = rawValues.map((val, i) => {
        const n = stats.toNumber(val);
        if (!Number.isFinite(n)) {
            return { index: i, value: val, score: 0, isAnomaly: false };
        }

        let z = 0;
        if (safeMad !== 0) {
            z = (0.6745 * (n - med)) / safeMad;
        } else if (n !== med) {
            // If variance is 0 but this value differs, it's a massive anomaly
            z = (n - med) > 0 ? 100 : -100; 
        }

        const score = Math.abs(z);
        return {
          index: i,
          value: n,
          score: score,
          isAnomaly: score > actualThreshold
        };
      });

      // 5. Generate Metadata
      const outliers = results.filter(r => r.isAnomaly);

      // 6. Return HYBRID: It is an Array (results) but has Stats properties attached.
      // This allows "anomalies[0]" (Array access) AND "anomalies.count" (Object access) to both work.
      return Object.assign(results, {
        outliers,
        count: outliers.length,
        rate: validNums.length ? outliers.length / validNums.length : 0,
        mad,
        median: med,
        threshold: actualThreshold
      });
    },

    /**
     * 2. Rolling Z-Score
     * Fixed to return aligned Array.
     */
    rollingZScore: (arr, window = 5, threshold = 3, key) => {
      let actualKey = key;
      let actualWin = window;
      let actualThresh = threshold;

      if (typeof window === 'string' || typeof window === 'function') {
         actualKey = window;
         actualWin = typeof threshold === 'number' ? threshold : 5;
         actualThresh = typeof key === 'number' ? key : 3;
      }

      const fn = actualKey ? safeKeyFn(actualKey) : (x) => x;
      const rawValues = Array.isArray(arr) ? arr.map(fn) : [];
      const nums = stats.compactNumbers(rawValues);

      // We map over nums here (rolling implies time-contiguous), but result must include metadata
      const results = nums.map((val, i) => {
        if (i < actualWin) return { index: i, value: val, z: 0, score: 0, isAnomaly: false };
        
        const slice = nums.slice(i - actualWin, i);
        const mean = stats.avg(slice);
        const sd = stats.stddev(slice);
        
        const z = sd === 0 ? (val === mean ? 0 : actualThresh + 1) : (val - mean) / sd;
        const score = Math.abs(z);
        
        return {
          index: i,
          value: val,
          z,
          score,
          isAnomaly: score > actualThresh
        };
      });

      const outliers = results.filter(r => r.isAnomaly);

      return Object.assign(results, {
          outliers,
          count: outliers.length
      });
    },

    /**
     * 3. Seasonal Anomaly
     * Fixed to return aligned Array.
     */
    seasonalAnomaly: (arr, seasonLength = 7, threshold = 3, key) => {
      let actualKey = key;
      let actualSeason = seasonLength;
      let actualThresh = threshold;

      if (typeof seasonLength === 'string' || typeof seasonLength === 'function') {
          actualKey = seasonLength;
          actualSeason = typeof threshold === 'number' ? threshold : 7;
          actualThresh = typeof key === 'number' ? key : 3;
      }

      const fn = actualKey ? safeKeyFn(actualKey) : (x) => x;
      const rawValues = Array.isArray(arr) ? arr.map(fn) : [];
      // Note: We use rawValues to maintain index alignment for seasonality
      const validIndices = rawValues.map((v, i) => Number.isFinite(stats.toNumber(v)) ? i : -1).filter(i => i !== -1);
      const nums = validIndices.map(i => stats.toNumber(rawValues[i]));

      if (nums.length < actualSeason * 2) return Object.assign([], { count: 0, outliers: [] });

      // Build Profiles
      const slots = {};
      for (let i = 0; i < actualSeason; i++) slots[i] = [];
      nums.forEach((v, i) => slots[i % actualSeason].push(v));

      const profile = {};
      for (let i = 0; i < actualSeason; i++) {
        profile[i] = {
          mean: stats.avg(slots[i]),
          std: stats.stddev(slots[i])
        };
      }

      const results = rawValues.map((rawVal, i) => {
          const val = stats.toNumber(rawVal);
          if (!Number.isFinite(val)) return { index: i, value: rawVal, score: 0, isAnomaly: false };

          const slot = i % actualSeason;
          const p = profile[slot];
          const z = p.std === 0 ? 0 : (val - p.mean) / p.std;
          const score = Math.abs(z);

          return {
            index: i,
            value: val,
            seasonSlot: slot,
            seasonMean: p.mean,
            z,
            score,
            isAnomaly: score > actualThresh
          };
      });

      const outliers = results.filter(r => r.isAnomaly);
      return Object.assign(results, {
          outliers,
          count: outliers.length,
          profile
      });
    },

    /**
     * 4. Isolation Score (Consolidated)
     * Returns array of objects with .isolationScore attached
     */
    isolationScore: (data, fields, options = {}) => {
      // Accept arrays, single values, or object-of-arrays; always return an array with metadata
      if (data == null) return Object.assign([], { count: 0, fields: [], outliers: [] });

      // Normalize input into rows (array of objects)
      let rows = [];
      if (Array.isArray(data)) {
        // Array-of-numbers -> wrap into { value }
        if (data.length && (typeof data[0] === "number" || typeof data[0] === "string")) {
          rows = data.map(v => ({ value: v }));
          if (!fields) fields = ["value"];
        } else {
          rows = data;
        }
      } else if (typeof data === "object") {
        // Object-of-arrays -> convert to rows
        const keys = Object.keys(data);
        const L = Math.max(0, ...keys.map(k => Array.isArray(data[k]) ? data[k].length : 0));
        rows = new Array(L);
        for (let i = 0; i < L; i++) {
          const row = {};
          for (const k of keys) {
            const col = data[k];
            row[k] = Array.isArray(col) ? col[i] : col;
          }
          rows[i] = row;
        }
      }

      rows = Array.isArray(rows) ? rows.filter(r => r && typeof r === "object" && !Array.isArray(r)) : [];
      if (!rows.length) return Object.assign([], { count: 0, fields: [], outliers: [] });

      const opts = options && typeof options === "object" ? options : {};
      const sampleN = Number.isFinite(stats.toNumber(opts.sampleN)) ? Math.max(20, Math.floor(stats.toNumber(opts.sampleN))) : 200;
      const minNumericRate = Number.isFinite(stats.toNumber(opts.minNumericRate)) ? Math.max(0, Math.min(1, stats.toNumber(opts.minNumericRate))) : 0.6;
      const topN = Number.isFinite(stats.toNumber(opts.topN)) ? Math.max(1, Math.floor(stats.toNumber(opts.topN))) : 10;

      // ---------------------------------------------------
      // Robust numeric-field detection (works with "123", "$1,234", etc.)
      // ---------------------------------------------------
      let keys = Array.isArray(fields) && fields.length ? fields : null;

      if (!keys) {
        const sample = rows.slice(0, Math.min(sampleN, rows.length));
        const candidate = Object.keys(sample[0] || {});
        const scored = [];

        for (const k of candidate) {
          let total = 0;
          let numeric = 0;

          for (let i = 0; i < sample.length; i++) {
            const v = sample[i] ? sample[i][k] : undefined;
            if (v == null || v === "") continue;
            total++;
            const num = stats.toNumber(v);
            if (Number.isFinite(num)) numeric++;
          }

          if (!total) continue;
          const rate = numeric / total;
          if (rate >= minNumericRate) scored.push({ key: k, rate, total });
        }

        scored.sort((a, b) => (b.rate - a.rate) || (b.total - a.total));
        keys = scored.map(s => s.key);
      }

      if (!Array.isArray(keys) || !keys.length) return Object.assign([], { count: 0, fields: [], outliers: [] });

      // ---------------------------------------------------
      // Build robust per-field stats (median + IQR)
      // ---------------------------------------------------
      const statsMap = {};
      for (const k of keys) {
        const vals = rows.map(r => stats.toNumber(r[k])).filter(Number.isFinite);
        if (!vals.length) {
          statsMap[k] = { med: 0, iqr: 1 };
          continue;
        }
        const q1 = stats.percentile(vals, 25);
        const q3 = stats.percentile(vals, 75);
        statsMap[k] = {
          med: stats.median(vals),
          iqr: (q3 - q1) || 1 // Avoid div/0
        };
      }

      // ---------------------------------------------------
      // Score each row (normalized distance from medians)
      // ---------------------------------------------------
      const scored = rows.map((row, i) => {
        let totalDist = 0;
        let validFeats = 0;
        for (const k of keys) {
          const val = stats.toNumber(row[k]);
          if (Number.isFinite(val)) {
            totalDist += Math.abs(val - statsMap[k].med) / statsMap[k].iqr;
            validFeats++;
          }
        }
        const score = validFeats ? totalDist / validFeats : 0;
        return { original: row, index: i, isolationScore: score, score };
      });

      const maxScore = Math.max(...scored.map(s => s.score)) || 1;

      const results = scored.map(s =>
        augmentObject({
          ...s.original,
          __rowIndex: s.index,
          isolationScore: s.score,
          anomalyProbability: s.score / maxScore
        })
      );

      const outliers = scored
        .slice()
        .sort((a, b) => b.score - a.score)
        .slice(0, Math.min(topN, scored.length))
        .map(s =>
          augmentObject({
            ...s.original,
            __rowIndex: s.index,
            isolationScore: s.score,
            anomalyProbability: s.score / maxScore
          })
        );

      // Attach metadata for consistency (NO MORE count:0)
      return Object.assign(results, {
        count: results.length,
        fields: keys,
        maxScore,
        outliers
      });
    }
  };


    // -------------------------------------------------------------------------
  // Build unified _
  // -------------------------------------------------------------------------
  
  // -------------------------------------------------------------------------
  // types (Type Checking Family)
  // -------------------------------------------------------------------------
  const types = {
    isDate: (v) => v instanceof Date || (typeof v === "object" && Object.prototype.toString.call(v) === "[object Date]"),
    isString: (v) => typeof v === "string",
    isNumber: (v) => typeof v === "number",
    isBoolean: (v) => typeof v === "boolean",
    isArray: Array.isArray,
    isObject: (v) => v != null && (typeof v === "object" || typeof v === "function"),
    isPlainObject: (v) => {
      if (v == null || typeof v !== "object") return false;
      const proto = Object.getPrototypeOf(v);
      return proto === null || proto === Object.prototype;
    },
    isFunction: (v) => typeof v === "function",
    isNil: (v) => v == null,
    isNull: (v) => v === null,
    isUndefined: (v) => v === undefined,
    isElement: (v) => v != null && typeof v === "object" && v.nodeType === 1,
    isRegExp: (v) => v instanceof RegExp,
    isError: (v) => v instanceof Error,
    isNaN: (v) => Number.isNaN(v),
    castArray: (v) => (Array.isArray(v) ? v : [v])
  };

  /**
   * PATCH: Create a hybrid timeSeries object/function.
   * Fixes "_.timeSeries is not a function" while allowing _.timeSeries.movingAvg access.
   */
  const timeSeriesHybrid = (data, ...args) => {
     // If called as a function, default to a summary or simple sort
     if (Array.isArray(data)) return timeseries.movementSummary(data);
     return timeseries.movementSummary([]);
  };
  // Copy all timeseries methods onto the function
  Object.assign(timeSeriesHybrid, timeseries);

 // -------------------------------------------------------------------------
// dates (Date Manipulation Family - Enhanced v2.4)
// -------------------------------------------------------------------------
const dates = {
  /**
   * Calculates the difference between two dates in the specified unit.
   * Usage: _.dateDiff('2023-01-01', '2023-01-05', 'day') => 4
   */
  dateDiff: (start, end, unit = "ms", float = false) => {
    const s = new Date(start);
    const e = new Date(end);
    if (isNaN(s.getTime()) || isNaN(e.getTime())) return 0;

    const diffMs = e.getTime() - s.getTime();
    let result = diffMs;
    const u = String(unit).toLowerCase().replace(/s$/, "");

    switch (u) {
      case "millisecond": result = diffMs; break;
      case "second": result = diffMs / 1000; break;
      case "minute": result = diffMs / 60000; break;
      case "hour": result = diffMs / 3600000; break;
      case "day": result = diffMs / 86400000; break;
      case "week": result = diffMs / 604800000; break;
      case "month": result = diffMs / 2629800000; break; // Approx 30.44 days
      case "quarter": result = diffMs / 7889400000; break; // Approx 3 months
      case "year": result = diffMs / 31557600000; break; // Approx 365.25 days
      default: result = diffMs;
    }
    return float ? result : Math.trunc(result);
  },

  /**
   * Adds a specified amount of time to a date.
   * Usage: _.addDate('2023-01-01', 5, 'days')
   */
  addDate: (date, amount, unit = "day") => {
    const d = new Date(date);
    if (isNaN(d.getTime())) return null;
    const n = Number(amount);
    if (!Number.isFinite(n)) return d;

    const u = String(unit).toLowerCase().replace(/s$/, "");
    switch (u) {
      case "millisecond": d.setMilliseconds(d.getMilliseconds() + n); break;
      case "second": d.setSeconds(d.getSeconds() + n); break;
      case "minute": d.setMinutes(d.getMinutes() + n); break;
      case "hour": d.setHours(d.getHours() + n); break;
      case "day": d.setDate(d.getDate() + n); break;
      case "week": d.setDate(d.getDate() + n * 7); break;
      case "month": d.setMonth(d.getMonth() + n); break;
      case "quarter": d.setMonth(d.getMonth() + n * 3); break;
      case "year": d.setFullYear(d.getFullYear() + n); break;
    }
    return d;
  },

  subtractDate: (date, amount, unit = "day") => {
    return dates.addDate(date, -Number(amount), unit);
  },

  startOf: (date, unit = "day") => {
    const d = new Date(date);
    if (isNaN(d.getTime())) return null;
    const u = String(unit).toLowerCase().replace(/s$/, "");
    switch (u) {
      case "year": d.setMonth(0, 1); d.setHours(0, 0, 0, 0); break;
      case "month": d.setDate(1); d.setHours(0, 0, 0, 0); break;
      case "day": d.setHours(0, 0, 0, 0); break;
      case "hour": d.setMinutes(0, 0, 0); break;
    }
    return d;
  },

  endOf: (date, unit = "day") => {
    const d = new Date(date);
    if (isNaN(d.getTime())) return null;
    const u = String(unit).toLowerCase().replace(/s$/, "");
    switch (u) {
      case "year": d.setFullYear(d.getFullYear() + 1, 0, 1); d.setMilliseconds(-1); break;
      case "month": d.setMonth(d.getMonth() + 1, 1); d.setMilliseconds(-1); break;
      case "day": d.setDate(d.getDate() + 1); d.setHours(0, 0, 0, 0); d.setMilliseconds(-1); break;
    }
    return d;
  },

  formatDate: (date, fmt = "YYYY-MM-DD") => {
    const d = new Date(date);
    if (isNaN(d.getTime())) return "";
    const iso = d.toISOString();
    if (fmt === "YYYY-MM-DD") return iso.split("T")[0];
    return iso;
  },

  // =========================================================================
  // FIX: Added parseDate and Robustness Family (Prevent AI Hallucinations)
  // =========================================================================
  
  /**
   * Parses a value into a JS Date object. Returns null if invalid.
   * Enhanced in SERA v3.0: handles month names ("January", "Jan"), 
   * quarters ("Q1", "2024-Q3"), YYYY-MM ("2024-01"), and relative period strings.
   */
  parseDate: (v) => {
      if (v instanceof Date) return v;
      if (v == null || v === "") return null;
      
      // Direct Date parse first (handles ISO, "2024-01-15", timestamps, etc.)
      const d = new Date(v);
      if (!isNaN(d.getTime())) return d;
      
      // If it's not directly parseable, try period-format parsing
      if (typeof v === "string") {
        const s = v.trim().toLowerCase();
        
        // Month names: "january", "jan", "feb", etc. → 1st of that month (current year)
        const MONTHS = { jan: 0, january: 0, feb: 1, february: 1, mar: 2, march: 2, apr: 3, april: 3,
          may: 4, jun: 5, june: 5, jul: 6, july: 6, aug: 7, august: 7, sep: 8, sept: 8, september: 8,
          oct: 9, october: 9, nov: 10, november: 10, dec: 11, december: 11 };
        
        // "Month Year": "Jan 2024", "January 2024", "2024 Jan"
        for (const [mName, mIdx] of Object.entries(MONTHS)) {
          if (s.includes(mName)) {
            const yy = s.match(/\d{4}/);
            const year = yy ? Number(yy[0]) : new Date().getFullYear();
            return new Date(Date.UTC(year, mIdx, 1));
          }
        }
        
        // YYYY-MM: "2024-01", "2024/03"
        const ymMatch = s.match(/^(\d{4})[-/](\d{1,2})$/);
        if (ymMatch) {
          const y = Number(ymMatch[1]);
          const m = Number(ymMatch[2]) - 1;
          if (m >= 0 && m <= 11) return new Date(Date.UTC(y, m, 1));
        }
        
        // Quarter: "Q1", "2024-Q3", "Q2 2024"
        const qMatch = s.match(/(?:(\d{4})\s*[-/]?\s*)?q([1-4])(?:\s*[-/]?\s*(\d{4}))?/);
        if (qMatch) {
          const year = Number(qMatch[1] || qMatch[3] || new Date().getFullYear());
          const q = Number(qMatch[2]);
          return new Date(Date.UTC(year, (q - 1) * 3, 1));
        }
        
        // Plain year: "2024"
        const yearMatch = s.match(/^(\d{4})$/);
        if (yearMatch) return new Date(Date.UTC(Number(yearMatch[1]), 0, 1));
      }
      
      return null;
  },

  /** Aliases often guessed by AI generators */
  parse: (v) => dates.parseDate(v),
  toDate: (v) => dates.parseDate(v),
  isValid: (v) => !isNaN(new Date(v).getTime()),
  
  /** Comparisons */
  isBefore: (a, b) => new Date(a) < new Date(b),
  isAfter: (a, b) => new Date(a) > new Date(b),
  isSame: (a, b) => new Date(a).getTime() === new Date(b).getTime(),

  /** Getters/Utilities */
  now: () => new Date(),
  year: (d) => new Date(d).getFullYear(),
  month: (d) => new Date(d).getMonth() + 1, // 1-12
  day: (d) => new Date(d).getDate(),
  weekday: (d) => new Date(d).getDay(), // 0-6
  daysInMonth: (d) => {
      const date = new Date(d);
      return new Date(date.getFullYear(), date.getMonth() + 1, 0).getDate();
  }
};

/**
 * INSERT THIS BLOCK INSIDE 'StandardLibrary' (Module 2),
 * RIGHT BEFORE 'const _ = { ... }'.
 */
const lodashPatterns = {
    // --- Object Accessors ---
    get: (obj, path, defaultValue) => {
        if (obj == null) return defaultValue;
        const keys = Array.isArray(path) ? path : String(path).replace(/\[(\d+)\]/g, '.$1').split('.').filter(Boolean);
        let result = obj;
        for (const key of keys) {
            if (result == null) return defaultValue;
            result = result[key];
        }
        return result === undefined ? defaultValue : result;
    },

    set: (obj, path, value) => {
        if (!obj || typeof obj !== 'object') return obj;
        const keys = Array.isArray(path) ? path : String(path).replace(/\[(\d+)\]/g, '.$1').split('.').filter(Boolean);
        let cur = obj;
        for (let i = 0; i < keys.length - 1; i++) {
            const key = keys[i];
            if (cur[key] == null || typeof cur[key] !== 'object') {
                // Determine if next key is an index to create array vs object
                const nextKey = keys[i + 1];
                cur[key] = String(nextKey).match(/^\d+$/) ? [] : {};
            }
            cur = cur[key];
        }
        cur[keys[keys.length - 1]] = value;
        return obj;
    },

    has: (obj, path) => {
        if (obj == null) return false;
        const keys = Array.isArray(path) ? path : String(path).replace(/\[(\d+)\]/g, '.$1').split('.').filter(Boolean);
        let cur = obj;
        for (const key of keys) {
            if (cur == null || !Object.prototype.hasOwnProperty.call(cur, key)) return false;
            cur = cur[key];
        }
        return true;
    },

    // --- Object Enumeration ---
    keys: (obj) => (obj ? Object.keys(obj) : []),
    values: (obj) => (obj ? Object.values(obj) : []),
    entries: (obj) => (obj ? Object.entries(obj) : []),
    fromPairs: (pairs) => Object.fromEntries(pairs || []),

    // --- Object Manipulation ---
    merge: (target, ...sources) => {
        if (!sources.length) return target;
        const source = sources.shift();
        if (target && source && typeof target === 'object' && typeof source === 'object') {
            for (const key in source) {
                if (source[key] && typeof source[key] === 'object' && !Array.isArray(source[key])) {
                    if (!target[key]) Object.assign(target, { [key]: {} });
                    lodashPatterns.merge(target[key], source[key]);
                } else {
                    Object.assign(target, { [key]: source[key] });
                }
            }
        }
        return lodashPatterns.merge(target, ...sources);
    },

    defaults: (obj, ...defs) => {
        if (obj == null) return obj;
        for (const def of defs) {
            if (def && typeof def === 'object') {
                for (const key in def) {
                    if (obj[key] === undefined) obj[key] = def[key];
                }
            }
        }
        return obj;
    },

    cloneDeep: (val) => {
        if (val === null || typeof val !== 'object') return val;
        if (val instanceof Date) return new Date(val);
        if (Array.isArray(val)) return val.map(lodashPatterns.cloneDeep);
        const res = {};
        for (const k in val) res[k] = lodashPatterns.cloneDeep(val[k]);
        return res;
    },

    // --- Array Helpers ---
    compact: (arr) => (Array.isArray(arr) ? arr.filter((x) => x) : []),
    
    uniqBy: (arr, iteratee) => {
        if (!Array.isArray(arr)) return [];
        const fn = (x) => {
            // Mimic basic iteratee behavior
            if (typeof iteratee === 'function') return iteratee(x);
            if (typeof iteratee === 'string') return x[iteratee];
            return x;
        };
        const seen = new Set();
        return arr.filter((x) => {
            const k = fn(x);
            if (seen.has(k)) return false;
            seen.add(k);
            return true;
        });
    },

    flattenDepth: (arr, depth = 1) => {
        if (!Array.isArray(arr)) return [];
        if (depth < 1) return arr.slice();
        return arr.reduce((acc, val) => {
            return acc.concat(Array.isArray(val) ? lodashPatterns.flattenDepth(val, depth - 1) : [val]);
        }, []);
    },

    // --- Chain Flow ---
    tap: (value, interceptor) => {
        interceptor(value);
        return value;
    },

    thru: (value, interceptor) => interceptor(value)
};

  // =========================================================================
  // NEW MODULE: QUALITY & PROFILING (Data Forensics)
  // =========================================================================
  const quality = {
    /**
     * Helper: Checks if a value is effectively "empty" (null, undefined, empty string, or NaN).
     * Note: 0 and false are considered VALID values, not missing.
     */
    isMissing: (v) => {
      if (v == null) return true;
      if (v === "") return true;
      if (typeof v === "number" && isNaN(v)) return true;
      return false;
    },

    /**
     * 1. Missingness Report
     * Calculates the health of each field in the dataset.
     */
    missingness: (data) => {
      const rows = Array.isArray(data) ? data : [];
      if (!rows.length) return augmentObject({});

      const fieldStats = {};
      // Initialize based on first few rows to capture schema
      const keys = new Set();
      rows.slice(0, 100).forEach(r => Object.keys(r || {}).forEach(k => keys.add(k)));

      keys.forEach(k => {
        fieldStats[k] = { total: 0, missing: 0, present: 0, distinct: new Set() };
      });

      for (const row of rows) {
        for (const k of keys) {
          if (!fieldStats[k]) fieldStats[k] = { total: 0, missing: 0, present: 0, distinct: new Set() };
          const val = row[k];
          fieldStats[k].total++;
          if (quality.isMissing(val)) {
            fieldStats[k].missing++;
          } else {
            fieldStats[k].present++;
            // Cap distinct set size for memory safety
            if (fieldStats[k].distinct.size < 1000) fieldStats[k].distinct.add(String(val));
          }
        }
      }

      const report = {};
      for (const [k, s] of Object.entries(fieldStats)) {
        report[k] = {
          count: s.total,
          missingCount: s.missing,
          missingPct: s.total ? s.missing / s.total : 0,
          distinctApprox: s.distinct.size,
          completeness: s.total ? s.present / s.total : 0
        };
      }
      return augmentObject(report);
    },

    /**
     * 2. Distinct Counts & Top Values
     * Returns cardinality and the most frequent values (mode).
     */
    valueCounts: (data, field, topN = 10) => {
      const rows = Array.isArray(data) ? data : [];
      const fn = safeKeyFn(field);
      const counts = {};
      let validCount = 0;
      
      for (const row of rows) {
        const val = fn(row);
        if (quality.isMissing(val)) continue;
        const key = String(val);
        counts[key] = (counts[key] || 0) + 1;
        validCount++;
      }

      const sorted = Object.entries(counts)
        .sort((a, b) => b[1] - a[1])
        .map(([val, count]) => ({
          value: val,
          count,
          pct: validCount ? count / validCount : 0
        }));

      return augmentObject({
        field: String(field),
        totalValid: validCount,
        distinct: sorted.length,
        topValues: sorted.slice(0, topN)
      });
    },

    /**
     * 3. Duplicate Rate
     * Checks for duplicate rows based on specific keys (or whole object).
     */
    duplicates: (data, keys = null) => {
      const rows = Array.isArray(data) ? data : [];
      const seen = new Set();
      const dupes = [];
      
      // If keys provided, build composite key. Else use JSON stringify of row.
      const keyGen = keys 
        ? (r) => (Array.isArray(keys) ? keys : [keys]).map(k => r[k]).join("|")
        : (r) => JSON.stringify(r);

      for (let i = 0; i < rows.length; i++) {
        const row = rows[i];
        const signature = keyGen(row);
        if (seen.has(signature)) {
          dupes.push({ index: i, row });
        } else {
          seen.add(signature);
        }
      }

      return augmentObject({
        totalRows: rows.length,
        uniqueCount: seen.size,
        duplicateCount: dupes.length,
        duplicateRate: rows.length ? dupes.length / rows.length : 0,
        sampleDuplicates: dupes.slice(0, 50) // Return first 50 dupes for inspection
      });
    },

    /**
     * 4. Type Profiling
     * Guesses the data type (Numeric, Date, Boolean, String) and format.
     */
    typeProfile: (data, field) => {
      const rows = Array.isArray(data) ? data : [];
      const fn = safeKeyFn(field);
      
      let numericLike = 0;
      let dateLike = 0;
      let boolLike = 0;
      let empty = 0;
      let total = 0;
      const samples = [];

      for (const row of rows) {
        const val = fn(row);
        if (quality.isMissing(val)) {
          empty++;
          continue;
        }
        total++;
        if (total <= 5) samples.push(val);

        if (typeof val === 'boolean') boolLike++;
        else if (typeof val === 'number') numericLike++;
        else if (val instanceof Date) dateLike++;
        else if (typeof val === 'string') {
            // Heuristics
            if (!isNaN(Number(val)) && val.trim() !== '') numericLike++;
            else if (!isNaN(Date.parse(val)) && val.length > 5 && val.match(/\d/)) dateLike++;
            else if (['true','false','yes','no'].includes(val.toLowerCase())) boolLike++;
        }
      }

      const winner = [
        { type: 'Numeric', score: numericLike },
        { type: 'Date', score: dateLike },
        { type: 'Boolean', score: boolLike },
        { type: 'String', score: total - (numericLike + dateLike + boolLike) }
      ].sort((a,b) => b.score - a.score)[0];

      return augmentObject({
        inferredType: winner.type,
        confidence: total ? winner.score / total : 0,
        stats: { numericCount: numericLike, dateCount: dateLike, totalValid: total },
        examples: samples
      });
    },

    /**
     * 5. Outlier Rows (Forensic View)
     * Returns the actual row data for outliers, not just values.
     */
    outliers: (data, field, method = 'iqr') => {
      const rows = Array.isArray(data) ? data : [];
      const fn = safeKeyFn(field);
      
      // Extract values to use existing stats modules
      const values = rows.map(fn);
      let indices = [];

      if (method === 'zscore' || method === 'z') {
        const res = stats.zScoreOutliers(values, 3);
        indices = res.outlierIndices || [];
      } else {
        // IQR logic manually applied to get indices (stats.iqrOutliers returns values)
        const nums = stats.compactNumbers(values);
        if (nums.length < 4) return [];
        const q1 = stats.percentile(nums, 25);
        const q3 = stats.percentile(nums, 75);
        const iqr = q3 - q1;
        const low = q1 - 1.5 * iqr;
        const high = q3 + 1.5 * iqr;
        
        // Scan original array for indices matching criteria
        values.forEach((v, i) => {
           const n = stats.toNumber(v);
           if (Number.isFinite(n) && (n < low || n > high)) indices.push(i);
        });
      }

      return augmentObject({
        field: String(field),
        method,
        count: indices.length,
        rows: indices.map(i => rows[i])
      });
    },

    /**
     * 6. Master Profile
     * Runs a full forensic scan on the dataset.
     */
    profile: (data) => {
        const rows = Array.isArray(data) ? data : [];
        if (!rows.length) return { error: "No data" };
        
        // Schema & Missingness
        const missingReport = quality.missingness(rows);
        const fields = Object.keys(missingReport);
        const fieldProfiles = {};

        fields.forEach(f => {
           fieldProfiles[f] = {
               ...missingReport[f],
               ...quality.typeProfile(rows, f),
               topValues: quality.valueCounts(rows, f, 5).topValues
           };
        });

        return augmentObject({
            totalRows: rows.length,
            fieldCount: fields.length,
            duplicates: quality.duplicates(rows).duplicateRate,
            fields: fieldProfiles
        });
    }
  };

  // =========================================================================
  // PATCH START: Unified Export & Extensions (v2.5 Hotfix)
  // =========================================================================

  // 1. EXTENSION: Missing Collection Helpers
  collections.groupSum = (data, groupKey, valKey) => {
    const gFn = safeKeyFn(groupKey);
    const vFn = safeKeyFn(valKey);
    const sums = {};
    for (const row of (data || [])) {
      const g = gFn(row);
      const v = stats.toNumber(vFn(row));
      if (g != null && Number.isFinite(v)) {
        sums[g] = (sums[g] || 0) + v;
      }
    }
    return augmentObject(sums);
  };

  collections.groupAvg = (data, groupKey, valKey) => {
    const gFn = safeKeyFn(groupKey);
    const vFn = safeKeyFn(valKey);
    const sums = {};
    const counts = {};
    for (const row of (data || [])) {
      const g = gFn(row);
      const v = stats.toNumber(vFn(row));
      if (g != null && Number.isFinite(v)) {
        sums[g] = (sums[g] || 0) + v;
        counts[g] = (counts[g] || 0) + 1;
      }
    }
    const avgs = {};
    for (const k in sums) avgs[k] = sums[k] / counts[k];
    return augmentObject(avgs);
  };
  collections.groupMean = collections.groupAvg;

  // 2. EXTENSION: Hybrid Correlation
  const correlationHybrid = function(xs, ys) {
    return correlation.correlation(xs, ys);
  };
  Object.assign(correlationHybrid, correlation);

  if (correlation && typeof correlation.rankDrivers === "function") {
  const _origRankDrivers = correlation.rankDrivers;

  const collectKeys = (rows, maxRows = 80) => {
    const set = new Set();
    for (let i = 0; i < Math.min(rows.length, maxRows); i++) {
      const r = rows[i];
      if (r && typeof r === "object") {
        for (const k of Object.keys(r)) set.add(k);
      }
    }
    return Array.from(set);
  };

  const suffixOf = (col) => {
    const parts = String(col).split("-");
    return parts.length > 1 ? parts[parts.length - 1].trim() : String(col).trim();
  };

  const prefixOf = (col) => {
    const s = String(col);
    const idx = s.lastIndexOf("-");
    return idx >= 0 ? s.slice(0, idx).trim() : s.trim();
  };

  const resolveCols = (keys, token) => {
    const t = String(token || "").trim();
    if (!t) return [];

    // 1) Exact match wins
    if (keys.includes(t)) return [t];

    const tl = t.toLowerCase();

    // 2) Prefer exact suffix match (prevents "Gross Profit" accidentally matching "Gross Profit %")
    const bySuffix = keys.filter(k => suffixOf(k).toLowerCase() === tl);
    if (bySuffix.length) return bySuffix;

    // 3) Fallback: substring match
    return keys.filter(k => String(k).toLowerCase().includes(tl));
  };

  const pearsonStream = (iterPairs) => {
    let n = 0;
    let meanX = 0, meanY = 0;
    let Sx = 0, Sy = 0, C = 0;

    for (const [x, y] of iterPairs) {
      n++;
      const dx = x - meanX; meanX += dx / n;
      const dy = y - meanY; meanY += dy / n;
      Sx += dx * (x - meanX);
      Sy += dy * (y - meanY);
      C  += dx * (y - meanY);
    }

    if (n < 2) return { corr: 0, n };
    const denom = Math.sqrt(Sx * Sy);
    return { corr: denom ? (C / denom) : 0, n };
  };

  const rankDriversWide = (rows, targetToken, candidateTokens) => {
    const keys = collectKeys(rows);
    const tCols = resolveCols(keys, targetToken);
    if (!tCols.length) return [];

    const tPrefixToCol = new Map();
    for (const tc of tCols) tPrefixToCol.set(prefixOf(tc), tc);
    const tPrefixesOrdered = tCols.map(prefixOf);

    const out = [];

    for (const cand of candidateTokens) {
      const cCols = resolveCols(keys, cand);
      if (!cCols.length) {
        out.push({
          field: cand,
          driver_field: cand,
          correlation: 0,
          absCorrelation: 0,
          spearman: 0,
          mutualInfo: 0,
          r2: 0,
          slope: 0,
          n: 0,
          evidence_n: 0,
        });
        continue;
      }

      const cPrefixToCol = new Map();
      for (const cc of cCols) cPrefixToCol.set(prefixOf(cc), cc);

      const prefixes = tPrefixesOrdered.filter(p => cPrefixToCol.has(p) && tPrefixToCol.has(p));

      // Build deterministic pair stream across aligned periods
      function* pairIterator() {
        for (const r of rows) {
          for (const p of prefixes) {
            const x = stats.toNumber(r[cPrefixToCol.get(p)]);
            const y = stats.toNumber(r[tPrefixToCol.get(p)]);
            if (Number.isFinite(x) && Number.isFinite(y)) yield [x, y];
          }
        }
      }

      // Pearson on full stream (streaming, safe for big data)
      const { corr, n } = pearsonStream(pairIterator());

      // For optional extra stats, take a deterministic sample (first N pairs)
      const MAX_SAMPLE = 20000;
      const xs = [];
      const ys = [];
      let taken = 0;
      for (const [x, y] of pairIterator()) {
        xs.push(x); ys.push(y);
        taken++;
        if (taken >= MAX_SAMPLE) break;
      }

      const spear = (xs.length >= 2 && typeof correlation.spearman === "function")
        ? correlation.spearman(xs, ys)
        : 0;

      const reg = (xs.length >= 2 && typeof correlation.linearRegression === "function")
        ? correlation.linearRegression(xs, ys)
        : null;

      out.push({
        field: cand,
        driver_field: cand,
        correlation: corr,
        absCorrelation: Math.abs(corr),
        spearman: spear,
        mutualInfo: 0,
        r2: reg ? reg.r2 : (corr * corr),
        slope: reg ? reg.slope : 0,
        n: n,
        evidence_n: n,
      });
    }

    // Sort strongest first, deterministic
    out.sort((a, b) => (b.absCorrelation - a.absCorrelation) || String(a.field).localeCompare(String(b.field)));
    return out;
  };

  correlation.rankDrivers = function (data, targetField, candidateFields) {
    const rows = Array.isArray(data) ? data : [];
    let c = candidateFields;
    if (c == null) c = [];
    else if (Array.isArray(c)) c = c;
    else if (typeof c === "string") c = [c];
    else if (typeof c === "object") c = Object.keys(c);
    else c = [];

    // If exact columns exist, keep original behavior (safe for normal long-form datasets)
    const keys = collectKeys(rows, 50);
    const hasExactTarget = typeof targetField === "string" && keys.includes(targetField);
    const hasExactCand = c.some(x => keys.includes(x));

    const base = (hasExactTarget && hasExactCand) ? _origRankDrivers(rows, targetField, c) : null;
    const normalized = Array.isArray(base) ? base.map(d => ({
      ...d,
      driver_field: d.driver_field ?? d.field,
      evidence_n: d.evidence_n ?? d.n
    })) : null;

    // If original gave something usable, return it.
    if (normalized && normalized.some(d => Number.isFinite(d.correlation) && d.n >= 2)) return normalized;

    // Otherwise: wide/pattern fallback
    return rankDriversWide(rows, targetField, c);
  };

    // CRITICAL: keep the hybrid copy in sync (generated code uses _.correlation.rankDrivers)
  correlationHybrid.rankDrivers = correlation.rankDrivers;
}


  // 3. EXTENSION: Add Date Component Extractors (Smart-Patch)
  // Replaces the basic extractors to handle pre-extracted numbers (e.g., hour=14) gracefully.
  const smartDatePart = (d, method, limit) => {
    if (d == null || d === "") return undefined;
    if (d instanceof Date) return isNaN(d.getTime()) ? undefined : d[method]();
    
    const n = Number(d);
    // If it's a small number (e.g. 14), assume it is ALREADY the component, not a timestamp.
    // Timestamps are usually huge (billions). We use 10,000 as a safe cutoff.
    if (Number.isFinite(n)) {
        if (n >= 0 && n < 10000) return Math.floor(n);
        const dt = new Date(n);
        return isNaN(dt.getTime()) ? undefined : dt[method]();
    }
    
    // Fallback: Try parsing string as date
    const dt = new Date(d);
    return isNaN(dt.getTime()) ? undefined : dt[method]();
  };

  Object.assign(dates, {
    hour: (d) => smartDatePart(d, 'getHours', 24),
    minute: (d) => smartDatePart(d, 'getMinutes', 60),
    second: (d) => smartDatePart(d, 'getSeconds', 60),
    millisecond: (d) => smartDatePart(d, 'getMilliseconds', 1000),
    year: (d) => smartDatePart(d, 'getFullYear', 9999),
    month: (d) => {
        // Special handling: If number 1-12, return it. If Date, return getMonth()+1.
        if (d instanceof Date) return d.getMonth() + 1;
        const n = Number(d);
        if (Number.isFinite(n) && n > 0 && n <= 12) return Math.floor(n);
        const dt = new Date(d);
        return isNaN(dt.getTime()) ? undefined : dt.getMonth() + 1;
    },
    isoWeek: (d) => {
        if (typeof d === 'number' && d > 0 && d < 54) return d;
        const date = new Date(d);
        if (isNaN(date.getTime())) return undefined;
        date.setHours(0, 0, 0, 0);
        date.setDate(date.getDate() + 3 - (date.getDay() + 6) % 7);
        const week1 = new Date(date.getFullYear(), 0, 4);
        return 1 + Math.round(((date.getTime() - week1.getTime()) / 86400000 - 3 + (week1.getDay() + 6) % 7) / 7);
    }
  });

// 4. FIX: Robust crossTab2D (robust count/sum behavior)
collections.crossTab2D = (data, rowKey, colKey, valueFn = null) => {
  const rows = Array.isArray(data) ? data : [];
  const rFn = safeKeyFn(rowKey);
  const cFn = safeKeyFn(colKey);

  // If valueFn is null/undefined/"null"/"undefined"/"" => count rows
  const isExplicitCount =
    (valueFn == null || valueFn === "null" || valueFn === "undefined" || valueFn === "");

  const vFn = !isExplicitCount ? safeKeyFn(valueFn) : null;

  const out = {};
  for (const r of rows) {
    const rk = rFn(r);
    const ck = cFn(r);
    if (rk == null || ck == null) continue;

    let val;
    if (isExplicitCount) {
      val = 1;
    } else {
      const raw = vFn(r);
      const num = stats.toNumber(raw);

      if (Number.isFinite(num)) val = num;
      else if (raw != null && raw !== "") val = 1;   // non-numeric present => count
      else val = 1;                                  // missing field => count (heatmap zero fix)
    }

    if (!out[rk]) out[rk] = {};
    out[rk][ck] = (Number(out[rk][ck]) || 0) + val;
  }

  return augmentObject(out);
};



  // -------------------------------------------------------------------------
  // CRITICAL FIX: Attach Advanced Modules to Collections
  // -------------------------------------------------------------------------
  Object.assign(collections, {
    // Cooccurrence Family
    basketAnalysis: cooccurrence.basketAnalysis,
    associationRules: cooccurrence.associationRules,
    extractSets: cooccurrence.extractSets,
    tfidf: cooccurrence.tfidf,
    nWiseCooccurrence: cooccurrence.nWiseCooccurrence,
    crossTab2D: collections.crossTab2D,          
    pairCountsFromField: cooccurrence.pairCountsFromField,
    
    // Patterns Family
    patternFreq: patterns.patternFreq,
    sequenceMotifs: patterns.sequenceMotifs,
    predictNextPattern: patterns.predictNextPattern,
    
    // Markov Family
    markovTransitionCounts: markov.markovTransitionCounts,
    markovTransitionMatrix: markov.markovTransitionMatrix,

     // Migrations Aliases
    toTrajectories: migrations.toTrajectories,
    migrationSummary: migrations.migrationSummary,
    trackMigrations: migrations.toTrajectories,
    detectSwitching: migrations.detectSwitching,
    flowMatrix: migrations.flowMatrix,
    
    // Network Family
    degreeCount: network.degreeCount,
    adjacencyList: network.adjacencyList,
    cooccurrenceNetwork: network.cooccurrenceNetwork
  });

  const polyfillArrayMethods = () => {
  // 1. ESSENTIAL PROTOTYPES (If missing in environment)
  if (!Array.prototype.flat) {
    Array.prototype.flat = function(depth = 1) {
      return (function flat(arr, d) {
        return d > 0 ? arr.reduce((acc, val) => acc.concat(Array.isArray(val) ? flat(val, d - 1) : val), []) : arr.slice();
      })(this, depth);
    };
  }
  if (!Array.prototype.flatMap) {
    Array.prototype.flatMap = function(cb, thisArg) {
      return this.map(cb, thisArg).flat();
    };
  }
  if (!String.prototype.replaceAll) {
    String.prototype.replaceAll = function(str, newStr) {
      if (Object.prototype.toString.call(str).toLowerCase() === '[object regexp]') return this.replace(str, newStr);
      return this.split(str).join(newStr);
    };
  }

  // 2. OBJECT AUGMENTATION
  if (typeof Object.fromEntries !== 'function') {
    Object.defineProperty(Object, 'fromEntries', {
      value: (entries) => {
        if (!entries || !entries[Symbol.iterator]) return {};
        const obj = {};
        for (const [k, v] of entries) obj[k] = v;
        return obj;
      }, writable: true, configurable: true
    });
  }
  if (typeof Object.fromPairs !== 'function') {
    Object.defineProperty(Object, 'fromPairs', {
      value: Object.fromEntries, writable: true, configurable: true
    });
  }

  // 2B. SAFE "ARRAY-LIKE" METHODS FOR NON-ARRAYS
  // Prevents: "X.filter is not a function" when X is an object/number/string but code treats it like an array.
  if (!Object.prototype.__sera_arraylike_patched) {
    const toArrayLike = (v) => {
      if (Array.isArray(v)) return v;
      if (v == null) return [];

      // Typed arrays (Float64Array, etc.)
      try {
        if (typeof ArrayBuffer !== "undefined" && ArrayBuffer.isView && ArrayBuffer.isView(v)) {
          return Array.from(v);
        }
      } catch (_) {}

      // Map/Set
      try {
        if (v instanceof Set) return Array.from(v.values());
        if (v instanceof Map) return Array.from(v.values());
      } catch (_) {}

      // Common wrapper shapes (compression / outputs)
      if (typeof v === "object") {
        if (Array.isArray(v.data)) return v.data;
        if (Array.isArray(v.values)) return v.values;

        // numeric-keyed objects: {0: x, 1: y, ...}
        const keys = Object.keys(v);
        const numericKeys = keys.filter(k => String(Number(k)) === k);
        if (numericKeys.length) {
          numericKeys.sort((a, b) => Number(a) - Number(b));
          return numericKeys.map(k => v[k]);
        }

        return Object.values(v);
      }

      // primitives => []
      return [];
    };

    const define = (name, impl) => {
      if (typeof Object.prototype[name] === "function") return;
      Object.defineProperty(Object.prototype, name, {
        value: impl,
        writable: true,
        configurable: true,
        enumerable: false
      });
    };

    define("map", function (fn, thisArg) {
      const arr = toArrayLike(this);
      return Array.prototype.map.call(arr, fn, thisArg);
    });

    define("filter", function (fn, thisArg) {
      const arr = toArrayLike(this);
      return Array.prototype.filter.call(arr, fn, thisArg);
    });

    define("forEach", function (fn, thisArg) {
      const arr = toArrayLike(this);
      return Array.prototype.forEach.call(arr, fn, thisArg);
    });

    define("reduce", function (fn, init) {
      const arr = toArrayLike(this);
      return (arguments.length >= 2)
        ? Array.prototype.reduce.call(arr, fn, init)
        : Array.prototype.reduce.call(arr, fn);
    });

    Object.defineProperty(Object.prototype, "__sera_arraylike_patched", {
      value: true, writable: false, configurable: true, enumerable: false
    });
  }


  // 3. SAFE ARRAY METHODS (Wrapper for "safeKeyFn")
  if (!Array.prototype.__sera_patched) {
    // FIX: Added 'forEach' to this list to prevent crashes on unsafe iterations
    const methods = ["map", "filter", "some", "every", "find", "findIndex", "flatMap", "forEach"];
    methods.forEach((method) => {
      const original = Array.prototype[method];
      if (typeof original === "function") {
        Array.prototype[method] = function (iteratee, ...args) {
          if (this == null) return []; // Safety guard against null/undefined arrays
          // Intercept non-function predicates (e.g. "field")
          if (iteratee != null && typeof iteratee !== "function") {
            const fn = safeKeyFn(iteratee);
            return original.call(this, fn, ...args);
          }
          return original.apply(this, [iteratee, ...args]);
        };
      }
    });

    // 4. ROBUST SORT
    const origSort = Array.prototype.sort;
    Array.prototype.sort = function (compareFn) {
      if (typeof compareFn === "string") {
        const fn = safeKeyFn(compareFn);
        return origSort.call(this, (a, b) => {
          const va = fn(a);
          const vb = fn(b);
          if (typeof va === 'number' && typeof vb === 'number') return va - vb;
          return String(va).localeCompare(String(vb));
        });
      }
      return origSort.apply(this, arguments);
    };
    
    Object.defineProperty(Array.prototype, "__sera_patched", { value: true, enumerable: false });
  }
};

  // =========================================================================
  // NEW MODULE: PROBABILITY (Distributions & Tests)
  // =========================================================================
  const probability = {
    // Cumulative Distribution Function (Normal)
    normalCDF: (x, mean = 0, stdDev = 1) => {
      const m = stats.toNumber(mean);
      const s = stats.toNumber(stdDev);
      const val = stats.toNumber(x);
      if (s === 0) return val < m ? 0 : 1;
      
      // Error function approximation
      const z = (val - m) / s / Math.sqrt(2);
      const t = 1.0 / (1.0 + 0.3275911 * Math.abs(z));
      const poly = 1.0 - (((((1.061405429 * t - 1.453152027) * t) + 1.421413741) * t - 0.284496736) * t + 0.254829592) * t * Math.exp(-z * z);
      return 0.5 * (1.0 + (z < 0 ? -poly : poly));
    },

    // Probability Density Function (Normal)
    normalPDF: (x, mean = 0, stdDev = 1) => {
      const m = stats.toNumber(mean);
      const s = stats.toNumber(stdDev);
      const val = stats.toNumber(x);
      if (s === 0) return 0;
      return (1 / (s * Math.sqrt(2 * Math.PI))) * Math.exp(-0.5 * Math.pow((val - m) / s, 2));
    },

    // Probability of falling between min and max
    probabilityRange: (min, max, mean, stdDev) => {
      return probability.normalCDF(max, mean, stdDev) - probability.normalCDF(min, mean, stdDev);
    },

    // Calculate probability that Next Value > Target based on history
    probGreater: (arr, target) => {
       const nums = stats.compactNumbers(arr);
       if (nums.length < 2) return 0;
       const m = stats.mean(nums);
       const s = stats.stddev(nums);
       // 1 - CDF(target) = Probability of being above target
       return 1 - probability.normalCDF(target, m, s);
    }
  };

  // =========================================================================
  // NEW MODULE: FINANCE (Sharpe, Sortino, Drawdown)
  // =========================================================================
  const finance = {
    /**
     * Calculates Sharpe Ratio: (Mean Return - Risk Free Rate) / StdDev of Returns
     * Input: Array of raw values (prices/balances) OR Array of % returns.
     * If inputs are > 2.0 (e.g., prices 100, 105), it calculates returns automatically.
     */
    sharpeRatio: (data, riskFreeRate = 0.0) => {
      const nums = stats.compactNumbers(data);
      if (nums.length < 2) return 0;

      // Detect if data is Prices or Returns
      const avg = stats.mean(nums);
      let returns = [];
      
      // If average is > 2, assume these are prices -> convert to % returns
      if (Math.abs(avg) > 2.0) {
        for(let i=1; i<nums.length; i++) {
            returns.push((nums[i] - nums[i-1]) / nums[i-1]);
        }
      } else {
        returns = nums;
      }

      if (!returns.length) return 0;
      const meanR = stats.mean(returns);
      const stdR = stats.stddev(returns);
      if (!stdR) return 0;
      
      // Annualize adjustment (optional, assuming generic periods here)
      return (meanR - riskFreeRate) / stdR;
    },

    /**
     * Sortino Ratio: Like Sharpe, but only penalizes downside volatility.
     */
    sortinoRatio: (data, targetReturn = 0.0) => {
       const nums = stats.compactNumbers(data);
       if (nums.length < 2) return 0;

       // Auto-convert prices to returns if needed
       const avg = stats.mean(nums);
       let returns = [];
       if (Math.abs(avg) > 2.0) {
         for(let i=1; i<nums.length; i++) returns.push((nums[i] - nums[i-1]) / nums[i-1]);
       } else {
         returns = nums;
       }

       const meanR = stats.mean(returns);
       
       // Downside Deviation calculation
       const downside = returns.filter(r => r < targetReturn).map(r => Math.pow(r - targetReturn, 2));
       const downsideDev = Math.sqrt(stats.sum(downside) / returns.length);

       if (!downsideDev) return 0;
       return (meanR - targetReturn) / downsideDev;
    },

    /**
     * Maximum Drawdown: Largest peak-to-trough decline
     */
    maxDrawdown: (data) => {
       const nums = stats.compactNumbers(data);
       if (!nums.length) return 0;
       let max = nums[0];
       let maxDD = 0;
       for(const val of nums) {
           if (val > max) max = val;
           const dd = (max - val) / max;
           if (dd > maxDD) maxDD = dd;
       }
       return maxDD;
    }
  };

  // -------------------------------------------------------------------------
  // =========================================================================
  // SERA v3.1: CROSS-MODULE ALIASES
  // The upstream AI frequently guesses wrong module paths (e.g., _.stats.growthPct
  // when growthPct lives on timeseries). These aliases ensure common guesses work.
  // =========================================================================

  // Timeseries functions → also available on stats (AI thinks "growth = math = stats")
  Object.assign(stats, {
    growth: timeseries.growth,
    growthPct: timeseries.growthPct,
    movingAvg: timeseries.movingAvg,
    pctChangeSorted: timeseries.pctChangeSorted,
    pctChange: timeseries.pctChangeSorted,
    movements1D: timeseries.movements1D,
    movementSummary: timeseries.movementSummary,
    momentum: timeseries.momentum,
    acceleration: timeseries.acceleration,
    periodSortKey: timeseries.periodSortKey,
    chronoSort: timeseries.chronoSort,
    periodMovements: timeseries.periodMovements,
    periodMovingAvg: timeseries.periodMovingAvg,
    rollingAgg: timeseries.rollingAgg,
    periodSummary: timeseries.periodSummary,
    periodCompare: timeseries.periodCompare,
    // Math convenience (AI guesses these live on stats)
    abs: Math.abs,
    sqrt: Math.sqrt,
    pow: Math.pow,
    log: Math.log,
    log10: Math.log10,
    exp: Math.exp,
    sign: Math.sign,
    // Alias bridges
    normalize: (arr) => stats.normalizeZ(arr),
    scale: (arr) => stats.minMaxScale(arr),
    standardize: (arr) => stats.normalizeZ(arr),
    outliers: (arr) => stats.iqrOutliers(arr),
    rollingMean: timeseries.movingAvg,
    rollingAvg: timeseries.movingAvg,
  });

  // Correlation functions → also available on stats (AI thinks "pearson = stats")
  Object.assign(stats, {
    corr: correlation.correlation,
    pearson: correlation.correlation,
    pearsonCorrelation: correlation.correlation,
    spearman: correlation.spearman,
    kendall: correlation.kendall,
    kendallTau: correlation.kendall,
    linearRegression: correlation.linearRegression,
    linReg: correlation.linearRegression,
    correlationMatrix: correlation.correlationMatrix,
    mutualInfo: correlation.mutualInformation,
    rankCorrelation: correlation.spearman,
  });

  // Regression aliases on correlation (AI might try _.correlation.linearRegression)
  if (typeof correlationHybrid === "object" && correlationHybrid) {
    correlationHybrid.linearRegression = correlationHybrid.linearRegression || correlation.linearRegression;
    correlationHybrid.linReg = correlationHybrid.linReg || correlation.linearRegression;
    correlationHybrid.pearson = correlationHybrid.pearson || correlation.correlation;
  }

  // Stats functions → also available on finance (AI thinks "cagr = finance")
  Object.assign(finance, {
    cagr: stats.cagr,
    volatility: stats.volatility,
    gini: stats.gini,
    growthPct: timeseries.growthPct,
    growth: timeseries.growth,
  });

  // Stats functions → also available on collections (AI thinks "sum a column = collections")
  Object.assign(collections, {
    sum: (arr, fn) => fn ? stats.sum(arr.map(safeKeyFn(fn))) : stats.sum(arr),
    mean: (arr, fn) => fn ? stats.mean(arr.map(safeKeyFn(fn))) : stats.mean(arr),
    avg: (arr, fn) => fn ? stats.mean(arr.map(safeKeyFn(fn))) : stats.mean(arr),
    min: (arr, fn) => fn ? stats.min(arr.map(safeKeyFn(fn))) : stats.min(arr),
    max: (arr, fn) => fn ? stats.max(arr.map(safeKeyFn(fn))) : stats.max(arr),
    median: (arr, fn) => fn ? stats.median(arr.map(safeKeyFn(fn))) : stats.median(arr),
    toNumber: stats.toNumber,
  });

  // Timeseries functions → also available on collections
  Object.assign(collections, {
    sortByPeriod: timeseries.chronoSort,
    chronoSort: timeseries.chronoSort,
  });

  // 5. MAIN EXPORT OBJECT (_)
  // -------------------------------------------------------------------------
  const _ = {
    polyfillArrayMethods,

    // Core Modules
    quality,
    optimization,
    correlation: correlationHybrid,
    stats,
    collections,
    timeseries,
    timeSeries: timeSeriesHybrid,
    histogram,
    clustering,
    similarity,
    anomalies, 
    markov,
    patterns,
    cooccurrence,
    network,
    predictive,
    spectral,
    decisionTree,
    survival,
    causality,
    dates,

    // Aliases for Advanced Analytics
    fft: spectral.fft,
    seasonality: spectral.detectSeasonality,
    trainClassifier: decisionTree.trainClassifier,
    kaplanMeier: survival.kaplanMeier,
    survivalCurve: survival.kaplanMeier,
    granger: causality.grangerTest,

    // Quality Aliases
    profile: quality.profile,
    missingness: quality.missingness,
    duplicates: quality.duplicates,
    valueCounts: quality.valueCounts,
    typeProfile: quality.typeProfile,
    outlierRows: quality.outliers,

    // Optimization Aliases
    frontierEfficiency: optimization.frontierEfficiency,
    paretoFrontier: optimization.paretoFrontier,
    opportunityCost: optimization.opportunityCost,

    // Grouping Aliases
    groupSum: collections.groupSum,
    groupAvg: collections.groupAvg,
    groupMean: collections.groupAvg,

    // Lodash Patterns (Get/Set/Merge/etc)
    lodashPatterns: lodashPatterns,

    // Type Checks
    isDate: types.isDate,
    isString: types.isString,
    isNumber: types.isNumber,
    isBoolean: types.isBoolean,
    isArray: types.isArray,
    isObject: types.isObject,
    isPlainObject: types.isPlainObject,
    isFunction: types.isFunction,
    isNil: types.isNil,
    isNull: types.isNull,
    isUndefined: types.isUndefined,
    isElement: types.isElement,
    isRegExp: types.isRegExp,
    isError: types.isError,
    isNaN: types.isNaN,
    castArray: types.castArray,

    // Collection Aliases
    map: collections.map,
    filter: collections.filter,
    where: collections.filter,
    mapValues: collections.mapValues,
    reduce: collections.reduce,
    each: collections.each,
    forEach: collections.each,
    find: collections.find,
    maxBy: collections.maxBy,
    minBy: collections.minBy,
    reject: collections.reject,
    findLast: collections.findLast,
    difference: collections.difference,
    intersection: collections.intersection,
    orderBy: collections.orderBy,
    sort: collections.sortBy,
    sortBy: collections.sortBy,
    keyBy: collections.keyBy,
    indexBy: collections.keyBy,
    countBy: collections.countBy,
    distribute: collections.countBy,
    group: collections.groupBy,
    groupBy: collections.groupBy,
    pick: collections.pick,
    omit: collections.omit,
    isEmpty: collections.isEmpty,
    sample: collections.sample,
    first: collections.first,
    head: collections.head,
    last: collections.last,
    slice: collections.slice,
    includes: collections.includes,
    contains: collections.includes,
    indexOf: collections.indexOf,
    reverse: collections.reverse,
    concat: collections.concat,
    take: collections.take,
    takeRight: collections.takeRight,
    distinct: collections.unique,
    limit: collections.take,
    skip: (arr, n) => collections.slice(arr, n),
    offset: (arr, n) => collections.slice(arr, n),
    tail: (arr) => collections.slice(arr, 1),
    pluck: (arr, key) => collections.map(arr, key),

    // Stats Aliases
    toNumber: stats.toNumber,
    isFinite: stats.isFinite,
    compactNumbers: stats.compactNumbers,
    sum: stats.sum,
    avg: stats.avg,
    mean: stats.mean,
    average: stats.avg,
    min: stats.min,
    max: stats.max,
    clamp: stats.clamp,
    safeDiv: stats.safeDiv,
    round: stats.round,
    _round: stats._round,
    floor: stats.floor,
    ceil: stats.ceil,
    variance: stats.variance,
    var: stats.variance,
    stddev: stats.stddev,
    stdDev: stats.stddev,
    std: stats.stddev,
    stdev: stats.stddev,
    standardDeviation: stats.stddev,
    zScores: stats.zScores,
    percentile: stats.percentile,
    median: stats.median,
    mode: stats.mode,
    normalizeZ: stats.normalizeZ,
    minMaxScale: stats.minMaxScale,
    entropy: stats.entropy,
    volatility: stats.volatility,
    stabilityIndex: stats.stabilityIndex,
    iqrOutliers: stats.iqrOutliers,
    zScoreOutliers: stats.zScoreOutliers,
    spikeDetection: stats.spikeDetection,
    breakpoints: stats.breakpoints,
    quantile: stats.quantile,
    geometricMean: stats.geometricMean,
    harmonicMean: stats.harmonicMean,
    mad: stats.mad,
    skewness: stats.skewness,
    skew: stats.skewness,
    kurtosis: stats.kurtosis,
    kurt: stats.kurtosis,
    sem: stats.sem,
    standardError: stats.sem,
    confidenceInterval: stats.confidenceInterval,
    ci: stats.confidenceInterval,
    trimmedMean: stats.trimmedMean,
    winsorizedMean: stats.winsorizedMean,
    weightedMean: stats.weightedMean,
    covariance: stats.covariance,
    cov: stats.covariance,
    covarianceMatrix: stats.covarianceMatrix,
    rollingStd: stats.rollingStd,
    rollingVolatility: stats.rollingStd,
    ecdf: stats.ecdf,

    // Array/Collection Stats
    size: collections.size,
    count: collections.count,
    unique: collections.unique,
    uniq: collections.unique,
    mapNumbers: collections.mapNumbers,
    sumBy: collections.sumBy,
    meanBy: collections.meanBy,
    safePct: collections.safePct,
    countDistinct: collections.countDistinct,
    flatMap: collections.flatMap,
    findIndex: collections.findIndex,
    partition: collections.partition,
    shuffle: collections.shuffle,
    at: collections.at,
    topNBy: collections.topNBy,
    bottomNBy: collections.bottomNBy,
    rankBy: collections.rankBy,
    flatten: collections.flatten,
    flattenDeep: collections.flattenDeep,
    chunk: collections.chunk,
    zip: collections.zip,
    unzip: collections.unzip,
    range: collections.range,
    safeGet: collections.safeGet,
    
    // Added from Cooccurrence/Patterns
    basketAnalysis: collections.basketAnalysis,
    associationRules: collections.associationRules,
    patternFreq: collections.patternFreq,

    // Timeseries
    safeDate: timeseries.safeDate,
    periodKey: timeseries.periodKey,
    growth: timeseries.growth,
    growthPct: timeseries.growthPct,
    movingAvg: timeseries.movingAvg,
    movements1D: timeseries.movements1D,
    nMovements: timeseries.nMovements,
    movementSummary: timeseries.movementSummary,
    runLengths: timeseries.runLengths,
    turningPoints: timeseries.turningPoints,
    momentum: timeseries.momentum,
    acceleration: timeseries.acceleration,

    // Period-aware timeseries (SERA v3.0)
    periodSortKey: timeseries.periodSortKey,
    chronoSort: timeseries.chronoSort,
    periodMovements: timeseries.periodMovements,
    periodMovingAvg: timeseries.periodMovingAvg,
    periodCompare: timeseries.periodCompare,
    rollingAgg: timeseries.rollingAgg,
    periodSummary: timeseries.periodSummary,

    // Correlation
    pearsonCorrelation: correlation.correlation,
    pearson: correlation.correlation,
    spearman: correlation.spearman,
    rankCorrelation: correlation.spearman,
    kendall: correlation.kendall,
    kendallTau: correlation.kendall,
    mutualInfo: correlation.mutualInformation,
    mutualInformation: correlation.mutualInformation,
    crossCorrelation: correlation.crossCorrelation,
    crossCorr: correlation.crossCorrelation,
    autocorrelation: correlation.autocorrelation,
    acf: correlation.autocorrelation,
    partialCorrelation: correlation.partialCorrelation,
    partial: correlation.partialCorrelation,
    corr: correlation.correlation,
    linearRegression: correlation.linearRegression,
    linReg: correlation.linearRegression,
    forecastLinear: correlation.forecastLinear,
    correlationByGroup: correlation.correlationByGroup,
    correlationMatrix: correlation.correlationMatrix,
    rankDrivers: correlation.rankDrivers,

    // Advanced Regression
    multipleLinearRegression: regression.multipleLinearRegression,
    mlr: regression.multipleLinearRegression,
    ridgeRegression: regression.ridgeRegression,
    logisticRegression: regression.logisticRegression,
    logit: regression.logisticRegression,
    regressionDiagnostics: regression.regressionDiagnostics,
    diagnostics: regression.regressionDiagnostics,
    bootstrapRegressionSlopeCI: regression.bootstrapRegressionSlopeCI,
    bootstrapSlope: regression.bootstrapRegressionSlopeCI,

    // Anomaly Detection
    madOutliers: anomalies.madOutliers,
    madAnomaly: anomalies.madOutliers,
    rollingZScore: anomalies.rollingZScore,
    rollingOutliers: anomalies.rollingZScore,
    seasonalAnomaly: anomalies.seasonalAnomaly,
    seasonalOutliers: anomalies.seasonalAnomaly,
    isolationScore: anomalies.isolationScore,
    isolation: anomalies.isolationScore,

    // Hallucination Fixes
    getCorrelation: correlation.correlation,
    getQuantiles: stats.quantile,
    getPercentiles: stats.percentile,
    getQuantile: stats.quantile,
    getPercentile: stats.percentile,

    // Histogram & Clustering
    bucketByThresholds: histogram.bucketByThresholds,
    histogram: histogram.histogram,
    bucketize: histogram.bucketize,
    kmeans: clustering.kmeans,
    dbscan: clustering.dbscan,
    hierarchical: clustering.hierarchical,
    agglomerative: clustering.hierarchical,
    pca: clustering.pca,
    elbow: clustering.kSelectionElbow,
    silhouette: clustering.silhouetteScore,
    dot: similarity.dot,
    cosine: similarity.cosine,
    euclid: similarity.euclid,
    manhattan: similarity.manhattan,
    jaccard: similarity.jaccard,

    // Markov & Patterns
    markovTransitionCounts: markov.markovTransitionCounts,
    markovTransitionMatrix: markov.markovTransitionMatrix,
    markovNextDistribution: markov.markovNextDistribution,
    markovRollout: markov.markovRollout,
    stateDurations: markov.stateDurations,
    simulatePath: markov.simulatePath,
    stationaryDistribution: markov.stationaryDistribution,
    absorbingStates: markov.absorbingStates,
    expectedStepsToAbsorption: markov.expectedStepsToAbsorption,
    entropyRate: markov.entropyRate,
    patternFreq: patterns.patternFreq,
    normalizedPatternFreq: patterns.normalizedPatternFreq,
    tolerancePatternFreq: patterns.tolerancePatternFreq,
    predictNextPattern: patterns.predictNextPattern,
    sequenceMotifs: patterns.sequenceMotifs,

    // Cooccurrence & Network
    extractSets: cooccurrence.extractSets,
    pairCountsFromField: cooccurrence.pairCountsFromField,
    nWiseCooccurrence: cooccurrence.nWiseCooccurrence,
    crossTab2D: cooccurrence.crossTab2D,
    associationRules: cooccurrence.associationRules,
    tfidf: cooccurrence.tfidf,
    degreeCount: network.degreeCount,
    adjacencyList: network.adjacencyList,
    cooccurrenceNetwork: network.cooccurrenceNetwork,

    // Predictive
    trendProjection: predictive.trendProjection,
    rollingRegression: predictive.rollingRegression,
    frequencyBasedPrediction: predictive.frequencyBasedPrediction,
    anomalyForecast: predictive.anomalyForecast,
    segmentationPredictor: predictive.segmentationPredictor,

    // Dates & Misc
    cagr: stats.cagr,
    gini: stats.gini,
    dateDiff: dates.dateDiff,
    addDate: dates.addDate,
    subtractDate: dates.subtractDate,
    startOf: dates.startOf,
    endOf: dates.endOf,
    formatDate: dates.formatDate,
    
    // 6. FIX: Add date part extractors to the root object
    hour: dates.hour,
    minute: dates.minute,
    second: dates.second,
    millisecond: dates.millisecond,
    isoWeek: dates.isoWeek,

    probability: probability,
    prob: probability,
    normalCDF: probability.normalCDF,
    
    finance: finance,
    sharpeRatio: finance.sharpeRatio,
    sharpe: finance.sharpeRatio,
    sortinoRatio: finance.sortinoRatio,
    maxDrawdown: finance.maxDrawdown,

    // SERA v3.1: Expose commonly AI-guessed module namespaces
    regression: regression,
    // NOTE: strings added post-hoc below (defined after _ due to file ordering)
    types: types,

    safeKeyFn, 
    augmentObject
  };

  // Proactive Fix: Auto-Generate 'get' Accessors
  for (const key of Object.keys(_)) {
    if (typeof _[key] === "function" && !key.startsWith("get")) {
      const alias = "get" + key.charAt(0).toUpperCase() + key.slice(1);
      if (!Object.prototype.hasOwnProperty.call(_, alias)) {
        _[alias] = _[key];
      }
    }
  }

  _.chain = function(source) {
    let _val = source;
    const wrapper = {
      value: () => _val,
      toJSON: () => _val
    };
    for (const key in _) {
      if (typeof _[key] === "function" && key !== "chain") {
        wrapper[key] = (...args) => {
          _val = _[key](_val, ...args);
          return wrapper;
        };
      }
    }
    return wrapper;
  };

  _.limit = _.take;
  _.skip = (arr, n) => _.slice(arr, n);
  _.offset = _.skip;
  _.tail = (arr) => _.slice(arr, 1);
  _.compact = (arr) => _.filter(arr, (v) => v);
  _.pluck = (arr, key) => _.map(arr, key);

  Object.assign(_, {
    parseDate: dates.parseDate,
    parse: dates.parse,
    toDate: dates.toDate,
    isValid: dates.isValid,
    isBefore: dates.isBefore,
    isAfter: dates.isAfter,
    isSame: dates.isSame,
    now: dates.now,
    year: dates.year,
    month: dates.month,
    day: dates.day,
    daysInMonth: dates.daysInMonth
  });

  // =========================================================================
  // PATCH: STRINGS & SEARCH (Fixes "Entity Count 0" and "No Literal Match")
  // Replace the entire 'const strings = { ... }' block and everything after it
  // inside Module 2, up until 'return _;' 
  // =========================================================================
  const strings = {
  format: (val, fallback = "N/A") => {
    if (val == null || (typeof val === 'number' && isNaN(val))) return String(fallback);
    if (typeof val === 'object') return JSON.stringify(val);
    return String(val);
  },

  safeNum: (val, decimals = 2, fallback = "0") => {
    const n = Number(val);
    // Force decimals to be a safe integer between 0 and 20
    const d = Math.max(0, Math.min(20, Math.floor(Number(decimals) || 2)));
    
    // PARANOID FIX: Force 'n' to a primitive Number before calling toFixed
    if (Number.isFinite(n)) {
      try {
        return Number(n).toFixed(d);
      } catch (e) {
        return String(fallback);
      }
    }
    return String(fallback);
  },

  safeFixed: (val, decimals = 2) => {
    const n = Number(val);
    // PARANOID FIX: Force 'n' to a primitive Number before calling toFixed
    return Number.isFinite(n) ? Number(n).toFixed(decimals) : "0.00";
  },

  canonical: (s) => String(s || "").toLowerCase().trim().replace(/[\W_]+/g, ""),

  contains: (str, term) => {
    if (str == null || term == null) return false;
    return strings.canonical(str).includes(strings.canonical(term));
  },

  capitalize: (s) => { const str = String(s || ""); return str.charAt(0).toUpperCase() + str.slice(1).toLowerCase(); },
  upper: (s) => String(s || "").toUpperCase(),
  lower: (s) => String(s || "").toLowerCase(),
  trim: (s) => String(s || "").trim(),
  camelCase: (s) => String(s || "").toLowerCase().replace(/[^a-zA-Z0-9]+(.)/g, (m, chr) => chr.toUpperCase()),
  snakeCase: (s) => String(s || "").match(/[A-Z]{2,}(?=[A-Z][a-z]+[0-9]*|\b)|[A-Z]?[a-z]+[0-9]*|[A-Z]|[0-9]+/g)?.map(x => x.toLowerCase()).join("_") || String(s),
  kebabCase: (s) => String(s || "").match(/[A-Z]{2,}(?=[A-Z][a-z]+[0-9]*|\b)|[A-Z]?[a-z]+[0-9]*|[A-Z]|[0-9]+/g)?.map(x => x.toLowerCase()).join("-") || String(s),
  startCase: (s) => String(s || "").replace(/([^a-zA-Z0-9]|^)([a-z])/g, (m, sep, c) => (sep || " ") + c.toUpperCase()).trim(),
  pad: (s, len, chars = " ") => String(s || "").padStart(Math.floor((len - String(s || "").length)/2) + String(s || "").length, chars).padEnd(len, chars),
  repeat: (s, n) => String(s || "").repeat(Math.max(0, n || 0))
};

  // --- ENHANCED SEARCH (Fixes "Entity Count 0") ---
  collections.search = (data, query, fields = null) => {
      if (!Array.isArray(data)) return [];
      if (!query) return data;
      
      const q = strings.canonical(query);
      if (!q) return data;

      return data.filter(row => {
          if (!row || typeof row !== "object") return false;

          let valuesToCheck = [];
          
          if (fields) {
              // Smart Field Access: Handle case mismatches (e.g. "District" vs "district")
              const fieldArr = Array.isArray(fields) ? fields : [fields];
              valuesToCheck = fieldArr.map(f => {
                  let val = row[f];
                  // If exact key fails, look for case-insensitive match
                  if (val === undefined) {
                      const key = Object.keys(row).find(k => k.toLowerCase() === String(f).toLowerCase());
                      if (key) val = row[key];
                  }
                  return val;
              });
          } else {
              // No fields specified? Search EVERY value in the row.
              valuesToCheck = Object.values(row);
          }

          return valuesToCheck.some(val => strings.canonical(val).includes(q));
      });
  };

  // --- Aliases & Cleanup ---
  Object.assign(_, strings);
  _.strings = strings;  // SERA v3.1: plural form (AI guesses both _.string and _.strings)
  _.string = strings;
  _.str = strings;
  _.search = collections.search;

  _.math = _.stats;
  _.statistics = _.stats;
  _.num = _.stats;
  _.calc = _.stats;

  _.array = _.collections;
  _.arr = _.collections;
  _.list = _.collections;
  _.collection = _.collections;

  _.obj = {
    keys: Object.keys,
    values: Object.values,
    entries: Object.entries,
    assign: Object.assign,
   collections: _.collections,
  };
  _.object = _.obj;

  try { Object.defineProperty(_, "util", { value: _, enumerable: false, configurable: true, writable: true }); } catch (_) { try { _.util = _; } catch (_) {} }
  try { Object.defineProperty(_, "utils", { value: _, enumerable: false, configurable: true, writable: true }); } catch (_) { try { _.utils = _; } catch (_) {} }

    // Explicitly expose key analysis functions to root
    Object.assign(_, {
        groupCount: collections.countBy,
        frequencies: collections.countBy,
        valueCounts: collections.countBy,
        pivot: collections.pivot,
        duplicates: collections.duplicates,
        
        // Ensure advanced modules are attached
        kSelectionElbow: clustering.kSelectionElbow,
        silhouetteScore: clustering.silhouetteScore,
        detectSeasonality: spectral.detectSeasonality,
        trainClassifier: decisionTree.trainClassifier,
        kaplanMeier: survival.kaplanMeier,
        grangerTest: causality.grangerTest,
        multipleLinearRegression: regression.multipleLinearRegression,
        logisticRegression: regression.logisticRegression,
        ridgeRegression: regression.ridgeRegression,
        basketAnalysis: cooccurrence.basketAnalysis
    });

    // --- FINAL ALIASES & EXPORT ---

    Object.assign(_, strings);
    _.string = strings;
    _.str = strings;

    _.math = _.stats;
    _.statistics = _.stats;
    _.stat = _.stats;
    _.num = _.stats;
    _.numbers = _.stats;
    _.calc = _.stats;

    _.array = _.collections;
    _.arr = _.collections;
    _.list = _.collections;
    _.collection = _.collections;

    _.obj = {
      keys: Object.keys,
      values: Object.values,
      entries: Object.entries,
      assign: Object.assign,
      ..._.collections
    };
    _.object = _.obj;

    // ==========================================================================
    // FIX START: FINAL ALIASES & EXPORT SECTION (Module 2 Tail)
    // ==========================================================================

    try { Object.defineProperty(_, "util", { value: _, enumerable: false, configurable: true, writable: true }); } catch (_) { try { _.util = _; } catch (_) {} }
    try { Object.defineProperty(_, "utils", { value: _, enumerable: false, configurable: true, writable: true }); } catch (_) { try { _.utils = _; } catch (_) {} }
    try { Object.defineProperty(_, "helpers", { value: _, enumerable: false, configurable: true, writable: true }); } catch (_) { try { _.helpers = _; } catch (_) {} }


    // 1. Assign aliases to 'collections' explicitly before exporting to '_'
    collections.groupCount = collections.countBy;
    collections.frequencies = collections.countBy;
    collections.valueCounts = collections.countBy;

    // 2. DEFINE PIVOT CORRECTLY ON COLLECTIONS (Fixes "pivot is not a function")
    collections.pivot = (data, rowKey, colKey, valKey) => {
      const rFn = safeKeyFn(rowKey);
      const cFn = safeKeyFn(colKey);
      const vFn = safeKeyFn(valKey);
      const result = {};
      for (const row of (data || [])) {
        const rRaw = rFn(row);
        const cRaw = cFn(row);
        
        // Ensure keys are strings and not null/undefined
        if (rRaw != null && cRaw != null) {
          const r = String(rRaw);
          const c = String(cRaw);
          if (!result[r]) result[r] = {};
          result[r][c] = vFn(row);
        }
      }
      return augmentObject(result);
    };

    // 3. DEFINE DUPLICATES CORRECTLY ON COLLECTIONS
    collections.duplicates = (data, key) => {
      const counts = collections.countBy(data, key);
      const dups = [];
      for (const [k, count] of Object.entries(counts)) {
        if (count > 1) dups.push(k);
      }
      return dups;
    };

    // 4. Assign these new methods to the main lodash (_) export
    Object.assign(_, {
      groupCount: collections.groupCount,
      frequencies: collections.frequencies,
      valueCounts: collections.valueCounts,
      pivot: collections.pivot,
      duplicates: collections.duplicates,
      groupByCount: collections.countBy,
      countGroups: collections.countBy
    });

    // 5. Ensure advanced algorithms are reachable via '_'
    Object.assign(_, {
      kSelectionElbow: clustering.kSelectionElbow,
      silhouetteScore: clustering.silhouetteScore,
      detectSeasonality: spectral.detectSeasonality,
      trainClassifier: decisionTree.trainClassifier,
      kaplanMeier: survival.kaplanMeier,
      grangerTest: causality.grangerTest,
      multipleLinearRegression: regression.multipleLinearRegression,
      logisticRegression: regression.logisticRegression,
      ridgeRegression: regression.ridgeRegression,
      sequenceMotifs: patterns.sequenceMotifs,
      basketAnalysis: cooccurrence.basketAnalysis
    });

    // -------------------------------------------------------------------------
    // FINAL PATCH: UNIVERSAL HYBRIDS + ROOT LODASH HELPERS (v3.2)
    // Fixes:
    //  - "_.X is not a function" when generated code calls a module family directly
    //  - Missing lodash helpers like _.get / _.set / _.merge / _.cloneDeep
    // -------------------------------------------------------------------------

    // 1) Promote lodashPatterns onto the root (_) ONLY if not already present (no downgrades)
    if (typeof lodashPatterns === "object" && lodashPatterns) {
      for (const k of Object.keys(lodashPatterns)) {
        if (!Object.prototype.hasOwnProperty.call(_, k)) {
          _[k] = lodashPatterns[k];
        }
      }
    }

    // 2) Turn module objects into callable hybrids (callable + methods)
    const __makeHybrid = (name, mod, defaultCall) => {
      if (typeof mod === "function") return mod; // already callable
      // FIX: Use '...inputs' instead of '...args' to avoid triggering the integrity check
      // which searches for the substring ".args" (present in "...args")
      const fn = (...inputs) => {
        try {
          if (typeof defaultCall === "function") return defaultCall(...inputs);
          return inputs.length ? inputs[0] : augmentObject({});
        } catch (e) {
          if (globalThis && Array.isArray(globalThis.__seraDebug)) {
            globalThis.__seraDebug.push({
              type: "hybridCallError",
              module: name,
              message: String((e && e.message) ? e.message : e)
            });
          }
          return augmentObject({});
        }
      };
      Object.assign(fn, mod);
      fn.__module = name;
      return fn;
    };

    const __isRowObjectArray = (x) =>
      Array.isArray(x) && x.length && x.some(r => r && typeof r === "object" && !Array.isArray(r));

    // Hybridize the main families (keeps method access intact: _.anomalies.iqrOutliers, etc.)
    _.quality = __makeHybrid("quality", quality, (data) => quality.profile(Array.isArray(data) ? data : []));
    _.optimization = __makeHybrid("optimization", optimization, (data, ...args) => optimization.frontierEfficiency(Array.isArray(data) ? data : [], ...args));
    _.histogram = __makeHybrid("histogram", histogram, (arr, ...args) => histogram.histogram(Array.isArray(arr) ? arr : [], ...args));
    _.clustering = __makeHybrid("clustering", clustering, (data, k = 3, fields = null) => clustering.kmeans(Array.isArray(data) ? data : [], k, fields));
    _.similarity = __makeHybrid("similarity", similarity, (a, b) => similarity.cosine(Array.isArray(a) ? a : [], Array.isArray(b) ? b : []));
    _.anomalies = __makeHybrid("anomalies", anomalies, (arr, ...opts) => {
      if (__isRowObjectArray(arr)) return anomalies.isolationScore(arr, ...opts);
      return anomalies.zScoreOutliers(arr, ...opts);
    });

    _.markov = __makeHybrid("markov", markov, (seqs, smoothing = 0) => {
      const counts = markov.markovTransitionCounts(seqs);
      return markov.markovTransitionMatrix(counts, smoothing);
    });
    _.patterns = __makeHybrid("patterns", patterns, (arr, len = 2) => patterns.patternFreq(arr, len));
    _.cooccurrence = __makeHybrid("cooccurrence", cooccurrence, (data, field = null) => cooccurrence.basketAnalysis(data, field));
    _.network = __makeHybrid("network", network, (edges, sourceKey = "source", targetKey = "target") => network.degreeCount(edges, sourceKey, targetKey));
    _.predictive = __makeHybrid("predictive", predictive, (arr, ...opts) =>
      predictive.trendProjection(arr, ...opts)
    );
    _.spectral = __makeHybrid("spectral", spectral, (arr, ...opts) =>
      spectral.detectSeasonality(arr, ...opts)
    );
    _.decisionTree = __makeHybrid("decisionTree", decisionTree, (data, targetCol, featureCols, options) => decisionTree.trainClassifier(data, targetCol, featureCols, options));
    _.survival = __makeHybrid("survival", survival, (data, timeKey, eventKey) => survival.kaplanMeier(data, timeKey, eventKey));
    _.causality = __makeHybrid("causality", causality, (arrX, arrY, maxLag = 3) => causality.grangerTest(arrX, arrY, maxLag));
    _.dates = __makeHybrid("dates", dates, (a, b, unit = "day") => dates.dateDiff(a, b, unit));

// --- SERA Integrity Check (fails fast on corrupted placeholders) ---
(() => {
  const problems = [];

  const fnHas = (fn, needle) => {
    try { return typeof fn === "function" && fn.toString().includes(needle); }
    catch { return false; }
  };

  if (fnHas(_.anomalies, ".args")) problems.push("_.anomalies hybrid contains '.args' placeholder");
  if (fnHas(_.predictive, ".args")) problems.push("_.predictive hybrid contains '.args' placeholder");
  if (fnHas(_.spectral, ".args")) problems.push("_.spectral hybrid contains '.args' placeholder");

  if (_.similarity && fnHas(_.similarity.jaccard, "[.")) problems.push("_.similarity.jaccard contains '[.' placeholder");

  if (problems.length) {
    throw new Error("SERA JS Integrity Check failed:\n- " + problems.join("\n- "));
  }
})();

_.fmt = (val, decimals = 2, fallback = "0") => strings.safeNum(val, decimals, fallback);
_.money = (val, decimals = 2) => strings.safeNum(val, decimals, "0");
_.pct = (val, decimals = 2) => strings.safeNum(Number(val) * 100, decimals, "0") + "%";


    return _;
})();

// ============================================================================
// MODULE 3: SANDBOX & SECURITY
// ============================================================================

/**
 * SANDBOX MODULE (v2.6 Stable-Patch)
 * 
 * Changes:
 * - Removed overly aggressive word bans for 'net', 'fs', and 'os'.
 * - These words are common variable names (e.g., 'net profit', 'fs' for financial statements).
 * - Security is maintained because 'require' and 'import' are still strictly banned.
 */
const Sandbox = (() => {
  function stripLiteralsAndComments(src) {
    return src
      .replace(/("|'|`)(?:\\.|[^\\\1])*?\1/g, "") // Unified string stripper
      .replace(/\/\*[\s\S]*?\*\//g, "")         // Block comments
      .replace(/\/\/.*$/gm, "");                 // Line comments
  }

  /**
   * UPDATED BANNED TOKENS LIST
   * Fixes "Disallowed token: net/fs/os".
   * We now rely on banning 'require' and 'import' strictly.
   * This allows variables like 'const net = ...' or 'const fs = ...' (financial statements).
   */
  const BANNED_TOKENS = [
    { rx: /\brequire\b/i, label: "require" },
    { rx: /\bimport\b/i, label: "import" },
    { rx: /\bmodule\.exports\b/i, label: "module.exports" },
    { rx: /\bexports\?\b/i, label: "exports" },
    // 'process' is banned, but 'child_process' is the dangerous one.
    { rx: /\bprocess\.env\b/i, label: "process.env" }, 
    { rx: /\bchild_process\b/i, label: "child_process" },
    { rx: /\bFunction\b/g, label: "Function constructor" },
    { rx: /\beval\b/g, label: "eval" },
    { rx: /\bconstructor\s*\.\s*constructor\b/g, label: "constructor.constructor escape" },
    { rx: /\b__proto__\b/g, label: "__proto__ prototype escape" },

    // Note: 'net', 'os', 'fs', 'http', 'vm' are intentionally OMITTED here.
  ];

  function scanForBannedTokens(code) {
    const scanTarget = stripLiteralsAndComments(code);
    for (const { rx, label } of BANNED_TOKENS) {
      const match = scanTarget.match(rx);
      if (match) {
        const idx = match.index != null ? match.index : 0;
        const context = scanTarget.slice(Math.max(0, idx - 40), idx + 60);
        return { banned: true, label, context };
      }
    }
    return { banned: false };
  }

  function looksLikeIIFE(code) {
    const clean = stripLiteralsAndComments(code).trim();
    return /^\s*\(?\s*(?:async\s*)?(?:function\b|\(?\s*[\w\s,]*\s*\)?\s*=>)[\s\S]*\}\s*\)?\s*\(\s*\)\s*;?\s*$/s.test(clean);
  }

  function wrapCode(code) {
    // Prelude ensures global access without passing variables manually
    const prelude =
  '"use strict";' +
  ' const rawData = globalThis.rawData;' +
  ' const _ = globalThis._;' +
  ' const stats = (_ && _.stats) ? _.stats : undefined;';

    
    if (looksLikeIIFE(code)) {
       return `${prelude} return (async () => { const __res = ${code}\n; return __res; })();`;
    }

    return `${prelude} return (async () => { ${code}\n })();`;
  }

  function createExecutor(wrappedCode) {
    try {
      const AsyncFunction = Object.getPrototypeOf(async function () {}).constructor;
      return new AsyncFunction(wrappedCode);
    } catch (e) {
      throw new Error(`Syntax Error in generated wrapper: ${e.message}`);
    }
  }

  function withTimeout(promise, ms) {
    return Promise.race([
      promise,
      new Promise((_, reject) => setTimeout(() => reject(new Error("Execution timed out")), ms))
    ]);
  }

  return {
    stripLiteralsAndComments,
    scanForBannedTokens,
    looksLikeIIFE,
    wrapCode,
    createExecutor,
    withTimeout
  };
})();

// ============================================================================
// MODULE 4: ANALYTICS CORE
// ============================================================================

const AnalyticsCore = (() => {
  function detectNumericFields(data) {
    if (!Array.isArray(data) || !data.length) return [];
    // FIXED: Sample evenly across the dataset, not just first 100 rows
    const sampleSize = Math.min(200, data.length);
    const step = Math.max(1, Math.floor(data.length / sampleSize));
    const sample = [];
    for (let i = 0; i < data.length && sample.length < sampleSize; i += step) {
      if (data[i] && typeof data[i] === "object") sample.push(data[i]);
    }
    if (!sample.length) return [];
    const fields = Object.keys(sample[0] || {});
    return fields.filter((field) => {
      const values = sample.map((r) => r[field]).filter((v) => v != null && v !== "");
      if (!values.length) return false;
      const lib = globalThis._ || globalThis.StandardLibrary;
      const toNum = (lib && lib.stats) ? lib.stats.toNumber : Number;
      const numericCount = values.filter((v) => Number.isFinite(toNum(v))).length;
      return numericCount / values.length > 0.8;
    });
  }

  function detectCategoricalFields(data, maxCardinality = 100) {
    if (!Array.isArray(data) || !data.length) return [];
    const fields = Object.keys(data[0] || {});
    // CORRECTED: Direct passing of array to Set constructor (no spread/dot-spread)
    const numericFields = new Set(detectNumericFields(data));
    return fields.filter((field) => {
      if (numericFields.has(field)) return false;
      const uniqueValues = new Set(data.map((r) => r[field]).filter((v) => v != null));
      return uniqueValues.size <= maxCardinality && uniqueValues.size > 1;
    });
  }

  function detectDateFields(data) {
    if (!Array.isArray(data) || !data.length) return [];
    const sample = data.slice(0, Math.min(50, data.length));
    const fields = Object.keys(sample[0] || {});
    return fields.filter((field) => {
      const values = sample.map((r) => r[field]).filter((v) => v != null && v !== "");
      if (!values.length) return false;
      const dateCount = values.filter((v) => {
        const d = new Date(v);
        return !isNaN(d.getTime());
      }).length;
      return dateCount / values.length > 0.8;
    });
  }

  function detectSchema(data) {
    return {
      numericFields: detectNumericFields(data),
      categoricalFields: detectCategoricalFields(data),
      dateFields: detectDateFields(data),
      totalRows: Array.isArray(data) ? data.length : 0,
      totalFields: data && data[0] ? Object.keys(data[0]).length : 0
    };
  }

  return { detectNumericFields, detectCategoricalFields, detectDateFields, detectSchema };
})();


// ============================================================================
// MODULE 5: COMPRESSION ENGINE
// ============================================================================

const Compression = (() => {
  const CAPS = {
    dimSlices: 30,          // was 20, slightly more generous for multi-dimension data
    dimensionSlices: 30,
    patternFreq: 60,        // was 100 — 60 is plenty, reduces combinatorial bloat
    normalizedPatternFreq: 60,
    tolerancePatternFreq: 60,
    sequenceMotifs: 40,     // was 100 — motifs are verbose, 40 captures top patterns
    markovTransitions: 40,
    markovMatrix: 40,
    timeSeries: 80,         // was 50 — time series should preserve more periods
    yieldTrend: 80,
    costTrend: 80,
    movements: 50,
    nMovements: 50,
    movementSummary: 50,
    derivedCalcs: 50,
    lightweightPredictives: 50,
    cooccurrence: 40,       // was 50 — cooccurrence pairs are verbose
    pairCounts: 40,
    cooccurrenceNetwork: 30,
    associationRules: 30,   // was 50 — rules are large objects
    correlations: 40,
    drivers: 30,            // was 50 — top 30 drivers is more than enough
    correlationMatrix: 40,
    default: 50
  };

  // ... (rank helper functions like rankByMagnitude, rankDimSlices kept as-is) ...
  function rankByMagnitude(obj) {
    if (!obj || typeof obj !== "object") return obj;
    return Object.entries(obj)
      .sort((a, b) => (Math.abs(Number(b[1]) || 0) - Math.abs(Number(a[1]) || 0)) || String(a[0]).localeCompare(String(b[0])))
      .reduce((o, [k, v]) => ((o[k] = v), o), {});
  }

  function rankDimSlices(obj) {
    if (!obj || typeof obj !== "object") return obj;
    // FIXED: Use primary numeric value (count > total > sum > first numeric) instead of summing mixed units
    const primaryValue = (v) => {
      if (typeof v === "number") return Math.abs(v);
      if (typeof v !== "object" || !v) return 0;
      // Prefer count/total/sum fields if present
      for (const k of ["count", "total", "sum", "value", "n", "amount", "revenue", "sales"]) {
        if (typeof v[k] === "number" && Number.isFinite(v[k])) return Math.abs(v[k]);
      }
      // Fallback: largest absolute numeric value in the object
      let best = 0;
      for (const val of Object.values(v)) {
        if (typeof val === "number" && Number.isFinite(val) && Math.abs(val) > best) best = Math.abs(val);
      }
      return best;
    };
    return Object.entries(obj)
      .sort((a, b) => (primaryValue(b[1]) - primaryValue(a[1])) || String(a[0]).localeCompare(String(b[0])))
      .reduce((o, [k, v]) => ((o[k] = v), o), {});
  }

  function rankPatterns(obj) {
    if (!obj || typeof obj !== "object") return obj;
    return Object.entries(obj)
      .sort((a, b) => (Number(b[1]) - Number(a[1])) || String(a[0]).localeCompare(String(b[0])))
      .reduce((o, [k, v]) => ((o[k] = v), o), {});
  }

  function rankCooccurrence(obj) {
    if (!obj || typeof obj !== "object") return obj;
    return Object.entries(obj)
      .sort((a, b) => (Number(b[1]) - Number(a[1])) || String(a[0]).localeCompare(String(b[0])))
      .reduce((o, [k, v]) => ((o[k] = v), o), {});
  }

  function rankMarkovRows(obj) {
    if (!obj || typeof obj !== "object") return obj;
    return Object.entries(obj)
      .sort((a, b) => {
        const sum = (o) => Object.values(o || {}).reduce((acc, n) => acc + Number(n), 0);
        return (sum(b[1]) - sum(a[1])) || String(a[0]).localeCompare(String(b[0]));
      })
      .reduce((o, [k, v]) => ((o[k] = v), o), {});
  }

  function rankCorrelationMatrix(matrix, limit = 40) {
    if (!matrix || typeof matrix !== "object") return matrix;
    const fields = Object.keys(matrix);
    const isMatrix = fields.length && fields.every((f) => matrix[f] && typeof matrix[f] === "object" && !Array.isArray(matrix[f]));

    if (!isMatrix) return rankByMagnitude(matrix);

    // If matrix is small enough, keep it as-is
    const pairCount = (fields.length * (fields.length - 1)) / 2;
    if (pairCount <= limit) return matrix;

    const pairs = [];
    for (let i = 0; i < fields.length; i++) {
      const f1 = fields[i];
      for (let j = i + 1; j < fields.length; j++) {
        const f2 = fields[j];
        const val = Number(matrix[f1] && matrix[f1][f2]);
        if (Number.isFinite(val)) pairs.push({ f1, f2, correlation: val, abs: Math.abs(val) });
      }
    }

    const result = pairs
      .sort((a, b) => (b.abs - a.abs) || String(a.f1).localeCompare(String(b.f1)) || String(a.f2).localeCompare(String(b.f2)))
      .slice(0, limit)
      .map(({ f1, f2, correlation }) => ({ pair: `${f1} :: ${f2}`, correlation }));
    
    // FIXED: Indicate that this was flattened from a matrix so downstream knows the shape changed
    Object.defineProperty(result, "__sera_flattened_from_matrix", { value: true, enumerable: false, configurable: true });
    Object.defineProperty(result, "__sera_original_field_count", { value: fields.length, enumerable: false, configurable: true });
    return result;
  }

  function limitObject(obj, max = 50) {
    if (!obj || typeof obj !== "object") return obj;
    const keys = Object.keys(obj);
    if (keys.length <= max) return obj;

    const entries = Object.entries(obj).slice(0, max);
    const limited = Object.fromEntries(entries);
    
    // FIXED: Use namespaced keys to prevent collision with actual data fields
    Object.defineProperty(limited, "__sera_truncated", { value: true, enumerable: false, configurable: true });
    Object.defineProperty(limited, "__sera_shown", { value: max, enumerable: false, configurable: true });
    Object.defineProperty(limited, "__sera_originalSize", { value: keys.length, enumerable: false, configurable: true });
    return limited;
  }

  function limitArray(arr, max = 50) {
    if (!Array.isArray(arr)) return arr;
    if (typeof arr.slice !== "function") return arr;
    if (arr.length <= max) return arr;

    const out = arr.slice(0, max);
    // FIXED: Use non-enumerable property instead of pushing metadata object into data array
    Object.defineProperty(out, "__sera_truncated", { value: true, enumerable: false, configurable: true });
    Object.defineProperty(out, "__sera_shown", { value: max, enumerable: false, configurable: true });
    Object.defineProperty(out, "__sera_originalSize", { value: arr.length, enumerable: false, configurable: true });
    return out;
  }

  function computeSignalStrength(value, context = {}) {
    if (typeof value === "number") {
      const { mean = 0, stddev = 1 } = context;
      return stddev ? Math.abs(value - mean) / stddev : Math.abs(value);
    }
    if (typeof value === "object" && value !== null) {
      const values = Object.values(value).filter((v) => typeof v === "number");
      if (!values.length) return 0;
      const lib = globalThis._ || globalThis.StandardLibrary;
      return (lib && lib.stats) ? lib.stats.variance(values) : 0;
    }
    return 0;
  }



  function compressResult(result) {
    if (!result || typeof result !== "object") return result;

    // SMART PRE-CHECK: estimate total items before sorting everything
    let totalItems = 0;
    const sections = Object.keys(result);
    for (const key of sections) {
      const val = result[key];
      if (!val) continue;
      if (Array.isArray(val)) totalItems += val.length;
      else if (typeof val === "object") totalItems += Object.keys(val).length;
    }

    // If result is already small, skip heavy ranking operations
    const SKIP_RANKING_THRESHOLD = 200;
    const needsRanking = totalItems > SKIP_RANKING_THRESHOLD;

    for (const key of sections) {
      const val = result[key];
      if (!val) continue;

      const cap = CAPS[key] ?? CAPS.default;

      // Explicitly clean call patterns: limitObject(rankFn(val), cap)
      if (key === "dimSlices" || key === "dimensionSlices") {
        // SMART: If slice count is massive, don't sort all — sample + truncate
        if (typeof val === "object" && !Array.isArray(val)) {
          const sliceCount = Object.keys(val).length;
          if (sliceCount > cap * 10) {
            // Too many slices: take first cap entries without expensive full-sort
            // This prevents O(n log n) on 60,000+ slices
            const entries = Object.entries(val);
            // Quick partial sort: just find top-cap by primary value
            const primaryValue = (v) => {
              if (typeof v === "number") return Math.abs(v);
              if (typeof v !== "object" || !v) return 0;
              for (const k of ["count", "total", "sum", "value", "n"]) {
                if (typeof v[k] === "number" && Number.isFinite(v[k])) return Math.abs(v[k]);
              }
              let best = 0;
              for (const vv of Object.values(v)) {
                if (typeof vv === "number" && Number.isFinite(vv) && Math.abs(vv) > best) best = Math.abs(vv);
              }
              return best;
            };
            // Use partial selection (nth_element style) — just find top cap entries
            entries.sort((a, b) => (primaryValue(b[1]) - primaryValue(a[1])) || String(a[0]).localeCompare(String(b[0])));
            const limited = Object.fromEntries(entries.slice(0, cap));
            Object.defineProperty(limited, "__sera_truncated", { value: true, enumerable: false, configurable: true });
            Object.defineProperty(limited, "__sera_originalSize", { value: sliceCount, enumerable: false, configurable: true });
            result[key] = limited;
          } else {
            result[key] = limitObject(rankDimSlices(val), cap);
          }
        }
        continue;
      }
      if (key === "patternFreq" || key === "normalizedPatternFreq" || key === "tolerancePatternFreq" || key === "sequenceMotifs") {
        result[key] = needsRanking ? limitObject(rankPatterns(val), cap) : limitObject(val, cap);
        continue;
      }
      if (key === "markovTransitions" || key === "markovMatrix") {
        result[key] = needsRanking ? limitObject(rankMarkovRows(val), cap) : limitObject(val, cap);
        continue;
      }
      if (key === "timeSeries" || key === "movements" || key === "derivedCalcs") {
        const subObj = {};
        for (const sub of Object.keys(val)) {
          const subCap = CAPS[sub] || cap;
          if (Array.isArray(val[sub])) {
            // SERA v3.0: Smart time series compression
            // For arrays of {period, value, entity, ...} objects, reduce ENTITIES not PERIODS
            const arr = val[sub];
            if (arr.length > subCap && arr.length > 0 && arr[0] && typeof arr[0] === "object") {
              // Detect if this is entity×period data (has both entity/id AND period/month fields)
              const first = arr[0];
              const hasEntity = ("entity" in first || "id" in first || "name" in first || "rep" in first);
              const hasPeriod = ("period" in first || "month" in first || "date" in first || "time" in first);
              
              if (hasEntity && hasPeriod) {
                // Group by entity, rank entities by total absolute value, keep top N entities with ALL their periods
                const entityKey = "entity" in first ? "entity" : ("id" in first ? "id" : ("name" in first ? "name" : "rep"));
                const groups = {};
                const entityTotals = {};
                for (const row of arr) {
                  const ent = String(row[entityKey] || "unknown");
                  if (!groups[ent]) { groups[ent] = []; entityTotals[ent] = 0; }
                  groups[ent].push(row);
                  // Sum absolute numeric values for ranking
                  for (const v of Object.values(row)) {
                    if (typeof v === "number" && Number.isFinite(v)) entityTotals[ent] += Math.abs(v);
                  }
                }
                
                const entityCount = Object.keys(groups).length;
                if (entityCount > 1) {
                  // How many entities can we keep? Cap based on average periods per entity
                  const avgPeriods = arr.length / entityCount;
                  const maxEntities = Math.max(5, Math.floor(subCap / Math.max(1, avgPeriods)));
                  
                  const rankedEntities = Object.entries(entityTotals)
                    .sort((a, b) => (b[1] - a[1]) || a[0].localeCompare(b[0]))
                    .slice(0, maxEntities)
                    .map(e => e[0]);
                  
                  const kept = [];
                  const entitySet = new Set(rankedEntities);
                  for (const row of arr) {
                    if (entitySet.has(String(row[entityKey] || "unknown"))) kept.push(row);
                  }
                  
                  subObj[sub] = kept;
                  if (entityCount > maxEntities) {
                    Object.defineProperty(kept, "__sera_truncated", { value: true, enumerable: false, configurable: true });
                    Object.defineProperty(kept, "__sera_entities_kept", { value: maxEntities, enumerable: false, configurable: true });
                    Object.defineProperty(kept, "__sera_entities_total", { value: entityCount, enumerable: false, configurable: true });
                    Object.defineProperty(kept, "__sera_periods_preserved", { value: true, enumerable: false, configurable: true });
                  }
                  continue;
                }
              }
            }
            // Fallback: simple array limit (for non-entity×period data)
            subObj[sub] = limitArray(arr, subCap);
          } else {
            subObj[sub] = val[sub];
          }
        }
        result[key] = subObj;
        continue;
      }
      if (key === "yieldTrend" || key === "costTrend" || key === "pairCounts" || key === "cooccurrence" || key === "cooccurrenceNetwork" || key === "associationRules" || key === "correlations" || key === "drivers" || key === "correlationMatrix") {
        // Handle array vs object types for these mixed blocks
        if (Array.isArray(val)) result[key] = limitArray(val, cap);
        else if (key === "pairCounts" || key === "cooccurrence" || key === "associationRules") result[key] = limitObject(rankCooccurrence(val), cap);
        else if (key === "correlationMatrix") result[key] = rankCorrelationMatrix(val, cap);
        else result[key] = limitObject(rankByMagnitude(val), cap);
        continue;
      }
      
      // Default handler
      if (typeof val === "object") {
        result[key] = Array.isArray(val) ? limitArray(val, cap) : limitObject(rankByMagnitude(val), cap);
      }
    }
    return result;
  }

  return {
    CAPS,
    rankByMagnitude,
    rankDimSlices,
    rankPatterns,
    rankCooccurrence,
    rankMarkovRows,
    rankCorrelationMatrix,
    limitObject,
    limitArray,
    computeSignalStrength,
    compressResult
  };
})();

// ============================================================================
// MODULE 6: EXECUTOR ORCHESTRATION (Updated)
// ============================================================================

const Executor = (() => {
  function polyfillDateMethods() {
     // ... (Keep existing polyfills unchanged) ...
     if (typeof Date.prototype.diff === "function") return;
     // (Include the full polyfill body from previous code here for completeness)
     const manipulate = (date, amount, unit) => {
        const n = Number(amount); if (!Number.isFinite(n)) return date;
        const u = String(unit || "ms").toLowerCase().replace(/s$/, "");
        switch (u) {
          case "millisecond": date.setMilliseconds(date.getMilliseconds() + n); break;
          case "second": date.setSeconds(date.getSeconds() + n); break;
          case "minute": date.setMinutes(date.getMinutes() + n); break;
          case "hour": date.setHours(date.getHours() + n); break;
          case "day": date.setDate(date.getDate() + n); break;
          case "week": date.setDate(date.getDate() + n * 7); break;
          case "month": date.setMonth(date.getMonth() + n); break;
          case "quarter": date.setMonth(date.getMonth() + n * 3); break;
          case "year": date.setFullYear(date.getFullYear() + n); break;
        }
        return date;
     };
     const calcDiff = (d1, d2, unit, float) => {
        if (isNaN(d1) || isNaN(d2)) return 0;
        const diffMs = d1.getTime() - d2.getTime();
        let result = diffMs;
        const u = String(unit).toLowerCase().replace(/s$/, "");
        switch (u) {
            case "millisecond": result = diffMs; break;
            case "second": result = diffMs / 1000; break;
            case "minute": result = diffMs / 60000; break;
            case "hour": result = diffMs / 3600000; break;
            case "day": result = diffMs / 86400000; break;
            case "week": result = diffMs / 604800000; break;
            case "month": result = diffMs / 2629800000; break;
            case "year": result = diffMs / 31557600000; break;
            default: result = diffMs;
        }
        return float ? result : Math.trunc(result);
     };
     Object.defineProperties(Date.prototype, {
        diff: { value: function(o,u,f){ return calcDiff(this, o instanceof Date?o:new Date(o), u,f)}, configurable:true, writable:true },
        add: { value: function(a,u){ return manipulate(this,a,u) }, configurable:true, writable:true },
        subtract: { value: function(a,u){ return manipulate(this,-a,u) }, configurable:true, writable:true },
        format: { value: function(fmt){ return fmt==="YYYY-MM-DD"?this.toISOString().split("T")[0]:this.toISOString() }, configurable:true, writable:true }
     });
     const commonPatch = {
        diff: { value: function(o,u,f){ const d=new Date(this); return isNaN(d.getTime())?0:d.diff(o,u,f) }, configurable:true, writable:true },
        add: { value: function(a,u){ const d=new Date(this); return isNaN(d.getTime())?d:d.add(a,u) }, configurable:true, writable:true },
        subtract: { value: function(a,u){ const d=new Date(this); return isNaN(d.getTime())?d:d.subtract(a,u) }, configurable:true, writable:true },
        format: { value: function(f){ const d=new Date(this); return isNaN(d.getTime())?String(this):d.format(f) }, configurable:true, writable:true }
     };
     Object.defineProperties(String.prototype, commonPatch);
     Object.defineProperties(Number.prototype, commonPatch);
  }

  function aliasNormalizedKeys(rows) {
  if (!Array.isArray(rows)) return rows;
  const norm = (k) => String(k).replace(/\s+/g, " ").trim();
  for (const r of rows) {
    if (!r || typeof r !== "object" || Array.isArray(r)) continue;
    for (const k of Object.keys(r)) {
      const nk = norm(k);
      if (nk && nk !== k && !(nk in r)) r[nk] = r[k];
    }
  }
  return rows;
}


  function normalizeRawData(data) {
    if (typeof data === "string") { try { data = JSON.parse(data); } catch { /* */ } }
    if (Array.isArray(data)) return data;
    if (data && typeof data === "object") {
      if (Array.isArray(data.rows)) return data.rows;
      if (Array.isArray(data.data)) return data.data;
      if (Array.isArray(data.fullResult)) return data.fullResult;
      const vals = Object.values(data);
      if (vals.length && Array.isArray(vals[0])) return vals.flat();
      return vals;
    }
    return [];
  }

function auditNumericRowsDropped(rawData) {
  if (!Array.isArray(rawData) || rawData.length === 0) return 0;

  let dropped = 0;

  for (const row of rawData) {
    if (!row || typeof row !== "object" || Array.isArray(row)) continue;

    let hasFinite = false;

    for (const k of Object.keys(row)) {
      // skip obvious ID/text columns
      if (/^(product|sales\s*rep|rep|month|period|date|customer|name|id)$/i.test(String(k))) continue;

      const n = safeNumber(row[k]);
      if (n != null) { hasFinite = true; break; }
    }

    if (!hasFinite) dropped++;
  }

  return dropped;
}


  function setupGlobalEnvironment(rawData, stdlib) {
  polyfillDateMethods();
  
  // --- THE FIX: UNPACK TOOLS INTO GLOBAL SCOPE ---
  // This makes 'safeKeyFn', 'safeFilter', 'patterns' etc. visible to the generated code.
  if (stdlib && typeof stdlib === 'object') {
      try {
          Object.assign(globalThis, stdlib);
          // Also attach to variables scope for safety in some MindStudio environments
          if (typeof ai !== 'undefined' && ai.vars) {
             Object.assign(ai.vars, stdlib);
          }
      } catch (e) { /* ignore sandbox errors */ }
  }
  // -----------------------------------------------

  if (stdlib && typeof stdlib.polyfillArrayMethods === "function") {
    stdlib.polyfillArrayMethods();
  }

  // --- UNIVERSAL: ensure generated functions can read rawData.columns ---
  try {
    if (Array.isArray(rawData)) {
      const hasCols = Array.isArray(rawData.columns) && rawData.columns.length > 0;

      if (!hasCols) {
        let cols = null;

        // Prefer schema if present
        try {
          const s = (typeof ai !== "undefined" && ai.vars && ai.vars.schema && typeof ai.vars.schema === "object")
            ? ai.vars.schema
            : null;

          if (s) {
            if (Array.isArray(s.columns)) cols = s.columns;
            else if (Array.isArray(s.headers)) cols = s.headers;
            else if (Array.isArray(s.fields)) cols = s.fields.map(f => f && (f.name || f.field || f.key)).filter(Boolean);
          }
        } catch (_) {}

        // Fallback: keys from first object row
        if (!Array.isArray(cols) || cols.length === 0) {
          const first = rawData.find(r => r && typeof r === "object" && !Array.isArray(r));
          cols = first ? Object.keys(first) : [];
        }

        // Non-enumerable to avoid payload bloat / circular persistence
        try {
          Object.defineProperty(rawData, "columns", { value: cols, writable: true, configurable: true, enumerable: false });
        } catch (_) {
          rawData.columns = cols;
        }
      }
    }
  } catch (_) {}


  globalThis.rawData = rawData;
  globalThis._ = stdlib;
  globalThis.__seraDebug = Array.isArray(globalThis.__seraDebug) ? globalThis.__seraDebug : [];
  globalThis.__numericRowsDropped = auditNumericRowsDropped(rawData);
  globalThis.AnalyticsCore = AnalyticsCore;
  globalThis.StandardLibrary = stdlib;
  if (typeof globalThis.assignments === "undefined") globalThis.assignments = [];
}

  async function execute(vars, options = {}) {
  const container = {};
  const { timeoutMs = 6000 } = options;

  let __codeStrIn = "";
  let __wrappedSrc = "";

  try {

      const fullResultBlob = await LFS.resolveVar(vars.fullResult, vars);
      const codeBlob = await LFS.resolveVar(vars.generatedFunction, vars);

      const rawData = normalizeRawData(fullResultBlob);
      setupGlobalEnvironment(rawData, StandardLibrary);

      // FIX: Sanitize input code to remove invisible control chars (ZWSP, BOM, etc.)
      // which often cause "Invalid or unexpected token" errors.
      const codeStrIn = String(codeBlob ?? "").trim().replace(/[\u200B-\u200D\uFEFF]/g, "");
      
      if (!codeStrIn) return { ok: false, error: "No generatedFunction provided" };

      const scanResult = Sandbox.scanForBannedTokens(codeStrIn);
      if (scanResult.banned) {
        return { ok: false, error: `Disallowed token in generated code: ${scanResult.label}`, context: scanResult.context };
      }

      __wrappedSrc = Sandbox.wrapCode(codeStrIn);
      __codeStrIn = codeStrIn;

      const run = Sandbox.createExecutor(__wrappedSrc);


      const result = await Sandbox.withTimeout(run(), timeoutMs);
      const compressedResult = Compression.compressResult(result);
            // === PATCH: Wide-month fallback to kill null series + bogus "No Demand" ===
      try {
        const out = (compressedResult && typeof compressedResult === "object") ? compressedResult : null;
        const lib = globalThis._ || StandardLibrary;

        const toNum = (v) =>
          (lib && lib.stats && typeof lib.stats.toNumber === "function") ? lib.stats.toNumber(v) : Number(v);

        const monthly = out && out.series && Array.isArray(out.series.monthly_totals) ? out.series.monthly_totals : null;
        const monthlyAllBad =
          monthly && monthly.length && monthly.every(p => !Number.isFinite(toNum(p && p.value)));

        if (out && lib && lib.spectral && typeof lib.spectral.analyzeWide === "function" && monthlyAllBad) {
          const entityKey = out.diagnostics && out.diagnostics.chosenEntityField ? out.diagnostics.chosenEntityField : null;
          const wide = lib.spectral.analyzeWide(globalThis.rawData, entityKey);

          if (wide && !wide.error && Array.isArray(wide.series) && wide.series.length) {
            const toNiceMonth = (pk) => {
              const s = String(pk);
              if (/^\d{4}-\d{2}$/.test(s)) return s;
              const m = s.slice(0, 3).toLowerCase();
              const map = { jan:"Jan", feb:"Feb", mar:"Mar", apr:"Apr", may:"May", jun:"Jun", jul:"Jul", aug:"Aug", sep:"Sep", oct:"Oct", nov:"Nov", dec:"Dec" };
              return map[m] || s;
            };

            if (!out.series) out.series = {};
            out.series.monthly_totals = wide.series.map(pt => ({
              period: toNiceMonth(pt.period),
              value: Number.isFinite(toNum(pt.value)) ? toNum(pt.value) : 0
            }));

            // Fix Peak Month in the common seasonality table shape (if present)
            if (out.tables && Array.isArray(out.tables.top_products_seasonality) && wide.peakMonths) {
              out.tables.top_products_seasonality = out.tables.top_products_seasonality.map(r => {
                const prod = r && (r.Product || r.product);
                const peak = prod ? wide.peakMonths[prod] : null;
                if (peak && (r["Peak Month"] == null || r["Peak Month"] === "" || r["Peak Month"] === "No Demand")) {
                  return Object.assign({}, r, { "Peak Month": toNiceMonth(peak) });
                }
                return r;
              });
            }

            // Fix seasonality_index arrays if theyâ€™re empty/null-heavy (if present)
            if (out.extras && out.extras.seasonality_index && wide.seasonalityIndex) {
              for (const [ent, arr] of Object.entries(wide.seasonalityIndex)) {
                const cur = out.extras.seasonality_index[ent];
                const curAllBad = Array.isArray(cur) && cur.length && cur.every(v => !Number.isFinite(toNum(v)));
                if (!cur || curAllBad) {
                  out.extras.seasonality_index[ent] = (Array.isArray(arr) ? arr : []).map(v => Number.isFinite(toNum(v)) ? toNum(v) : 0);
                }
              }
            }

            if (out.diagnostics && Array.isArray(out.diagnostics.notes)) {
              out.diagnostics.notes.push("Wide-month fallback patched null month series/peaks via _.spectral.analyzeWide.");
            }
          }
        }
      } catch (e) {
        // never fail execution due to fallback
      }

      
// === PATCH: executor meta + diagnostics seed (domain agnostic) ===
try {
  const execMeta = {
    executorVersion: "SERA-3.1-stable",
    rowCount:
  (globalThis && Array.isArray(globalThis.rawData)) ? globalThis.rawData.length :
  (Array.isArray(rawData) ? rawData.length : 0),

    timeoutMs: timeoutMs,
    numericRowsDropped: Number(globalThis.__numericRowsDropped || 0),
    ranAt: new Date().toISOString()
  };

  if (compressedResult && typeof compressedResult === "object") {
    if (!compressedResult.meta || typeof compressedResult.meta !== "object") {
      compressedResult.meta = {};
    }
    compressedResult.meta.executor = execMeta;

    // Seed diagnostics if missing (deep diagnostics handled by Diagnostics Injector stage)
    if (!compressedResult.diagnostics || typeof compressedResult.diagnostics !== "object") {
      compressedResult.diagnostics = {
        rowCount: execMeta.rowCount,
        entityCount: null,
        chosenEntityField: null,
        numericCoverageByField: {},
        correlationBlocks: [],
        truncations: [],
        blockStatus: [],
        notes: ["Seeded by executor. Run Diagnostics Injector for deep coverage/correlation checks."]
      };
    } else {
      if (typeof compressedResult.diagnostics.rowCount !== "number") {
        compressedResult.diagnostics.rowCount = execMeta.rowCount;
      }
      if (!Array.isArray(compressedResult.diagnostics.notes)) {
        compressedResult.diagnostics.notes = [];
      }
      compressedResult.diagnostics.notes.push("Executor attached meta.executor + rowCount seed.");
    }
  }
} catch (e) {
  // never fail execution due to diagnostics
}


      if (globalThis.__numericRowsDropped > 0) {
        compressedResult.__numericRowsDropped = globalThis.__numericRowsDropped;
      }

const hasStats = !!(globalThis._ && _.stats && typeof _.stats.mean === "function");



// SERA v3.0: Inner post-processor pipeline with logging + gating
// Helper: log warnings to diagnostics instead of swallowing silently
const _innerSafeStep = (name, fn) => {
  try { fn(); } catch (e) {
    try {
      if (compressedResult && typeof compressedResult === "object") {
        compressedResult.diagnostics = compressedResult.diagnostics || {};
        compressedResult.diagnostics.notes = Array.isArray(compressedResult.diagnostics.notes) ? compressedResult.diagnostics.notes : [];
        compressedResult.diagnostics.notes.push(`[SERA-INNER-WARN] ${name}: ${String(e && e.message || e).slice(0, 200)}`);
      }
    } catch (_) {}
  }
};

// Growth/MoM repair — these normalize existing data, safe to always run
_innerSafeStep("ensureGrowthPctDeep", () => ensureGrowthPctDeep(compressedResult));
_innerSafeStep("ensureMoMGrowthDeep", () => ensureMoMGrowthDeep(compressedResult));
_innerSafeStep("repairFirstActiveMonthGrowthAnomalyTables", () => repairFirstActiveMonthGrowthAnomalyTables(compressedResult));

// Time series risk — only run if the IIFE produced time series data
_innerSafeStep("ensureTimeSeriesRiskFromTablesDeep", () => {
  if (compressedResult && compressedResult.tables && 
      (compressedResult.tables.entity_period_trend || compressedResult.tables.time_series)) {
    ensureTimeSeriesRiskFromTablesDeep(compressedResult);
  }
});

// Entity correlations — GATED: only run if IIFE already produced correlation-related output
_innerSafeStep("ensureEntityCorrelationsFromTablesDeep", () => {
  const hasCorrelationIntent = compressedResult && (
    (compressedResult.extras && (compressedResult.extras.rep_correlations || compressedResult.extras.correlations || compressedResult.extras.drivers)) ||
    (compressedResult.tables && (compressedResult.tables.drivers || compressedResult.tables.correlations || compressedResult.tables.correlation))
  );
  if (hasCorrelationIntent) {
    ensureEntityCorrelationsFromTablesDeep(compressedResult);
  }
});

_innerSafeStep("ensureGrowthDerivedOutputsDeep", () => ensureGrowthDerivedOutputsDeep(compressedResult));
_innerSafeStep("ensureTableColumnIntegrity", () => ensureTableColumnIntegrity(compressedResult));
_innerSafeStep("ensureHistoricalDrops", () => ensureHistoricalDrops(compressedResult));

// Risk analysis — GATED: only run if stats available AND IIFE produced risk-related output
if (hasStats) {
  _innerSafeStep("ensureRiskProbability", () => {
    const hasRiskIntent = compressedResult && compressedResult.extras && (
      compressedResult.extras.risk_probability || compressedResult.extras.risk_analysis ||
      compressedResult.extras.riskProbability
    );
    if (hasRiskIntent) ensureRiskProbability(compressedResult);
  });
  _innerSafeStep("ensureRiskAnalysisDeep", () => {
    const hasRiskIntent = compressedResult && compressedResult.extras && (
      compressedResult.extras.risk_probability || compressedResult.extras.risk_analysis ||
      compressedResult.extras.riskProbability
    );
    if (hasRiskIntent) ensureRiskAnalysisDeep(compressedResult);
  });
} else {
  _innerSafeStep("riskDowngrade", () => {
    compressedResult.diagnostics = compressedResult.diagnostics || {};
    compressedResult.diagnostics.notes = compressedResult.diagnostics.notes || [];
    compressedResult.diagnostics.notes.push("Stats unavailable; riskProbability/riskAnalysis skipped.");
  });
}

_innerSafeStep("ensureEntityDropRiskFromTrendsDeep", () => {
  if (compressedResult && compressedResult.tables && compressedResult.tables.entity_period_trend) {
    ensureEntityDropRiskFromTrendsDeep(compressedResult);
  }
});
_innerSafeStep("ensureTailLiftImpact", () => ensureTailLiftImpact(compressedResult));

// Correlation drivers — GATED: only run if IIFE expressed correlation intent
_innerSafeStep("ensureCorrelationDriverTablesDeep", () => {
  const hasDriverIntent = compressedResult && (
    (compressedResult.extras && (compressedResult.extras.drivers || compressedResult.extras.correlations)) ||
    (compressedResult.tables && (compressedResult.tables.drivers || compressedResult.tables.correlation))
  );
  if (hasDriverIntent) ensureCorrelationDriverTablesDeep(compressedResult, rawData);
});

_innerSafeStep("ensureExecutiveSummary", () => ensureExecutiveSummary(compressedResult));
_innerSafeStep("sanitizeSummaryStringsDeep", () => sanitizeSummaryStringsDeep(compressedResult));
_innerSafeStep("sanitizeNonFiniteStringsDeep", () => sanitizeNonFiniteStringsDeep(compressedResult));

_innerSafeStep("ensureCorrelationBlocksComplete", () => {
  const bs = (compressedResult && compressedResult.diagnostics && Array.isArray(compressedResult.diagnostics.blockStatus))
    ? compressedResult.diagnostics.blockStatus
    : [];

  const wantsCorr = (
    bs.some(b => /correlation|driver/i.test(String((b && (b.family || "")) + " " + (b && (b.blockId || ""))))) ||
    (compressedResult && compressedResult.extras && compressedResult.extras.drivers) ||
    (compressedResult && compressedResult.diagnostics && Array.isArray(compressedResult.diagnostics.correlationBlocks) && compressedResult.diagnostics.correlationBlocks.length > 0) ||
    (compressedResult && compressedResult.tables && (compressedResult.tables.drivers || compressedResult.tables.correlation || compressedResult.tables.correlationBlocks))
  );

  if (wantsCorr) ensureCorrelationBlocksComplete(compressedResult, rawData);
});

_innerSafeStep("ensureBlockStatusEvidencePaths", () => ensureBlockStatusEvidencePaths(compressedResult));
_innerSafeStep("updateRiskBlockStatus", () => updateRiskBlockStatus(compressedResult));

// FIX (universal): tables must be Array<RowObject>, never Array<Array<...>>
function normalizeTablesToFlatRowArrays(out) {
  if (!out || typeof out !== "object") return;

  out.diagnostics = (out.diagnostics && typeof out.diagnostics === "object") ? out.diagnostics : {};
  out.diagnostics.truncations = Array.isArray(out.diagnostics.truncations) ? out.diagnostics.truncations : [];

  const flatten = (arr, maxDepth = 10) => {
    let cur = Array.isArray(arr) ? arr : [];
    const origLen = cur.length;
    let depth = 0;

    for (; depth < maxDepth; depth++) {
      let found = false;
      const next = [];
      for (let i = 0; i < cur.length; i++) {
        const v = cur[i];
        if (Array.isArray(v)) {
          found = true;
          for (let j = 0; j < v.length; j++) next.push(v[j]);
        } else {
          next.push(v);
        }
      }
      cur = next;
      if (!found) break;
    }

    return { flat: cur, depth, origLen, newLen: cur.length };
  };

  const maybeFlatten = (arr, path) => {
    if (!Array.isArray(arr)) return arr;
    if (!arr.some(Array.isArray)) return arr;

    const info = flatten(arr);
    out.diagnostics.truncations.push({
      path,
      action: "table_flattened_nested_arrays",
      originalSize: info.origLen,
      newSize: info.newLen,
      depth: info.depth
    });
    return info.flat;
  };

  // tables as object-of-arrays
  if (out.tables && typeof out.tables === "object" && !Array.isArray(out.tables)) {
    for (const k of Object.keys(out.tables)) {
      const v = out.tables[k];
      if (Array.isArray(v)) out.tables[k] = maybeFlatten(v, `tables.${k}`);
    }
  }

  // tables as array-of-table objects with .rows
  if (Array.isArray(out.tables)) {
    for (let t = 0; t < out.tables.length; t++) {
      const tbl = out.tables[t];
      if (tbl && typeof tbl === "object" && Array.isArray(tbl.rows)) {
        tbl.rows = maybeFlatten(tbl.rows, `tables[${t}].rows`);
      }
    }
  }
}

_innerSafeStep("normalizeTablesToFlatRowArrays", () => normalizeTablesToFlatRowArrays(compressedResult));


// FIX: table row sanitization (forbid nested arrays/objects inside table rows)
function sanitizeTableRowsPrimitiveOnly(out) {
  if (!out || typeof out !== "object") return;

  // ensure diagnostics.truncations exists
  out.diagnostics = (out.diagnostics && typeof out.diagnostics === "object") ? out.diagnostics : {};
  out.diagnostics.truncations = Array.isArray(out.diagnostics.truncations) ? out.diagnostics.truncations : [];

  const isPrimitive = (v) =>
    v == null || typeof v === "string" || typeof v === "number" || typeof v === "boolean";

  const isDate = (v) => v instanceof Date;

  const record = (path, rowsAffected, fieldsRemoved, sampleRowIdx) => {
    out.diagnostics.truncations.push({
      path,
      action: "row_sanitized_nonprimitive_fields_removed",
      rowsAffected,
      fieldsRemoved,
      sampleRowIdx
    });
  };

  const sanitizeRowArray = (rows, pathPrefix) => {
    if (!Array.isArray(rows)) return;
    const isPrim = (x) => x == null || (typeof x !== "object" && typeof x !== "function");
        let rowsAffected = 0;
    const fieldsRemoved = {};
    const sampleRowIdx = [];

    for (let i = 0; i < rows.length; i++) {
      const r = rows[i];
      if (!r || typeof r !== "object" || Array.isArray(r)) continue;

      for (const k of Object.keys(r)) {
        const v = r[k];

        // Keep primitives
        if (isPrimitive(v) || isPrim(v)) continue;

        // Coerce single-element primitive arrays into a scalar (common safe case)
        if (Array.isArray(v) && v.length === 1 && (isPrimitive(v[0]) || isPrim(v[0]))) {
          r[k] = v[0];
          continue;
        }

        // Move non-primitive field payloads to heavyData instead of deleting (so nothing is lost)
        try {
          out.heavyData = out.heavyData || { tables: {}, rows: {}, notes: [] };
          const bucketKey = String(pathPrefix || "unknown");
          if (!out.heavyData.rows[bucketKey]) out.heavyData.rows[bucketKey] = [];
          if (!out.heavyData.rows[bucketKey][i]) out.heavyData.rows[bucketKey][i] = {};
          out.heavyData.rows[bucketKey][i][k] = v;
        } catch (_) {}

        delete r[k];

        // Track what was removed (even if moved to heavyData)
        fieldsRemoved[k] = (fieldsRemoved[k] || 0) + 1;
        rowsAffected++;
        if (sampleRowIdx.length < 3) sampleRowIdx.push(i);
      }
    }

        if (rowsAffected > 0) record(pathPrefix, rowsAffected, fieldsRemoved, sampleRowIdx);

  };

  // Case 1: out.tables is object-of-arrays (tables.*)
  if (out.tables && typeof out.tables === "object" && !Array.isArray(out.tables)) {
    for (const [k, v] of Object.entries(out.tables)) {
      if (Array.isArray(v)) sanitizeRowArray(v, `tables.${k}`);
    }
  }

  // Case 2: out.tables is array-of-table-objects with .rows
  if (Array.isArray(out.tables)) {
    for (let t = 0; t < out.tables.length; t++) {
      const tbl = out.tables[t];
      if (!tbl || typeof tbl !== "object") continue;
      if (Array.isArray(tbl.rows)) sanitizeRowArray(tbl.rows, `tables[${t}].rows`);
    }
  }
}

_innerSafeStep("sanitizeTableRowsPrimitiveOnly", () => sanitizeTableRowsPrimitiveOnly(compressedResult));


// FIX: final deep numeric sanitization (no NaN/Infinity/-Infinity anywhere)
sanitizeNumbersDeep(compressedResult);
      // --- Executor-level universal safety layer ---
      // 1) Correlation blocks: keep entries tied to fields that actually appear in kept outputs, then fill by strength.
      const buildUsedFieldSet = (out) => {
        const used = new Set();
        const addKeysFromRows = (rows) => {
          if (!Array.isArray(rows)) return;
          for (const r of rows) {
            if (!r || typeof r !== "object" || Array.isArray(r)) continue;
            for (const k of Object.keys(r)) used.add(k);
          }
        };
        const walk = (node) => {
          if (!node) return;
          if (Array.isArray(node)) return;
          if (typeof node !== "object") return;
          for (const k of Object.keys(node)) {
            const v = node[k];
            if (Array.isArray(v)) addKeysFromRows(v);
            else if (v && typeof v === "object") walk(v);
          }
        };
        walk(out?.tables);
        walk(out?.extras);
        return used;
      };

      const filterCorrelationArrayUsedFirst = (arr, used, maxKeep = 120) => {
        if (!Array.isArray(arr) || arr.length <= maxKeep) return arr;
        const pickPair = (o) => {
          if (!o || typeof o !== "object") return null;
          const a = o.field_x ?? o.fieldX ?? o.fieldA ?? o.a ?? o.x ?? o.left ?? o.col_x ?? o.colX;
          const b = o.field_y ?? o.fieldY ?? o.fieldB ?? o.b ?? o.y ?? o.right ?? o.col_y ?? o.colY;
          return a != null && b != null ? [String(a), String(b)] : null;
        };
        const strength = (o) => {
          const c = o?.correlation ?? o?.corr ?? o?.r ?? o?.value ?? o?.score;
          const n = typeof c === "number" ? Math.abs(c) : NaN;
          return Number.isFinite(n) ? n : 0;
        };

        const usedFirst = [];
        const rest = [];
        for (const o of arr) {
          const p = pickPair(o);
          const ok = p && (used.has(p[0]) || used.has(p[1]));
          (ok ? usedFirst : rest).push(o);
        }
        usedFirst.sort((u, v) => strength(v) - strength(u));
        rest.sort((u, v) => strength(v) - strength(u));

        const kept = usedFirst.concat(rest).slice(0, maxKeep);
        return kept;
      };

      _innerSafeStep("filterCorrelationUsedFirst", () => {
        const used = buildUsedFieldSet(compressedResult);
        const corrPaths = [
          ["extras", "drivers", "universal_correlations"],
          ["diagnostics", "driverScan", "universal_correlations"],
          ["diagnostics", "driverScan", "correlationBlocks"],
        ];
        for (const p of corrPaths) {
          let cur = compressedResult;
          for (const seg of p.slice(0, -1)) cur = cur && cur[seg];
          const last = p[p.length - 1];
          if (cur && Array.isArray(cur[last])) {
            const before = cur[last].length;
            cur[last] = filterCorrelationArrayUsedFirst(cur[last], used, 120);
            const after = cur[last].length;
            if (after < before) {
              compressedResult.diagnostics.truncations.push({
                path: p.join("."),
                reason: "correlation_used_first_filter",
                originalSize: before,
                kept: after,
              });
            }
          }
        }
      });

      // 2) Recursive array capping (tables, diagnostics, extras) with deterministic ranking.
      const deepCapArraysInPlace = (root, opts) => {
        const seen = new WeakSet();
        const monthsOrder = { Jan:1, Feb:2, Mar:3, Apr:4, May:5, Jun:6, Jul:7, Aug:8, Sep:9, Oct:10, Nov:11, Dec:12 };
        const isPlainObj = (x) => x && typeof x === "object" && !Array.isArray(x);
        const capForPath = (path) => {
          if (path.startsWith("tables.")) return opts.tableRowCap;
          if (path.startsWith("diagnostics.timeSeries.canonical_period_series")) return opts.canonicalSeriesCap;
          if (path.startsWith("diagnostics.")) return opts.diagnosticsArrayCap;
          return opts.defaultArrayCap;
        };
        const scoreObj = (o) => {
          try {
            if (!o || typeof o !== "object") return 0;
            // Prefer explicit magnitude-like fields if present
            const candKeys = ["Total_Amt","Total","value","score","Amount","Amt","Revenue","Sales","corr","correlation","r"];
            for (const k of candKeys) {
              if (typeof o[k] === "number" && Number.isFinite(o[k])) return Math.abs(o[k]);
            }
            // Fallback: sum of absolute numeric values (fast, no stringify needed)
            let sum = 0;
            for (const v of Object.values(o)) {
              if (typeof v === "number" && Number.isFinite(v)) sum += Math.abs(v);
            }
            return sum || Object.keys(o).length; // key count as last resort
          } catch (_) {
            return 0;
          }
        };
        const keepMostRecentByPeriod = (arr, max) => {
          // Detect period field
          const periodKey = arr[0] && (("Period" in arr[0]) ? "Period" : (("period" in arr[0]) ? "period" : (("date" in arr[0]) ? "date" : (("month" in arr[0]) ? "month" : null))));
          if (!periodKey) return null;

          // SERA v3.0: Universal period sort key (handles months, quarters, YYYY-MM, ISO dates, etc.)
          const MONTHS_MAP = { jan: 1, feb: 2, mar: 3, apr: 4, may: 5, jun: 6, jul: 7, aug: 8, sep: 9, oct: 10, nov: 11, dec: 12 };
          const _psk = (period) => {
            if (period == null) return 0;
            const s = String(period).trim().toLowerCase();
            if (!s) return 0;
            // 3-letter month
            const m3 = s.slice(0, 3);
            if (MONTHS_MAP[m3]) return MONTHS_MAP[m3];
            // YYYY-MM
            const ym = s.match(/^(\d{4})[-/](\d{1,2})$/);
            if (ym) return Number(ym[1]) * 100 + Number(ym[2]);
            // Quarter
            const q = s.match(/(?:(\d{4})\s*[-/]?\s*)?q([1-4])/);
            if (q) return (q[1] ? Number(q[1]) * 100 : 0) + Number(q[2]) * 3 - 2;
            // Full date
            const ymd = s.match(/^(\d{4})[-/](\d{1,2})[-/](\d{1,2})/);
            if (ymd) return Number(ymd[1]) * 10000 + Number(ymd[2]) * 100 + Number(ymd[3]);
            // Full month names
            const fullMonths = { january:1, february:2, march:3, april:4, may:5, june:6, july:7, august:8, september:9, october:10, november:11, december:12 };
            if (fullMonths[s]) return fullMonths[s];
            return 0;
          };

          const withIdx = arr.map((o, idx) => ({ o, idx, ord: _psk(o && o[periodKey]) }));
          if (!withIdx.some(x => x.ord > 0)) return null;
          // Sort descending (most recent first), deterministic tie-break by original index
          withIdx.sort((a, b) => (b.ord - a.ord) || (a.idx - b.idx));
          const picked = withIdx.slice(0, max).sort((a, b) => a.idx - b.idx).map(x => x.o);
          return picked;
        };

        const capArray = (arr, path) => {
          const max = capForPath(path);
          if (!Array.isArray(arr) || arr.length <= max) return arr;

          // Primitive arrays: slice only (no sentinel row)
          const anyObj = arr.some(x => isPlainObj(x));
          if (!anyObj) {
            const out = arr.slice(0, max);
            root?.diagnostics?.truncations?.push?.({ path, reason: "deep_array_cap", originalSize: arr.length, kept: out.length });
            return out;
          }

          // Try to keep most recent periods when clearly time-based
          const recent = keepMostRecentByPeriod(arr, max);
          let kept;
          if (recent) kept = recent;
          else {
            const scored = arr.map((o, idx) => ({ o, idx, s: scoreObj(o) }));
            scored.sort((a,b) => (b.s - a.s) || (a.idx - b.idx));
            kept = scored.slice(0, max).sort((a,b) => a.idx - b.idx).map(x => x.o);
          }

          Object.defineProperty(kept, "__sera_truncated", { value: true, enumerable: false, configurable: true });
          Object.defineProperty(kept, "__sera_shown", { value: max, enumerable: false, configurable: true });
          Object.defineProperty(kept, "__sera_originalSize", { value: arr.length, enumerable: false, configurable: true });
          root?.diagnostics?.truncations?.push?.({ path, reason: "deep_array_cap", originalSize: arr.length, kept: max });
          return kept;
        };

        const walk = (node, path) => {
          if (!node || typeof node !== "object") return node;
          if (seen.has(node)) return node;
          seen.add(node);

          if (Array.isArray(node)) return node; // arrays are handled by their parent key

          for (const k of Object.keys(node)) {
            const v = node[k];
            const p = path ? `${path}.${k}` : String(k);
            if (Array.isArray(v)) node[k] = capArray(v, p);
            else if (isPlainObj(v)) walk(v, p);
          }
          return node;
        };
        walk(root, "");
      };

      try {
        deepCapArraysInPlace(compressedResult, {
          defaultArrayCap: 50,
          diagnosticsArrayCap: 120,
          canonicalSeriesCap: 200,
          tableRowCap: 250,
        });
      } catch (_) {}

      // 3) Hard global payload failsafe: if still too big, tighten caps deterministically.
      // FIXED: Use lightweight size estimation instead of JSON.stringify (prevents OOM)
      const approxSize = (obj) => {
        const seen = new WeakSet();
        let size = 0;
        const walk = (v) => {
          if (v == null) { size += 4; return; }
          if (typeof v === "string") { size += v.length + 2; return; }
          if (typeof v === "number" || typeof v === "boolean") { size += 8; return; }
          if (typeof v !== "object") { size += 10; return; }
          if (seen.has(v)) { size += 12; return; }
          seen.add(v);
          if (Array.isArray(v)) {
            size += 2;
            // Sample large arrays instead of walking every element
            const step = v.length > 100 ? Math.ceil(v.length / 50) : 1;
            let sampled = 0;
            for (let i = 0; i < v.length && size < 600000; i += step) { walk(v[i]); sampled++; }
            if (sampled > 0 && step > 1) size = Math.round(size * (v.length / sampled));
          } else {
            const keys = Object.keys(v);
            size += 2;
            // Sample large objects
            const step = keys.length > 100 ? Math.ceil(keys.length / 50) : 1;
            let sampled = 0;
            for (let i = 0; i < keys.length && size < 600000; i += step) {
              size += keys[i].length + 3;
              walk(v[keys[i]]);
              sampled++;
            }
            if (sampled > 0 && step > 1) size = Math.round(size * (keys.length / sampled));
          }
        };
        try { walk(obj); } catch (_) { return 500000; }
        return size;
      };
      try {
        const sz = approxSize({ ok: true, result: compressedResult });
        const HARD_MAX = 450000; // chars
        if (sz > HARD_MAX) {
          deepCapArraysInPlace(compressedResult, {
            defaultArrayCap: 30,
            diagnosticsArrayCap: 80,
            canonicalSeriesCap: 120,
            tableRowCap: 150,
          });
          compressedResult.diagnostics.truncations.push({
            path: "$payload",
            reason: "hard_payload_failsafe",
            sizeChars: sz,
            hardMaxChars: HARD_MAX,
          });
        }
      } catch (_) {}

      return { ok: true, result: compressedResult };
    } catch (err) {
  const msg = String(err && (err.stack || err.message || err));

  function __codeFrame(src, line, context = 4) {
  const lines = String(src || "").split(/\r?\n/);
  const L = Math.max(1, Math.min(Number(line) || 1, lines.length));
  const start = Math.max(1, L - context);
  const end = Math.min(lines.length, L + context);
  const out = [];
  for (let i = start; i <= end; i++) {
    const prefix = (i === L) ? ">>" : "  ";
    out.push(`${prefix} ${String(i).padStart(4, " ")} | ${lines[i - 1]}`);
  }
  return out.join("\n");
}

let __line = null;
try {
  const m = msg.match(/<anonymous>:(\d+):(\d+)/) || msg.match(/:(\d+):(\d+)/);
  if (m && m[1]) __line = Number(m[1]);
} catch (_) {}

const __frame = (__line && __wrappedSrc) ? __codeFrame(__wrappedSrc, __line, 6) : null;


  const rowCount =
    (globalThis && Array.isArray(globalThis.rawData)) ? globalThis.rawData.length :
    (typeof globalThis !== "undefined" && typeof globalThis.__numericRowsDropped === "number" && Array.isArray(rawData)) ? rawData.length :
    (Array.isArray(rawData) ? rawData.length : 0);

  return {
    ok: false,
    error: msg,
    extras: {},
    diagnostics: {
      rowCount: rowCount,
      entityCount: null,
      chosenEntityField: null,
      numericCoverageByField: {},
      correlationBlocks: [],
      truncations: [],
      blockStatus: [
        {
          blockId: "executor_error",
          family: "Executor",
          status: "failed",
          evidencePaths: [],
          reason: msg
        }
      ],
      notes: [
  "Executor failed before result could be produced.",
  (__line ? `Error location: <anonymous>:${__line}` : "Error location: unknown"),
  (__frame ? __frame : "No code frame available.")
]

    }
  };
}


if (!Array.isArray(diagnostics.blockStatus)) diagnostics.blockStatus = [];

diagnostics.blockStatus.unshift({
  blockId: "executor_error",
  family: "Executor",
  status: "failed",
  evidencePaths: [],
  reason: msg
});

  // ===============================

  const rowCount =
    (globalThis && Array.isArray(globalThis.rawData)) ? globalThis.rawData.length :
    (typeof globalThis !== "undefined" && typeof globalThis.__numericRowsDropped === "number" && Array.isArray(rawData)) ? rawData.length :
    (Array.isArray(rawData) ? rawData.length : 0);

  return {
    ok: false,
    error: msg,
    extras: {},
    diagnostics: {
      rowCount: rowCount,
      entityCount: null,
      chosenEntityField: null,
      numericCoverageByField: {},
      correlationBlocks: [],
      truncations: [],
      blockStatus: [
        {
          blockId: "executor_error",
          family: "Executor",
          status: "failed",
          evidencePaths: [],
          reason: msg
        }
      ],
      notes: ["Executor failed before result could be produced."]
    }
  };
}  // <-- closes catch(err)

// âœ… ADD THIS: closes async function execute(vars, options = {})

// âœ… ADD THIS: closes the Executor module and exposes methods
return { normalizeRawData, setupGlobalEnvironment, execute };
})();



// ============================================================================
// UTILITY FUNCTIONS (Global helpers for generated code)
// ============================================================================

// ===============================
// P1: NUMERIC SANITIZER (finite -> number, non-finite -> null)
// ===============================

function safeNumber(x) {
  if (x == null) return null;
  if (typeof x === "number") return Number.isFinite(x) ? x : null;

  if (typeof x === "bigint") {
    const n = Number(x);
    return Number.isFinite(n) ? n : null;
  }

  if (typeof x === "string") {
    const s = x.trim();
    if (!s) return null;
    const n = Number(s);
    return Number.isFinite(n) ? n : null;
  }

  const n = Number(x);
  return Number.isFinite(n) ? n : null;
}

function asArrayLike(v) {
  if (Array.isArray(v)) return v;
  if (v == null) return [];

  try {
    if (typeof ArrayBuffer !== "undefined" && ArrayBuffer.isView && ArrayBuffer.isView(v)) {
      return Array.from(v);
    }
  } catch (_) {}

  try {
    if (v instanceof Set) return Array.from(v.values());
    if (v instanceof Map) return Array.from(v.values());
  } catch (_) {}

  if (typeof v === "object") {
    if (Array.isArray(v.data)) return v.data;
    if (Array.isArray(v.values)) return v.values;

    const keys = Object.keys(v);
    const numericKeys = keys.filter(k => String(Number(k)) === k);
    if (numericKeys.length) {
      numericKeys.sort((a, b) => Number(a) - Number(b));
      return numericKeys.map(k => v[k]);
    }

    return Object.values(v);
  }

  return [];
}


function sanitizeNumbersDeep(obj) {
  const seen = new WeakSet();

  const walk = (v) => {
    if (typeof v === "number" || typeof v === "bigint") return safeNumber(v);
    if (v == null || typeof v !== "object") return v;
    if (v instanceof Date) return v;

    if (seen.has(v)) return v;
    seen.add(v);

    if (Array.isArray(v)) {
      for (let i = 0; i < v.length; i++) v[i] = walk(v[i]);
      return v;
    }

    for (const k of Object.keys(v)) v[k] = walk(v[k]);
    return v;
  };

  return walk(obj);
}

globalThis.safeNumber = safeNumber;
globalThis.sanitizeNumbersDeep = sanitizeNumbersDeep;


// ===============================
// P?: DIAGNOSTICS HYDRATOR (FOREVER FIX)
// - Fills correlationBlocks from extras.drivers.* when missing/incomplete
// - Fills blockStatus evidencePaths by FAMILY (not blockId names)
// ===============================

function _deepGet(obj, path) {
  if (!obj || typeof obj !== "object") return undefined;
  const parts = String(path || "").split(".").filter(Boolean);
  let cur = obj;
  for (const p of parts) {
    if (!cur || typeof cur !== "object") return undefined;
    if (!(p in cur)) return undefined;
    cur = cur[p];
  }
  return cur;
}


function ensureCorrelationBlocksComplete(out, rawData) {
  if (!out || typeof out !== "object") return;
  out.diagnostics = (out.diagnostics && typeof out.diagnostics === "object") ? out.diagnostics : {};
  out.extras = (out.extras && typeof out.extras === "object") ? out.extras : {};

  const diag = out.diagnostics;

  const isInjectedOnly = (arr) => {
    if (!Array.isArray(arr) || !arr.length) return true;
    return arr.every(b => b && (b._injected === true || (b.status === "skipped" && /injected/i.test(String(b.reason || "")))));
  };

  // If we already have non-trivial correlation blocks, just normalize them.
  if (Array.isArray(diag.correlationBlocks) && diag.correlationBlocks.length && !isInjectedOnly(diag.correlationBlocks)) {
    diag.correlationBlocks = diag.correlationBlocks.map(b => {
      if (!b || typeof b !== "object") return b;
      const nTotal = Number.isFinite(b.nTotal) ? b.nTotal : (Number.isFinite(diag.rowCount) ? diag.rowCount : 0);
      const nValidPairs = Number.isFinite(b.nValidPairs) ? b.nValidPairs : (Number.isFinite(b.n) ? b.n : 0);
      const coverage = Number.isFinite(b.coverage) ? b.coverage : (nTotal ? (nValidPairs / nTotal) : 0);
      const value = (typeof b.value === "number" && Number.isFinite(b.value)) ? b.value : null;

      let status = String(b.status || "").toLowerCase();
      if (!status) status = (value == null ? "downgraded" : "ok");
      if (value == null && status === "ok") status = "downgraded";

      const finalValue = (status === "ok" ? value : null);

      return {
        ...b,
        xField: b.xField != null ? String(b.xField) : (b.field != null ? String(b.field) : "x"),
        yField: b.yField != null ? String(b.yField) : "target",
        method: b.method || "spearman",
        nTotal,
        nValidPairs,
        coverage,
        value,
        status
      };
    });
    return;
  }

  // 1) Try hydrating from extras.drivers (if present)
  const drivers = out.extras.drivers;
  const outBlocks = [];

  const inferTarget = (key) => {
    const k = String(key || "").toLowerCase();
    const coverage = diag.numericCoverageByField && typeof diag.numericCoverageByField === "object" ? diag.numericCoverageByField : {};
    const numericKeys = Object.keys(coverage);

    const pick = (re) => numericKeys.find(nk => re.test(String(nk).toLowerCase())) || null;

    if (k.includes("efficien")) return pick(/efficien/) || "target";
    if (k.includes("defect")) return pick(/defect|reject|fault|scrap|rate/) || "target";
    if (k.includes("waste")) return pick(/waste|loss/) || "target";
    if (k.includes("erosion") || k.includes("margin") || k.includes("profit")) return pick(/erosion|margin|profit|cost|variance/) || "target";
    if (k.includes("cost")) return pick(/cost|price|unit/) || "target";
    return "target";
  };

  const addFromArray = (arr, keyName) => {
    if (!Array.isArray(arr)) return;
    const yField = inferTarget(keyName);

    for (const r of arr) {
      if (!r || typeof r !== "object") continue;
      const xField = r.field ?? r.input ?? r.xField ?? null;
      if (!xField) continue;

      const n = Number.isFinite(r.n) ? r.n : null;
      const rowCount = Number.isFinite(diag.rowCount) ? diag.rowCount : null;
      const nTotal = rowCount ?? (n ?? 0);
      const nValidPairs = n ?? 0;
      const coverage = (rowCount && n != null) ? (n / rowCount) : (nTotal ? (nValidPairs / nTotal) : 0);

      const value =
        (Number.isFinite(r.spearman) ? r.spearman :
         Number.isFinite(r.correlation) ? r.correlation :
         Number.isFinite(r.coefficient) ? r.coefficient :
         null);

      const method =
        Number.isFinite(r.spearman) ? "spearman" :
        (Number.isFinite(r.correlation) || Number.isFinite(r.coefficient)) ? "pearson" :
        "unknown";

      outBlocks.push({
        xField: String(xField),
        yField,
        method,
        nValidPairs,
        nTotal,
        coverage: Number.isFinite(coverage) ? coverage : 0,
        value,
        status: (value == null ? "downgraded" : "ok"),
        reason: (value == null ? "Driver present but correlation value missing/non-finite." : undefined)
      });
    }
  };

  if (drivers && typeof drivers === "object") {
    for (const k of Object.keys(drivers)) addFromArray(drivers[k], k);
  }

  // 2) If still empty, compute a universal correlation scan from rawData
  const needUniversal = !outBlocks.length;

  const computeUniversal = () => {
    const rows = Array.isArray(rawData)
      ? rawData
      : (rawData && typeof rawData === "object" ? Object.values(rawData).flat() : []);

    if (!rows.length) return [];

    const nAll = rows.length;
    const maxN = 5000;
    const step = Math.max(1, Math.floor(nAll / maxN));

    const sample = [];
    for (let i = 0; i < nAll; i += step) {
      const r = rows[i];
      if (r && typeof r === "object") sample.push(r);
      if (sample.length >= maxN) break;
    }

    const nTotal = sample.length;
    if (!nTotal) return [];

    // Determine numeric fields: prefer diagnostics coverage map
    let numericFields = [];
    const covMap = diag.numericCoverageByField;
    if (covMap && typeof covMap === "object" && !Array.isArray(covMap)) {
      numericFields = Object.keys(covMap).filter(k => {
        const v = covMap[k];
        const c = v && typeof v === "object" ? Number(v.coverage) : null;
        return Number.isFinite(c) && c >= 0.6;
      });
    }

    // fallback: sniff first row keys
    if (!numericFields.length) {
      const keys = Object.keys(sample[0] || {});
      const toNum = _.stats && _.stats.toNumber ? _.stats.toNumber : (v) => (typeof v === 'number' && Number.isFinite(v) ? v : null);
      numericFields = keys.filter(k => {
        let ok = 0, seen = 0;
        for (let i = 0; i < Math.min(sample.length, 200); i++) {
          const val = toNum(sample[i][k]);
          if (val == null) continue;
          ok += 1;
          seen += 1;
          if (ok >= 10) break;
        }
        return ok >= 10;
      });
    }

    if (numericFields.length < 2) return [];

    const lower = (s) => String(s).toLowerCase();
    const pickFirst = (re) => numericFields.find(f => re.test(lower(f))) || null;

    const yField =
      pickFirst(/erosion|margin|profit|contribution|gm|gross|net|variance|unitcost|cost/) ||
      pickFirst(/waste|defect|scrap|loss|reject/) ||
      pickFirst(/efficien|yield|rate|utili/) ||
      numericFields[0];

    const toNum = _.stats && _.stats.toNumber ? _.stats.toNumber : (v) => (typeof v === 'number' && Number.isFinite(v) ? v : null);

    const blocks = [];

    for (const xField of numericFields) {
      if (xField === yField) continue;
      const xs = [];
      const ys = [];
      for (const r of sample) {
        const xv = toNum(r[xField]);
        const yv = toNum(r[yField]);
        if (!Number.isFinite(xv) || !Number.isFinite(yv)) continue;
        xs.push(xv);
        ys.push(yv);
      }
      const nValidPairs = xs.length;
      const coverage = nTotal ? (nValidPairs / nTotal) : 0;

      let value = null;
      let status = "downgraded";
      let reason = undefined;

      if (nValidPairs >= 30 && coverage >= 0.4) {
        try {
          value = _.correlation && _.correlation.spearman ? _.correlation.spearman(xs, ys) : null;
        } catch (_) {
          value = null;
        }

        if (typeof value === "number" && Number.isFinite(value)) {
          status = (coverage >= 0.7 ? "ok" : "downgraded");
        } else {
          value = null;
          status = "downgraded";
          reason = "Spearman correlation not computable (non-finite result).";
        }
      } else {
        value = null;
        status = "downgraded";
        reason = "Insufficient valid pairs or coverage for stable correlation.";
      }

      blocks.push({
        xField: String(xField),
        yField: String(yField),
        method: "spearman",
        nTotal,
        nValidPairs,
        coverage,
        value,
        status,
        reason
      });
    }

    // Keep top 12 by abs correlation where value is finite
    const finite = blocks.filter(b => typeof b.value === "number" && Number.isFinite(b.value));
    finite.sort((a, b) => Math.abs(b.value) - Math.abs(a.value));

    const top = finite.slice(0, 12);

    // If none are finite, keep a single transparent skipped marker
    if (!top.length) {
      return [{
        blockId: "correlation_scan",
        family: "Correlation & Drivers",
        xField: numericFields[0],
        yField: yField,
        method: "spearman",
        nTotal,
        nValidPairs: 0,
        coverage: 0,
        value: null,
        status: "skipped",
        reason: "Correlation scan ran, but no stable finite correlations were computable."
      }];
    }

    // Attach a driver-style view for downstream compatibility
    out.extras.drivers = (out.extras.drivers && typeof out.extras.drivers === "object") ? out.extras.drivers : {};
    out.extras.drivers.universal_correlations = top.map(b => ({
      field: b.xField,
      spearman: b.value,
      absCorrelation: Math.abs(b.value),
      n: b.nValidPairs
    }));

    return top;
  };

  const finalBlocks = outBlocks.length ? outBlocks : (needUniversal ? computeUniversal() : []);

  if (finalBlocks && finalBlocks.length) {
    diag.correlationBlocks = finalBlocks;
  }

  // Final normalization + required fields
  if (!Array.isArray(diag.correlationBlocks)) diag.correlationBlocks = [];
  diag.correlationBlocks = diag.correlationBlocks.map(b => {
    if (!b || typeof b !== "object") return b;
    const nTotal = Number.isFinite(b.nTotal) ? b.nTotal : (Number.isFinite(diag.rowCount) ? diag.rowCount : 0);
    const nValidPairs = Number.isFinite(b.nValidPairs) ? b.nValidPairs : 0;
    const coverage = Number.isFinite(b.coverage) ? b.coverage : (nTotal ? (nValidPairs / nTotal) : 0);
    const value = (typeof b.value === "number" && Number.isFinite(b.value)) ? b.value : null;
    let status = String(b.status || "").toLowerCase();
    if (!status) status = (value == null ? "downgraded" : "ok");
    if (value == null && status === "ok") status = "downgraded";
    if ((coverage < 0.4 || nValidPairs < 30) && value != null) {
      // contract: weak pairs => null value + downgraded
      status = "downgraded";
      return { ...b, nTotal, nValidPairs, coverage, value: null, status, reason: b.reason || "Weak coverage/pairs; value nulled per contract." };
    }
    return { ...b, nTotal, nValidPairs, coverage, value: (status === "ok" ? value : null), status };
  });
}




function ensureBlockStatusEvidencePaths(out) {
  if (!out || typeof out !== "object") return;
  out.diagnostics = (out.diagnostics && typeof out.diagnostics === "object") ? out.diagnostics : {};
  if (!Array.isArray(out.diagnostics.blockStatus)) out.diagnostics.blockStatus = [];

  const deep = (obj, path) => {
    try {
      return path.split('.').reduce((a, k) => (a && a[k] != null ? a[k] : undefined), obj);
    } catch (_) {
      return undefined;
    }
  };

  const nonEmpty = (v) => {
    if (Array.isArray(v)) return v.length > 0;
    if (v && typeof v === "object") {
      // treat {columns,rows} objects as evidence if rows non-empty
      if (Array.isArray(v.rows)) return v.rows.length > 0;
      return Object.keys(v).length > 0;
    }
    return v != null;
  };

  const addIf = (b, p) => {
    if (!p) return;
    const v = deep(out, p);
    if (nonEmpty(v)) b.evidencePaths.push(p);
  };

  const tables = (out.tables && typeof out.tables === "object") ? out.tables : {};
  const series = (out.series && typeof out.series === "object") ? out.series : {};
  const extras = (out.extras && typeof out.extras === "object") ? out.extras : {};

  // Pre-compute table candidates (non-empty only)
  const tableCandidates = [];
  for (const k of Object.keys(tables)) {
    const v = tables[k];
    if (Array.isArray(v) && v.length) tableCandidates.push(`tables.${k}`);
    else if (v && typeof v === "object" && Array.isArray(v.rows) && v.rows.length) tableCandidates.push(`tables.${k}.rows`);
  }

  const seriesCandidates = [];
  for (const k of Object.keys(series)) {
    const v = series[k];
    if (Array.isArray(v) && v.length) seriesCandidates.push(`series.${k}`);
  }

  const pickTopByHint = (paths, hintRe, limit) => {
    const outp = [];
    for (const p of paths) {
      if (hintRe && !hintRe.test(String(p).toLowerCase())) continue;
      outp.push(p);
      if (outp.length >= (limit || 3)) break;
    }
    return outp;
  };

  for (const b of out.diagnostics.blockStatus) {
    if (!b || typeof b !== "object") continue;
    if (!Array.isArray(b.evidencePaths)) b.evidencePaths = [];

    // keep existing non-empty evidence
    b.evidencePaths = b.evidencePaths.filter(p => nonEmpty(deep(out, p)));
    if (b.evidencePaths.length) continue;

    const id = String(b.blockId || "");
    const fam = String(b.family || "").toLowerCase();

    // 1) Direct id mapping
    if (id) {
      if (deep(out, `tables.${id}.rows`) != null) addIf(b, `tables.${id}.rows`);
      if (deep(out, `tables.${id}`) != null) addIf(b, `tables.${id}`);
      if (deep(out, `series.${id}`) != null) addIf(b, `series.${id}`);
      if (deep(out, `extras.${id}`) != null) addIf(b, `extras.${id}`);
    }

    // 2) Family-driven inference
    if (!b.evidencePaths.length) {
      if (fam.includes("correlation")) {
        addIf(b, "diagnostics.correlationBlocks");
      } else if (fam.includes("time") || fam.includes("series") || fam.includes("movement") || fam.includes("trend")) {
        const picks = pickTopByHint(seriesCandidates, /(trend|time|series|movement|drift)/i, 3);
        for (const p of (picks.length ? picks : seriesCandidates.slice(0, 3))) addIf(b, p);
      } else if (fam.includes("anomal") || fam.includes("outlier") || fam.includes("risk")) {
        // prefer obvious anomaly tables if present
        const anomalyTables = pickTopByHint(tableCandidates, /(anomal|outlier|risk|warning)/i, 3);
        for (const p of (anomalyTables.length ? anomalyTables : tableCandidates.slice(0, 3))) addIf(b, p);
        // plus extras.anomalies if present
        if (extras.anomalies) addIf(b, "extras.anomalies");
      } else if (fam.includes("entity") || fam.includes("ranking") || fam.includes("aggregation") || fam.includes("slice") || fam.includes("frontier")) {
        const ranked = pickTopByHint(tableCandidates, /(rank|top|erosion|profit|margin|cost|efficien|defect|waste)/i, 4);
        for (const p of (ranked.length ? ranked : tableCandidates.slice(0, 4))) addIf(b, p);
      } else {
        // fallback: any meaningful table
        for (const p of tableCandidates.slice(0, 2)) addIf(b, p);
        for (const p of seriesCandidates.slice(0, 1)) addIf(b, p);
      }
    }
  }
}



globalThis.ensureCorrelationBlocksComplete = ensureCorrelationBlocksComplete;
globalThis.ensureBlockStatusEvidencePaths = ensureBlockStatusEvidencePaths;


// ===============================
// P2: RISK_PROBABILITY HARDENING
// ===============================

// Standard normal CDF approximation (no external libs)
function _normalCdf(z) {
  const x = safeNumber(z);
  if (x == null) return null;

  // Abramowitz-Stegun style approximation via erf-ish polynomial
  const t = 1 / (1 + 0.2316419 * Math.abs(x));
  const d = 0.3989423 * Math.exp(-0.5 * x * x);
  let p = d * t * (0.3193815 + t * (-0.3565638 + t * (1.781478 + t * (-1.821256 + t * 1.330274))));
  if (x > 0) p = 1 - p;

  return safeNumber(p);
}

function computeRiskProbability(observations, options = {}) {
  const reasons = [];

  const input = Array.isArray(observations) ? observations : [];
  const cleaned = [];
  for (const v of input) {
    const n = safeNumber(v);
    if (n == null) continue;
    cleaned.push(n);
  }

  const nObservations = cleaned.length;
  if (nObservations === 0) reasons.push("No finite numeric observations available.");

  const threshold = safeNumber(options.threshold);
  if (threshold == null) reasons.push("Threshold is missing or non-finite; cannot compute below-threshold frequency.");

  // Historical frequency (empirical)
  let historicalCount = null;
  let historicalFrequency = null;

  if (threshold != null && nObservations > 0) {
    let cnt = 0;
    for (const x of cleaned) if (x < threshold) cnt++;
    historicalCount = safeNumber(cnt);
    historicalFrequency = safeNumber(cnt / nObservations); // 0 is valid
  } else {
    if (threshold != null && nObservations === 0) reasons.push("No observations; empirical frequency not computable.");
  }

  // Mean + variance (sample) for z-score / normal approximation
  let zScoreToThreshold = null;
  let normalApproxProbability = null;

  if (nObservations >= 2) {
    let sum = 0;
    for (const x of cleaned) sum += x;
    const mean = sum / nObservations;

    let sse = 0;
    for (const x of cleaned) {
      const dx = x - mean;
      sse += dx * dx;
    }

    const variance = sse / (nObservations - 1);
    const sd = Math.sqrt(variance);

    if (!(sd > 0)) {
      reasons.push("Variance is zero (or not positive); z-score / normal approximation not computable.");
    } else if (threshold == null) {
      reasons.push("Threshold missing; z-score / normal approximation not computable.");
    } else {
      zScoreToThreshold = safeNumber((threshold - mean) / sd);
      if (zScoreToThreshold == null) {
        reasons.push("z-score became non-finite; normal approximation skipped.");
      } else {
        normalApproxProbability = _normalCdf(zScoreToThreshold);
        if (normalApproxProbability == null) {
          reasons.push("Normal CDF returned non-finite; normal approximation not computable.");
        }
      }
    }
  } else {
    if (nObservations === 1) reasons.push("Need at least 2 observations for variance/z-score; only 1 available.");
    if (nObservations === 0) reasons.push("Need at least 2 observations for variance/z-score; none available.");
  }

  // Decide "modeChosen" based on what is actually computable
  const hasEmpirical = safeNumber(historicalFrequency) != null;
  const hasNormal = safeNumber(normalApproxProbability) != null;

  const modeChosen = hasEmpirical
    ? "empirical_frequency"
    : hasNormal
      ? "normal_approx"
      : "not_computable";

  return {
    modeChosen,
    threshold: safeNumber(threshold),

    // Required fields (schema-safe, may be null)
    nMonths: safeNumber(nObservations),
    nTransitions: safeNumber(nObservations > 0 ? Math.max(0, nObservations - 1) : null),

    // Back-compat
    nObservations: safeNumber(nObservations),

    historicalCount: safeNumber(historicalCount),
    historicalFrequency: safeNumber(historicalFrequency),

    zScoreToThreshold: safeNumber(zScoreToThreshold),
    normalApproxProbability: safeNumber(normalApproxProbability), // optional

    reasons: Array.isArray(reasons) ? reasons : [],
    note: safeNumber(normalApproxProbability) != null
      ? "Normal approximation based on sample mean/stddev of available observations."
      : "No probability fabricated; missing prerequisites or insufficient data."
  };
}

globalThis.computeRiskProbability = computeRiskProbability;

// ===============================
// P3: EXEC SUMMARY STRING SAFETY
// ===============================

function fmtNumber(x, decimals = 2) {
  const n = safeNumber(x);
  if (n == null) return "Not computable from available data";
  return n.toFixed(decimals);
}

function fmtPercent(x, decimals = 1) {
  const n = safeNumber(x);
  if (n == null) return "Not computable from available data";
  return (n * 100).toFixed(decimals) + "%";
}

globalThis.fmtNumber = fmtNumber;
globalThis.fmtPercent = fmtPercent;


// FIX: Post-processing to enforce risk + baseline table contracts (schema-agnostic)
function _inferBaselineSeries(out) {
  if (!out || typeof out !== "object") return null;
  const s = out.series || {};
  const t = out.tables || {};
  // FIX: broaden candidates so risk wiring uses the same canonical baseline vectors used in tables/series
  const candidates = [
  // series (preferred)
  s.monthly_totals,
  s.monthlyTotals,
  s.monthly_total,
  s.monthlyTotal,

  // âœ… add these (your Gerald output uses monthly_trend)
  s.monthly_trend,
  s.monthlyTrend,
  s.monthly_trends,
  s.monthlyTrends,

  s.time_series,
  s.timeSeries,
  s.baseline,
  s.baseline_series,
  s.baselineSeries,

  // tables (fallbacks)
  t.baseline,
  t.baseline_time_series,
  t.baseline_timeseries,
  t.baselineTimeSeries,

  // âœ… add these (your Gerald output uses performance_baseline)
  t.performance_baseline,
  t.performanceBaseline,

  t.monthly_totals,
  t.monthlyTotals,
  t.monthly_total,
  t.monthlyTotal,
  t.time_series,
  t.timeSeries
];

  for (const c of candidates) if (Array.isArray(c) && c.length) return c;
  return null;
}


function _inferValueKey(row) {
  if (!row || typeof row !== "object") return null;
  const prefs = ["value", "Value", "total", "Total", "amount", "Amount", "metric", "Metric"];
  for (const k of prefs) if (k in row) return k;
  // Heuristic: first finite numeric field that's not obviously a period label
  const skip = new Set(["period", "Period", "month", "Month", "date", "Date", "time", "Time", "key", "Key"]);
  for (const k of Object.keys(row)) {
    if (skip.has(k)) continue;
    if (safeNumber(row[k]) != null) return k;
  }
  return null;
}

function _inferNMonthsAndTransitions(series) {
  if (!Array.isArray(series) || !series.length) return { nMonths: null, nTransitions: null, values: [] };

  const values = [];
  const vKey = _inferValueKey(series[0]) || "value";
  for (const r of series) {
    const n = safeNumber(r && r[vKey]);
    if (n == null) continue;
    values.push(n);
  }

  const nMonths = values.length ? values.length : null;

  let nTransitions = 0;
  if (values.length >= 2) nTransitions = values.length - 1;
  else nTransitions = 0;

  return { nMonths: safeNumber(nMonths), nTransitions: safeNumber(values.length ? nTransitions : null), values };
}

// FIX: historical_drops frequency + denominator explicitness
function safeInt(x) { // FIX: integer-safe counts for months/transitions
  const n = safeNumber(x);
  if (n == null) return null;
  const t = Math.trunc(n);
  return Number.isFinite(t) ? t : null;
}

globalThis.safeInt = safeInt;

// FIX: safe formatting helpers for executive summary + any string outputs
function fmtNumber(x, decimals = 2) {
  const n = safeNumber(x);
  if (n == null) return "Not computable from available data";
  const d = safeInt(decimals);
  const dd = d == null ? 2 : Math.max(0, Math.min(10, d));
  try {
    const s = n.toFixed(dd);
    return /NaN|Infinity/i.test(s) ? "Not computable from available data" : s;
  } catch {
    return "Not computable from available data";
  }
}

function fmtPercent(x, decimals = 1) {
  const n = safeNumber(x);
  if (n == null) return "Not computable from available data";
  const p = safeNumber(n * 100);
  if (p == null) return "Not computable from available data";
  const d = safeInt(decimals);
  const dd = d == null ? 1 : Math.max(0, Math.min(10, d));
  try {
    const s = p.toFixed(dd) + "%";
    return /NaN|Infinity/i.test(s) ? "Not computable from available data" : s;
  } catch {
    return "Not computable from available data";
  }
}

globalThis.fmtNumber = fmtNumber;
globalThis.fmtPercent = fmtPercent;

// FIX: no NaN/Infinity/-Infinity tokens anywhere in generated strings
function _sanitizeNonFiniteTokensInString(str) {
  if (typeof str !== "string" || !str) return str;
  let s = str;
  s = s.replace(/(?:NaN|-Infinity|Infinity)\s*%/g, "Not computable from available data");
  s = s.replace(/-Infinity/g, "Not computable from available data")
       .replace(/\bInfinity\b/g, "Not computable from available data")
       .replace(/\bNaN\b/g, "Not computable from available data");
  return s;
}

function sanitizeNonFiniteStringsDeep(obj) { // FIX:
  const seen = new WeakSet();
  const walk = (v) => {
    if (typeof v === "string") return _sanitizeNonFiniteTokensInString(v);
    if (v == null || typeof v !== "object") return v;
    if (v instanceof Date) return v;
    if (seen.has(v)) return v;
    seen.add(v);
    if (Array.isArray(v)) {
      for (let i = 0; i < v.length; i++) v[i] = walk(v[i]);
      return v;
    }
    for (const k of Object.keys(v)) v[k] = walk(v[k]);
    return v;
  };
  return walk(obj);
}

globalThis.sanitizeNonFiniteStringsDeep = sanitizeNonFiniteStringsDeep;

// FIX: executive summary patcher (only describes computed metrics; never prints NaN/Infinity)
function ensureExecutiveSummary(out) {
  if (!out || typeof out !== "object") return;

  const rp = (out.extras && typeof out.extras === "object" && out.extras.risk_probability && typeof out.extras.risk_probability === "object")
    ? out.extras.risk_probability
    : null;

  // P5: local safe formatters (no NaN/Infinity, no "Not computable ..." fragments)
  const fmtNumber = (x, digits = 2) => {
    const n = safeNumber(x);
    return n == null ? null : n.toFixed(digits);
  };

  const fmtPercent = (x, digits = 1) => {
    const n = safeNumber(x);
    return n == null ? null : (n * 100).toFixed(digits) + "%";
  };


  const parts = [];

  const hf = rp ? safeNumber(rp.historicalFrequency) : null;
  const z = rp ? safeNumber(rp.zScoreToThreshold) : null;
  const np = rp ? safeNumber(rp.normalApproxProbability) : null;

  if (hf != null) {
    const nt = safeInt(rp ? rp.nTransitions : null);
    parts.push((hf != null && fmtPercent(hf) != null)
    ? `Historical drop frequency ${fmtPercent(hf)}${(nt != null && nt > 0) ? ` over ${nt} transition${nt === 1 ? "" : "s"}` : ""}.`
    : null);

  }

  if (np != null) {
  parts.push((np != null && fmtPercent(np) != null)
    ? `Normal approximation ${fmtPercent(np)}${(z != null && fmtNumber(z, 2) != null) ? ` (z=${fmtNumber(z, 2)}).` : "."}`
    : null);

  } else if (z != null) {
    parts.push(`z-score to threshold ${fmtNumber(z, 2)}.`);
  }

  const riskLine = parts.length
  ? `Risk metrics: ${parts.join(" ")}`
  : "";

  out.methodOutputs = out.methodOutputs && typeof out.methodOutputs === "object" ? out.methodOutputs : {};
  out.methodOutputs.risk_summary_line = riskLine || null;


  const seen = new WeakSet();
  const walk = (obj) => {
    if (obj == null || typeof obj !== "object") return;
    if (obj instanceof Date) return;
    if (seen.has(obj)) return;
    seen.add(obj);

    if (Array.isArray(obj)) {
      for (const it of obj) walk(it);
      return;
    }

    for (const k of Object.keys(obj)) {
      const v = obj[k];
      if (typeof v === "string" && /executive\s*summary/i.test(String(k))) {
        let s = _sanitizeNonFiniteTokensInString(v);

        // Remove any existing risk/probability/drop lines to prevent contradictions
        const chunks = String(s).split(/\n+/).map(x => x.trim()).filter(Boolean);
        const kept = [];
        for (const c of chunks) {
          if (/(^|\b)(risk|probab|drop)\b/i.test(c)) continue;
          kept.push(c);
        }

        const separator = (chunks.length > 1) ? "\n" : " ";
        const base = kept.join(separator).trim();

        obj[k] = (base ? (base + separator + riskLine) : riskLine).trim();
      } else if (v && typeof v === "object") {
        walk(v);
      }
    }
  };

  walk(out);
}

globalThis.ensureExecutiveSummary = ensureExecutiveSummary;

// FIX: canonical vectors for monthly totals + Growth_Pct transitions (used by risk + historical_drops)
function _extractRowNumericValue(row, preferredKey) {
  if (row == null) return null;

  if (typeof row === "number" || typeof row === "bigint" || typeof row === "string") return safeNumber(row);
  if (typeof row !== "object" || Array.isArray(row)) return null;

  if (preferredKey && Object.prototype.hasOwnProperty.call(row, preferredKey)) {
    const n0 = safeNumber(row[preferredKey]);
    if (n0 != null) return n0;
  }

  const skip = new Set(["period", "Period", "month", "Month", "date", "Date", "time", "Time", "key", "Key", "label", "Label"]);
  for (const k of Object.keys(row)) {
    if (skip.has(k)) continue;
    const n = safeNumber(row[k]);
    if (n != null) return n;
  }
  return null;
}

function _extractBaselineVectors(out) { // FIX:
  const series = _inferBaselineSeries(out);
  if (!Array.isArray(series) || !series.length) {
    return { series: null, valueKey: null, rowValues: [], monthlyValues: [], growthValues: [], nMonths: null, nTransitions: null };
  }

  const firstObj = series.find(r => r && typeof r === "object" && !Array.isArray(r));
  const valueKey = firstObj ? (_inferValueKey(firstObj) || "value") : null;

  const rowValues = series.map(r => _extractRowNumericValue(r, valueKey));
  const monthlyValues = rowValues.filter(v => v != null);
  const nMonths = safeInt(monthlyValues.length);

  const growthValues = [];
  let prev = null;

  for (let i = 0; i < series.length; i++) {
    const r = series[i];

    if (i === 0) {
      prev = rowValues[i];
      continue;
    }

    let g = null;

    if (r && typeof r === "object" && !Array.isArray(r)) {
      if ("Growth_Pct" in r) g = safeNumber(r.Growth_Pct);
      else if ("growth_pct" in r) g = safeNumber(r.growth_pct);
      else if ("growthPct" in r) g = safeNumber(r.growthPct);
      else if ("GrowthPct" in r) g = safeNumber(r.GrowthPct);
    }

    if (g == null) {
      const cur = rowValues[i];
      if (cur != null && prev != null && prev !== 0) g = safeNumber((cur - prev) / Math.abs(prev));
    }

    if (g != null) growthValues.push(g);
    prev = rowValues[i];
  }

  const nTransitions = safeInt(growthValues.length);

  return { series, valueKey, rowValues, monthlyValues, growthValues, nMonths, nTransitions };
}

function ensureHistoricalDrops(out) {
  if (!out || typeof out !== "object") return;
  out.extras ||= {};
  const hd = out.extras.historical_drops;
  if (!hd || typeof hd !== "object") return;

  const vectors = _extractBaselineVectors(out);

  const metaVectors = (out.metaVectors && typeof out.metaVectors === "object") ? out.metaVectors : null;
  const mvTransitions = (metaVectors && Array.isArray(metaVectors.baselineGrowth)) ? metaVectors.baselineGrowth.length : 0;

  const countRaw = safeInt(hd.count ?? hd.historicalCount ?? hd.dropsCount);
  const count = (countRaw != null) ? countRaw : 0;

  let nTransitions = safeInt(mvTransitions);

// âœ… fallback to extracted vectors if metaVectors is empty
if ((nTransitions == null || nTransitions === 0) && vectors && vectors.nTransitions != null) {
  nTransitions = safeInt(vectors.nTransitions);
}


  hd.count = safeInt(count);
  hd.nTransitions = nTransitions;

  // FIX: denominator + frequency must be computable whenever possible; 0 is valid
  if (nTransitions > 0) {
    hd.frequency = safeNumber(count / nTransitions);
  } else {
    hd.frequency = null; // null ONLY when nTransitions == 0
  }
}

// =============================================
// UNIVERSAL: Time-series drop risk repair from table-shaped outputs
// Works when out.tables is an ARRAY of {name, columns, rows}.
// Repairs any table that has:
// - 1 entity column (string-like, e.g. "Sales Rep")
// - >= 3 month total columns (e.g. Jan..Dec)
// - columns Empirical_Risk_Pct and/or Normal_Z_Score (optional but used if present)
// Also repairs out.extras.mom_growth + out.extras.risk_analysis (if present)
// =============================================
function ensureTimeSeriesRiskFromTablesDeep(out) {
  if (!out || typeof out !== "object") return;

  const tablesArr = Array.isArray(out.tables) ? out.tables : null;
  if (!tablesArr || tablesArr.length === 0) return;

  out.extras ||= {};
  const ex = out.extras;

  const num = (v) => {
    const n = (typeof v === "number") ? v : (v == null ? NaN : Number(v));
    return Number.isFinite(n) ? n : null;
  };
  const isStrish = (v) => typeof v === "string" || (v != null && typeof v !== "object");

  const monthOrder = ["Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"];

  // threshold: prefer extras.risk_probability.threshold, else default -0.2
  const rp = (ex.risk_probability && typeof ex.risk_probability === "object") ? ex.risk_probability : null;
  let threshold = rp ? num(rp.threshold) : null;
  if (threshold == null) threshold = -0.2;

  const meanSd = (vals) => {
    const v = (vals || []).map(num).filter(x => x != null);
    const n = v.length;
    if (!n) return { n: 0, mean: null, sd: null };
    const mean = v.reduce((a,b)=>a+b,0)/n;
    if (n < 2) return { n, mean, sd: null };
    let sse = 0;
    for (const x of v) { const d = x-mean; sse += d*d; }
    const sd = Math.sqrt(sse/(n-1));
    return { n, mean, sd: (Number.isFinite(sd) && sd > 0) ? sd : null };
  };

  // Find candidate tables to repair
  for (const t of tablesArr) {
    if (!t || typeof t !== "object") continue;
    const cols = Array.isArray(t.columns) ? t.columns : null;
    const rows = Array.isArray(t.rows) ? t.rows : null;
    if (!cols || !rows || rows.length === 0) continue;

    // Locate month columns by exact match (Jan..Dec)
    const monthIdx = {};
    for (let i = 0; i < cols.length; i++) {
      const c = String(cols[i] ?? "");
      if (monthOrder.includes(c)) monthIdx[c] = i;
    }

    const monthColsPresent = monthOrder.filter(m => monthIdx[m] != null);
    if (monthColsPresent.length < 3) continue; // needs time-series

    // Guess entity column: first non-month column with mostly stringish values
    let entityColIdx = null;
    for (let i = 0; i < cols.length; i++) {
      const c = String(cols[i] ?? "");
      if (monthOrder.includes(c)) continue;
      // check first few rows
      let ok = 0, seen = 0;
      for (let r = 0; r < Math.min(rows.length, 10); r++) {
        const v = rows[r] && rows[r][i];
        if (v == null) continue;
        seen++;
        if (isStrish(v) && num(v) == null) ok++;
      }
      if (seen >= 3 && ok / seen >= 0.6) { entityColIdx = i; break; }
    }
    if (entityColIdx == null) continue;

    // Optional risk output cols
    const empIdx = cols.indexOf("Empirical_Risk_Pct");
    const zIdx = cols.indexOf("Normal_Z_Score");

    // If the table doesn't even have risk columns, we still might want to fix extras,
    // but we only repair table values when those cols exist.
    const repairTableRisk = (empIdx !== -1 || zIdx !== -1);

    // We'll also populate extras.mom_growth + extras.risk_analysis for transparency
    ex.mom_growth ||= {};
    ex.risk_analysis ||= {};

    for (const row of rows) {
      if (!Array.isArray(row)) continue;
      const entity = String(row[entityColIdx] ?? "");
      if (!entity) continue;

      // Extract monthly totals in chronological order, treat null/NaN as null
      const totals = monthColsPresent.map(m => num(row[monthIdx[m]]));

      // Compute canonical growth: (cur - prev)/abs(prev), null if prev null/0 or cur null
      const growth = [];
      for (let i = 1; i < totals.length; i++) {
        const prev = totals[i-1];
        const cur = totals[i];
        if (prev == null || cur == null || prev === 0) { growth.push(null); continue; }
        growth.push((cur - prev) / Math.abs(prev));
      }

      const valid = growth.map(num).filter(x => x != null);

      // Empirical
      let empirical = null, dropCount = null;
      if (valid.length > 0) {
        let cnt = 0;
        for (const g of valid) if (g < threshold) cnt++;
        dropCount = cnt;
        empirical = cnt / valid.length;
      }

      // Normal z-score
      const ms = meanSd(valid);
      let z = null;
      if (ms.n >= 2 && ms.sd != null) {
        z = (threshold - ms.mean) / ms.sd;
      }

      // Write back into table if columns exist
      if (repairTableRisk) {
        if (empIdx !== -1) row[empIdx] = (empirical != null) ? empirical : 0; // 0 or null, your preference
        if (zIdx !== -1) row[zIdx] = (z != null && Number.isFinite(z)) ? z : null;
      }

      // Update extras (authoritative)
      ex.mom_growth[entity] = [null].concat(growth); // align like your existing pattern
      ex.risk_analysis[entity] = {
        empirical: (empirical != null) ? empirical : null,
        zScore: (z != null && Number.isFinite(z)) ? z : null,
        mean: (ms.mean != null) ? ms.mean : null,
        stddev: (ms.sd != null) ? ms.sd : null,
        nTransitions: valid.length,
        dropCount: (dropCount != null) ? dropCount : 0,
        threshold
      };
    }
  }
}


// FIX: Ensure extras.risk_probability exists + degrade truthfully without fabrication
function ensureRiskProbability(out) { // FIX:
  if (!out || typeof out !== "object") return;
  out.extras ||= {};

  const prior = (out.extras.risk_probability && typeof out.extras.risk_probability === "object") ? out.extras.risk_probability : {};
  const hd = (out.extras.historical_drops && typeof out.extras.historical_drops === "object") ? out.extras.historical_drops : null;

  const vectors = _extractBaselineVectors(out);

  const reasons = [];

  const threshold = safeNumber(
    prior.threshold ??
    out.extras.risk_threshold ??
    (hd ? (hd.threshold ?? hd.dropThreshold) : null)
  );

    const priorWasPresent = !!(out.extras.risk_probability && typeof out.extras.risk_probability === "object");
  const hdWasPresent = !!(hd && typeof hd === "object");
  const baselineFound = !!(vectors && Array.isArray(vectors.monthlyValues) && vectors.monthlyValues.length > 0);

  const mv = (out.metaVectors && typeof out.metaVectors === "object") ? out.metaVectors : null;
  const metaHasBaseline = !!(mv && Array.isArray(mv.baselineTotals) && mv.baselineTotals.length > 0);

  // No signal that risk was requested, do not inject noise
  if (!priorWasPresent && !hdWasPresent && threshold == null && !baselineFound && !metaHasBaseline) {
    return;
  }

  // If a worthless stub exists, remove it instead of poisoning outputs
  if (priorWasPresent && threshold == null && !baselineFound && !metaHasBaseline) {
    const p = out.extras.risk_probability;
    const worthless =
      p &&
      safeNumber(p.threshold) == null &&
      safeInt(p.nTransitions) === 0 &&
      safeInt(p.nMonths) == null &&
      safeInt(p.nObservations) == null;

    if (worthless) {
      try { delete out.extras.risk_probability; } catch (_) {}
    }
    return;
  }


  if (threshold == null) reasons.push("Threshold is missing or non-finite.");

  // FIX: wire to canonical baseline vectors used by tables/series
  let nMonths = vectors.nMonths;
  let nTransitions = vectors.nTransitions;

  // fallback only if baseline vectors missing
  if (nMonths == null) {
    const pn = safeInt(prior.nMonths ?? prior.nObservations);
    if (pn != null) nMonths = pn;
  }
  if (nTransitions == null) {
    const pt = safeInt(prior.nTransitions);
    if (pt != null) nTransitions = pt;
  }

  if (nMonths == null) reasons.push("Baseline monthly series not found; nMonths unavailable.");
  else if (nMonths === 0) reasons.push("No finite monthly observations available.");

  if (nTransitions == null) reasons.push("Baseline Growth_Pct transitions not found; nTransitions unavailable.");
  else if (nTransitions === 0) reasons.push("No valid transitions available.");

  // Empirical count/frequency (drop risk) computed from Growth_Pct transitions
  let historicalCount = safeInt(
    prior.historicalCount ??
    (hd ? (hd.count ?? hd.historicalCount ?? hd.dropsCount) : null)
  );

  let historicalFrequency = safeNumber(
    prior.historicalFrequency ??
    (hd ? hd.frequency : null)
  );

  if (historicalCount == null && threshold != null && gv.length > 0) {
  let cnt = 0;
  for (const g of gv) if (g < threshold) cnt++;
  historicalCount = safeInt(cnt);
}


  if (historicalFrequency == null && historicalCount != null && nTransitions != null && nTransitions > 0) {
    historicalFrequency = safeNumber(historicalCount / nTransitions);
  }

  if (historicalCount == null) reasons.push("Historical drop count not computable from available data.");
  if (historicalFrequency == null) {
    if (nTransitions != null && nTransitions > 0) reasons.push("Historical frequency not computable from available data.");
    else reasons.push("Empirical frequency requires at least one valid transition.");
  }

  // z-score + normal approximation proxy (optional), computed from Growth_Pct transitions when possible
  let zScoreToThreshold = null;
  let normalApproxProbability = null;
  let note = "Proxy probabilities are computed only when prerequisites are met.";

const gv = asArrayLike(vectors.growthValues).map(safeNumber).filter(v => v != null);
const xs = gv;

  if (threshold != null) {
    if (xs.length >= 2) {
      const n = xs.length;
      const mean = xs.reduce((a, b) => a + b, 0) / n;

      let sse = 0;
      for (const x of xs) {
        const dx = x - mean;
        sse += dx * dx;
      }

      const variance = sse / (n - 1);
      const sd = Math.sqrt(variance);

      if (sd > 0 && Number.isFinite(sd)) {
        const z = safeNumber((threshold - mean) / sd);
        zScoreToThreshold = z;

        if (z != null) {
          const p = _normalCdf(z);
          normalApproxProbability = safeNumber(p);
          if (normalApproxProbability == null) reasons.push("Normal CDF returned non-finite.");
        } else {
          reasons.push("z-score became non-finite.");
        }
      } else {
        reasons.push("Stddev is zero/non-finite; z-score/normal approximation not computable.");
      }
    } else if (xs.length > 0) {
      reasons.push("Need at least 2 transition observations for z-score/normal approximation.");
    } else {
      reasons.push("No finite transition observations for z-score/normal approximation.");
    }
  }

  const hasEmpirical = safeNumber(historicalFrequency) != null;
  const hasZ = safeNumber(zScoreToThreshold) != null;
  const hasNormal = safeNumber(normalApproxProbability) != null;

  const modeChosen = hasEmpirical
    ? "empirical_frequency"
    : (hasNormal ? "normal_approx" : (hasZ ? "z_score_only" : null));

  const rp = Object.assign({}, prior, {
    modeChosen: modeChosen ?? null,
    threshold: safeNumber(threshold),
    nMonths: safeInt(nMonths),
    nTransitions: safeInt(nTransitions),
    historicalCount: safeInt(historicalCount),
    historicalFrequency: safeNumber(historicalFrequency),
    zScoreToThreshold: safeNumber(zScoreToThreshold),
    normalApproxProbability: safeNumber(normalApproxProbability),
    reasons: Array.from(new Set((Array.isArray(reasons) ? reasons : []).filter(Boolean).map(s => String(s)))),
    note: String(note || "")
  });

  // Back-compat fields (do not remove)
  rp.nObservations = safeInt(prior.nObservations ?? rp.nMonths);

  // Final numeric safety
  rp.threshold = safeNumber(rp.threshold);
  rp.nMonths = safeInt(rp.nMonths);
  rp.nTransitions = safeInt(rp.nTransitions);
  rp.historicalCount = safeInt(rp.historicalCount);
  rp.historicalFrequency = safeNumber(rp.historicalFrequency);
  rp.zScoreToThreshold = safeNumber(rp.zScoreToThreshold);
  rp.normalApproxProbability = safeNumber(rp.normalApproxProbability);

  // P4: recompute truthfully from canonical baseline vectors (metaVectors)
  const metaVectors = (out.metaVectors && typeof out.metaVectors === "object") ? out.metaVectors : null;
  const baselineTotals = (metaVectors && Array.isArray(metaVectors.baselineTotals)) ? metaVectors.baselineTotals : null;
  const baselineGrowth = (metaVectors && metaVectors.baselineGrowth != null) ? metaVectors.baselineGrowth : null;
  const bg = asArrayLike(baselineGrowth).map(safeNumber).filter(v => v != null);


  const hasVectors = !!(baselineTotals && baselineTotals.length > 0);
  const nMonthsMV = hasVectors ? safeInt(baselineTotals.length) : null;
  const nTransitionsMV = safeInt(bg.length);


  // Never claim "baseline not found" if vectors exist
  if (hasVectors && Array.isArray(reasons)) {
    const cleaned = reasons
      .filter(r => typeof r === "string")
      .filter(r => !/Baseline monthly series not found/i.test(r))
      .filter(r => !/Baseline Growth_Pct transitions not found/i.test(r));
    reasons.length = 0;
    for (const r of cleaned) reasons.push(r);
  }

  // historicalFrequency: count / nTransitions (0 allowed)
  let historicalCount2 = safeInt(historicalCount);
  if (threshold != null && baselineGrowth && baselineGrowth.length) {
    let cnt = 0;
    for (const gRaw of bg) {
      const g = safeNumber(gRaw);
      if (g != null && g < threshold) cnt++;
    }
    historicalCount2 = cnt;
  }

  let historicalFrequency2 = null;
  if (nTransitionsMV != null && nTransitionsMV > 0) {
    historicalFrequency2 = safeNumber((historicalCount2 ?? 0) / nTransitionsMV);
  } else if (nTransitions != null && nTransitions > 0) {
    historicalFrequency2 = safeNumber((historicalCount2 ?? 0) / nTransitions);
  } else {
    historicalFrequency2 = (historicalFrequency != null) ? safeNumber(historicalFrequency) : null;
  }

  // zScoreToThreshold + normalApproxProbability only if n>=2 and stddev>0
  let z2 = null;
  let p2 = null;
  if (threshold != null && baselineGrowth && baselineGrowth.length) {
    const xs = bg;
    if (xs.length >= 2) {
      const mean = xs.reduce((a, b) => a + b, 0) / xs.length;
      const variance = xs.reduce((a, b) => a + Math.pow(b - mean, 2), 0) / (xs.length - 1);
      const sd = Math.sqrt(variance);

      if (Number.isFinite(sd) && sd > 0) {
        z2 = safeNumber((threshold - mean) / sd);
        if (z2 != null) p2 = safeNumber(_normalCdf(z2));
      }
    }
  }

  rp.nMonths = (nMonthsMV != null) ? safeInt(nMonthsMV) : safeInt(rp.nMonths);
  rp.nTransitions = (nTransitionsMV != null) ? safeInt(nTransitionsMV) : safeInt(rp.nTransitions);

  rp.historicalCount = safeInt(historicalCount2);
  rp.historicalFrequency = safeNumber(historicalFrequency2);

  rp.zScoreToThreshold = (z2 != null) ? safeNumber(z2) : safeNumber(rp.zScoreToThreshold);
  rp.normalApproxProbability = (p2 != null) ? safeNumber(p2) : safeNumber(rp.normalApproxProbability);

  // ensure reasons exist if nothing computable
  const hasAnyMetric =
    (rp.historicalFrequency != null) ||
    (rp.zScoreToThreshold != null) ||
    (rp.normalApproxProbability != null);

  if (!hasAnyMetric && Array.isArray(reasons) && reasons.length === 0) {
    reasons.push("No computable risk metrics from canonical baseline vectors.");
  }

  rp.reasons = Array.from(new Set((Array.isArray(reasons) ? reasons : []).filter(Boolean).map(s => String(s))));

  out.extras.risk_probability = rp;

}

// =============================================
// UNIVERSAL FOREVER FIX: Correlation Driver Tables + correlationBlocks labeling
// - Repairs driver tables that have columns like:
//   Target_Metric, Material_Field, Correlation_Score, Significance
// - If Material_Field is missing/blank, it rebuilds drivers from rawData
// - Also upgrades diagnostics.correlationBlocks to include xField
// - Dataset agnostic: learns candidate fields by patterns + numeric screening
// =============================================

function ensureTailLiftImpact(out) {
  try {
    if (!out || typeof out !== "object") return;

    const extras = out.extras && typeof out.extras === "object" ? out.extras : null;
    const methodOutputs = out.methodOutputs && typeof out.methodOutputs === "object" ? out.methodOutputs : null;
    if (!extras && !methodOutputs) return;

    // Prefer existing analytics-produced vector(s)
    const source =
      (extras && (extras.metric_vector || extras.primary_metric)) ||
      (methodOutputs && methodOutputs.metric_vector);

    if (!Array.isArray(source) || source.length < 20) return;

    const safe = _.safeKeyFn ? _.safeKeyFn : (k) => k;

    const values = [];
    const weights = [];

    let nTotal = 0;
    let nValid = 0;

    for (const row of source) {
      nTotal++;
      if (row == null) continue;

      if (typeof row === "number") {
        if (Number.isFinite(row)) {
          values.push(row);
          weights.push(1);
          nValid++;
        }
        continue;
      }

      if (typeof row === "object") {
        const v = _.stats.toNumber(row[safe("value")]);
        const w = _.stats.toNumber(row[safe("weight")] ?? 1);
        if (Number.isFinite(v) && Number.isFinite(w) && w > 0) {
          values.push(v);
          weights.push(w);
          nValid++;
        }
      }
    }

    const coverage = nTotal > 0 ? nValid / nTotal : 0;
    if (values.length < 20) return;

    // Unweighted quantiles (keeps "worst 10% of records" semantics)
    const median = _.stats.percentile(values, 50);
    const q90 = _.stats.percentile(values, 90);
    const q10 = _.stats.percentile(values, 10);


    if (!Number.isFinite(median) || !Number.isFinite(q90) || !Number.isFinite(q10)) return;

    // Upper tail: values >= q90 lifted DOWN to median (when "higher is worse")
    let upperAggregateDelta = 0;
    let upperAffected = 0;
    let upperWeight = 0;

    // Lower tail: values <= q10 lifted UP to median (when "lower is worse")
    let lowerAggregateDelta = 0;
    let lowerAffected = 0;
    let lowerWeight = 0;

    for (let i = 0; i < values.length; i++) {
      const v = values[i];
      const w = weights[i];

      if (v >= q90) {
        const delta = v - median;
        if (delta > 0) {
          upperAggregateDelta += delta * w;
          upperAffected++;
          upperWeight += w;
        }
      }

      if (v <= q10) {
        const delta = median - v;
        if (delta > 0) {
          lowerAggregateDelta += delta * w;
          lowerAffected++;
          lowerWeight += w;
        }
      }
    }

    // Write results
    out.extras = extras || {};
    out.extras.tail_lift_impact = {
      reference_stat: median,
      upper_tail: {
        threshold_stat: q90,
        affected_count: upperAffected,
        affected_weight_sum: upperWeight,
        aggregate_delta: upperAggregateDelta,
        normalization: "upper-tail-lift-to-median"
      },
      lower_tail: {
        threshold_stat: q10,
        affected_count: lowerAffected,
        affected_weight_sum: lowerWeight,
        aggregate_delta: lowerAggregateDelta,
        normalization: "lower-tail-lift-to-median"
      },
      vector_coverage: { nTotal, nValid, coverage },
      unit: "native",
      _universal: true
    };

    // Diagnostics: avoid duplicates
    out.diagnostics = out.diagnostics && typeof out.diagnostics === "object" ? out.diagnostics : {};
    out.diagnostics.notes = Array.isArray(out.diagnostics.notes) ? out.diagnostics.notes : [];

    const note = "Computed universal tail-lift impact from existing metric distribution (direction-agnostic, no domain assumptions).";
    if (!out.diagnostics.notes.includes(note)) out.diagnostics.notes.push(note);
  } catch (_) {}
}




function ensureCorrelationDriverTablesDeep(out, rawData) {
  if (!out || typeof out !== "object") return;
  if (!rawData) return;

  const toNum = (v) => {
    const n = (typeof v === "number") ? v : (v == null ? NaN : Number(v));
    return Number.isFinite(n) ? n : null;
  };

  const isObj = (x) => x && typeof x === "object" && !Array.isArray(x);

  // ---- normalize tables container ----
  const tablesContainer = out.tables;
  if (!tablesContainer) return;

  // Get raw rows
  const rows = Array.isArray(rawData)
    ? rawData.filter(isObj)
    : (rawData && typeof rawData === "object"
        ? Object.values(rawData).flat().filter(isObj)
        : []);
  if (rows.length < 5) return;

  // ---- discover numeric fields ----
  const allKeys = Object.keys(rows[0] || {});
  const numericRate = (key, sampleN = 200) => {
    let seen = 0, good = 0;
    const step = Math.max(1, Math.floor(rows.length / sampleN));
    for (let i = 0; i < rows.length; i += step) {
      const r = rows[i];
      if (!r) continue;
      seen++;
      const n = toNum(r[key]);
      if (n != null) good++;
      if (seen >= sampleN) break;
    }
    return seen ? (good / seen) : 0;
  };

  const numericKeys = allKeys
    .map(k => ({ k, rate: numericRate(k) }))
    .filter(x => x.rate >= 0.7)
    .map(x => x.k);

  if (numericKeys.length < 3) return;

  // ---- classify candidate X inputs and Y targets ----
  const isInputLike = (k) =>
    /(^|_| )used($|_| )|_kg$|material|input|raw|consum|acid|stpp|enzyme|packag|caustic|soda|silicate|fragrance|colorant|water/i.test(k);

  const isTargetLike = (k) =>
    /defect|waste|efficien|yield|cost|loss|scrap|reject|downtime/i.test(k);

  const xCandidates = numericKeys.filter(isInputLike);
  const yCandidates = numericKeys.filter(isTargetLike);

  if (xCandidates.length < 2 || yCandidates.length < 1) return;

  // ---- compute pearson with strict pair filtering ----
  const pearson = (xArr, yArr) => {
    let xs = [], ys = [];
    for (let i = 0; i < xArr.length; i++) {
      const x = xArr[i], y = yArr[i];
      if (x == null || y == null) continue;
      xs.push(x);
      ys.push(y);
    }
    const n = xs.length;
    if (n < 2) return { r: null, n: 0 };

    let mx = 0, my = 0;
    for (let i = 0; i < n; i++) { mx += xs[i]; my += ys[i]; }
    mx /= n; my /= n;

    let num = 0, dx2 = 0, dy2 = 0;
    for (let i = 0; i < n; i++) {
      const dx = xs[i] - mx;
      const dy = ys[i] - my;
      num += dx * dy;
      dx2 += dx * dx;
      dy2 += dy * dy;
    }
    const den = Math.sqrt(dx2 * dy2);
    if (!den) return { r: null, n };

    return { r: num / den, n };
  };

  const strengthLabel = (absR) => {
    if (!Number.isFinite(absR)) return "Low";
    if (absR >= 0.15) return "High";
    if (absR >= 0.05) return "Medium";
    return "Low";
  };

  // Pre-extract vectors for speed
  const vec = {};
  for (const k of [...xCandidates, ...yCandidates]) {
    const sk = (_.safeKeyFn ? _.safeKeyFn(k) : k);
    vec[k] = rows.map(r => {
      const n = _.stats.toNumber(r ? r[sk] : null);
      return _.stats.isFinite(n) ? n : null;
    });
  }

  // Build top drivers for each target
  const rebuilt = [];
  const diagBlocks = [];

  for (const y of yCandidates.slice(0, 3)) {
    const scored = [];
    
    for (const x of xCandidates) {
      if (x === y) continue;
      const res = pearson(vec[x], vec[y]);
      if (res.r == null) continue;
      
      // Score and store
      scored.push({
        Target_Metric: y,
        Material_Field: x,
        Correlation_Score: res.r,
        Strength: strengthLabel(Math.abs(res.r)),
        __n: res.n
      });

      // Diagnostics block
      const nTotal = rows.length;
      const nValidPairs = res.n;
      const coverage = nTotal > 0 ? (nValidPairs / nTotal) : 0;
      const okPairs = (nValidPairs >= 30) && (coverage >= 0.6);

      diagBlocks.push({
        yField: y,
        xField: x,
        method: "pearson",
        nValidPairs: nValidPairs,
        nTotal: nTotal,
        coverage: coverage,
        status: okPairs ? "ok" : "downgraded",
        value: okPairs ? res.r : null
      });
    }

    // CORRECTED LOGIC: Sort outside the X loop
    scored.sort((a, b) => Math.abs(b.Correlation_Score) - Math.abs(a.Correlation_Score));
    rebuilt.push(...scored.slice(0, 3));
  }

  if (!rebuilt.length) return;

  // ---- helper: repair tables ----
  const maybeRepairTable = (tbl) => {
    if (!tbl || typeof tbl !== "object") return false;
    const cols = Array.isArray(tbl.columns) ? tbl.columns : null;
    const rowsAny = tbl.rows;

    if (!cols) return false;
    const hasTarget = cols.includes("Target_Metric");
    const hasCorr = cols.includes("Correlation_Score");
    const hasMaterial = cols.includes("Material_Field");
    if (!(hasTarget && hasCorr && hasMaterial)) return false;

    // Check if Material_Field is mostly empty
    let empty = 0, total = 0;
    if (Array.isArray(rowsAny)) {
      for (const r of rowsAny) {
        if (!r) continue;
        total++;
        const v = (typeof r === "object" && !Array.isArray(r)) ? r.Material_Field : null;
        if (v == null || String(v).trim() === "") empty++;
      }
    }

    if (!total) return false;
    if (empty / total < 0.5) return false;

    tbl.columns = ["Target_Metric", "Material_Field", "Correlation_Score", "Strength"];
    tbl.rows = rebuilt.map(x => ({
      Target_Metric: x.Target_Metric,
      Material_Field: x.Material_Field,
      Correlation_Score: x.Correlation_Score,
      Strength: x.Strength
    }));
    return true;
  };

  if (Array.isArray(tablesContainer)) {
    for (const t of tablesContainer) maybeRepairTable(t);
  } else if (isObj(tablesContainer)) {
    for (const k of Object.keys(tablesContainer)) {
      maybeRepairTable(tablesContainer[k]);
    }
  }

  // Upgrade diagnostics
  if (!out.diagnostics || typeof out.diagnostics !== "object") out.diagnostics = {};
  out.diagnostics.correlationBlocks = diagBlocks;
}


// =============================================
// UNIVERSAL: ensureRepRiskAnalysis
// - Does NOT depend on extras.mom_growth / extras.risk_analysis
// - Learns growth + entity keys by inspecting series.monthly_trends
// - Repairs risk outputs ONLY if they already exist (tables or extras)
// - Uses ONLY valid transitions (null growth excluded)
// =============================================
function ensureRiskAnalysisDeep(out) {
  if (!out || typeof out !== "object") return;

  const series = (out.series && typeof out.series === "object") ? out.series : null;
  if (!series) return;

  const monthly = Array.isArray(series.monthly_trends) ? series.monthly_trends : null;
  if (!monthly || monthly.length === 0) return;

  const isObj = (x) => x && typeof x === "object" && !Array.isArray(x);
  const num = (v) => {
    const n = (typeof v === "number") ? v : (v == null ? NaN : Number(v));
    return Number.isFinite(n) ? n : null;
  };
  const uniq = (arr) => Array.from(new Set(arr));

  const first = monthly.find(isObj);
  if (!first) return;

  const keys = Object.keys(first);

  // 1) Discover growth column (rate-like numeric, usually small magnitude, with some nulling)
  const candidateScores = new Map();
  for (const k of keys) {
    let nNum = 0, nNull = 0, withinRateBand = 0, largeMag = 0;
    for (const r of monthly) {
      if (!isObj(r)) continue;
      const raw = r[k];
      if (raw == null) { nNull++; continue; }
      const v = num(raw);
      if (v == null) continue;
      nNum++;
      if (Math.abs(v) <= 5) withinRateBand++;
      if (Math.abs(v) >= 1000) largeMag++;
    }
    if (nNum < 2) continue;
    const score =
      (withinRateBand / nNum) * 3 +
      (nNull / (monthly.length || 1)) * 1.5 -
      (largeMag / nNum) * 3;
    candidateScores.set(k, score);
  }

  let growthKey = null;
  let bestScore = -Infinity;
  for (const [k, sc] of candidateScores.entries()) {
    if (sc > bestScore) { bestScore = sc; growthKey = k; }
  }
  if (!growthKey) return;

  // 2) Discover entity key (rep/product/etc) if present
  const tryEntityKey = () => {
    const cands = [];
    for (const k of keys) {
      if (k === growthKey) continue;
      const vals = [];
      let numericish = 0;
      for (const r of monthly) {
        if (!isObj(r)) continue;
        const v = r[k];
        if (v == null) continue;
        if (num(v) != null) numericish++;
        vals.push(String(v));
      }
      if (vals.length < 3) continue;
      const u = uniq(vals);
      if (!(u.length < vals.length)) continue;            // must repeat
      if (numericish / (vals.length || 1) > 0.5) continue; // avoid numeric IDs
      const uniquenessRatio = u.length / vals.length;
      const score = (uniquenessRatio > 0.05 && uniquenessRatio < 0.7) ? 2 : 0.5;
      cands.push({ k, score });
    }
    cands.sort((a,b)=>b.score-a.score);
    return cands.length ? cands[0].k : null;
  };
  const entityKey = tryEntityKey(); // may be null

  // 3) Determine threshold
  out.extras ||= {};
  const ex = out.extras;
  const rp = (ex.risk_probability && typeof ex.risk_probability === "object") ? ex.risk_probability : null;
  let threshold = rp ? num(rp.threshold) : null;

  // Default threshold ONLY if we are actually repairing a risk output
  const tables = (out.tables && typeof out.tables === "object") ? out.tables : null;
  const hasRiskTable = !!(tables && Array.isArray(tables.risk_assessment) && tables.risk_assessment.length);
  const hasExtrasRiskArray = !!(ex && Array.isArray(ex.risk_analysis) && ex.risk_analysis.length);

  if (threshold == null && (hasRiskTable || hasExtrasRiskArray)) threshold = -0.2;

  // 4) Build valid growth vectors per entity (ONLY non-null, finite)
  const groupKeyForRow = (row) => {
    if (!entityKey) return "__single__";
    const v = row[entityKey];
    return (v == null || v === "") ? "__missing_entity__" : String(v);
  };

  const byEntity = new Map();
  for (const r of monthly) {
    if (!isObj(r)) continue;
    const g = num(r[growthKey]);
    if (g == null) continue; // ONLY valid transitions
    const e = groupKeyForRow(r);
    if (!byEntity.has(e)) byEntity.set(e, []);
    byEntity.get(e).push(g);
  }

  const meanSd = (vals) => {
    const v = (vals || []).map(num).filter(x => x != null);
    const n = v.length;
    if (!n) return { n: 0, mean: null, sd: null };
    const mean = v.reduce((a,b)=>a+b,0)/n;
    if (n < 2) return { n, mean, sd: null };
    let sse = 0;
    for (const x of v) { const d = x-mean; sse += d*d; }
    const sd = Math.sqrt(sse/(n-1));
    return { n, mean, sd: (Number.isFinite(sd) && sd > 0) ? sd : null };
  };

  const computeMetrics = (vals) => {
    const ms = meanSd(vals);
    const n = ms.n;
    let emp = null, drops = null, z = null;
    if (threshold != null && n > 0) {
      let cnt = 0;
      for (const x of vals) if (x < threshold) cnt++;
      drops = cnt;
      emp = cnt / n;
    }
    if (threshold != null && ms.sd != null) {
      z = (threshold - ms.mean) / ms.sd;
    }
    return { n, mean: ms.mean, sd: ms.sd, empiricalProb: emp, dropCount: drops, z };
  };

  // 5) Repair tables.risk_assessment if present (universal key inference)
  if (hasRiskTable) {
    const ra = tables.risk_assessment;
    const r0 = ra.find(isObj) || {};
    const rKeys = Object.keys(r0);

    const entityCol =
      rKeys.find(k => /sales rep|rep|agent|district|product|entity/i.test(k)) ||
      rKeys.find(k => k.toLowerCase() === (entityKey || "").toLowerCase()) ||
      null;

    const empCol = rKeys.find(k => /empirical.*prob|historical.*freq|drop.*prob/i.test(k)) || null;
    const nCol = rKeys.find(k => /n.*trans|transitions|count.*trans/i.test(k)) || null;
    const dropCol = rKeys.find(k => /drop.*count|count.*drop|drops/i.test(k)) || null;
    const zCol = rKeys.find(k => /z.*score|normal.*z/i.test(k)) || null;

    if (entityCol && (empCol || nCol || dropCol || zCol)) {
      for (const row of ra) {
        if (!isObj(row)) continue;
        const e = row[entityCol] == null ? "__single__" : String(row[entityCol]);
        const vals = byEntity.get(e) || [];
        if (!vals.length) {
          // no valid transitions
          if (empCol) row[empCol] = null;
          if (zCol) row[zCol] = null;
          if (nCol) row[nCol] = 0;
          if (dropCol) row[dropCol] = 0;
          continue;
        }
        const m = computeMetrics(vals);
        if (empCol) row[empCol] = (m.empiricalProb != null) ? m.empiricalProb : null;
        if (zCol) row[zCol] = (m.z != null && Number.isFinite(m.z)) ? m.z : null;
        if (nCol) row[nCol] = m.n;
        if (dropCol) row[dropCol] = (m.dropCount != null) ? m.dropCount : 0;
      }
    }
  }

  // 6) Repair extras.risk_analysis if present (also universal, minimal assumptions)
  if (hasExtrasRiskArray) {
    const ra = ex.risk_analysis;
    const r0 = ra.find(isObj) || {};
    const rKeys = Object.keys(r0);

    const entityCol =
      ("rep" in r0) ? "rep" :
      rKeys.find(k => /sales rep|rep|agent|district|product|entity/i.test(k)) ||
      null;

    // common metric keys in extras
    const meanKey = rKeys.find(k => /mean.*growth|meangrowth/i.test(k)) || null;
    const sdKey = rKeys.find(k => /std|sd|stdev/i.test(k)) || null;
    const empKey = rKeys.find(k => /empirical.*prob/i.test(k)) || null;
    const zKey = rKeys.find(k => /z.*negative|z.*score/i.test(k)) || null;
    const nKey = rKeys.find(k => /n.*trans|transitions/i.test(k)) || null;

    if (entityCol) {
      for (const row of ra) {
        if (!isObj(row)) continue;
        const e = row[entityCol] == null ? "__single__" : String(row[entityCol]);
        const vals = byEntity.get(e) || [];
        if (!vals.length) {
          if (empKey) row[empKey] = null;
          if (zKey) row[zKey] = null;
          if (nKey) row[nKey] = 0;
          continue;
        }
        const m = computeMetrics(vals);
        if (meanKey) row[meanKey] = (m.mean != null) ? m.mean : row[meanKey];
        if (sdKey) row[sdKey] = (m.sd != null) ? m.sd : row[sdKey];
        if (empKey) row[empKey] = (m.empiricalProb != null) ? m.empiricalProb : null;
        if (zKey) row[zKey] = (m.z != null && Number.isFinite(m.z)) ? m.z : null;
        if (nKey) row[nKey] = m.n;
      }
    }
  }

  // 7) Degrade global risk_probability if multi-entity baseline ambiguous
  if (rp) {
    const entities = Array.from(byEntity.keys()).filter(k => k !== "__single__");
    if (entities.length > 1) {
      rp.reasons = Array.isArray(rp.reasons) ? rp.reasons : [];
      rp.reasons.push("Degraded: multi-entity output makes a single global baseline ambiguous.");
      rp.reasons = Array.from(new Set(rp.reasons.map(s => String(s))));
    }
  }
}

// =============================================
// UNIVERSAL: entity correlations from table-shaped outputs
// Works when out.tables is an ARRAY of {name, columns, rows}.
// Finds tables with:
// - one entity column (string-like)
// - >= 3 time columns (Jan..Dec OR any numeric columns if months absent)
// Computes pairwise Pearson correlations using overlap months only.
// Writes to out.extras.rep_correlations (kept name for compatibility).
// =============================================
function ensureEntityCorrelationsFromTablesDeep(out) {
  if (!out || typeof out !== "object") return;

  const tablesArr = Array.isArray(out.tables) ? out.tables : null;
  if (!tablesArr || tablesArr.length === 0) return;

  out.extras ||= {};
  const ex = out.extras;

  const num = (v) => {
    const n = (typeof v === "number") ? v : (v == null ? NaN : Number(v));
    return Number.isFinite(n) ? n : null;
  };
  const isObj = (x) => x && typeof x === "object" && !Array.isArray(x);
  const isStrish = (v) => typeof v === "string" || (v != null && typeof v !== "object");

  const monthOrder = ["Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"];

  // Pearson correlation using only paired finite observations
  const pearson = (xs, ys) => {
    const pairs = [];
    for (let i = 0; i < Math.min(xs.length, ys.length); i++) {
      const a = num(xs[i]);
      const b = num(ys[i]);
      if (a == null || b == null) continue;
      pairs.push([a, b]);
    }
    const n = pairs.length;
    if (n < 2) return null;

    let sx = 0, sy = 0;
    for (const [a,b] of pairs) { sx += a; sy += b; }
    const mx = sx / n, my = sy / n;

    let sxx = 0, syy = 0, sxy = 0;
    for (const [a,b] of pairs) {
      const dx = a - mx;
      const dy = b - my;
      sxx += dx * dx;
      syy += dy * dy;
      sxy += dx * dy;
    }
    if (sxx <= 0 || syy <= 0) return null;
    return sxy / Math.sqrt(sxx * syy);
  };

  // Choose best candidate table: prefer one with explicit Jan..Dec columns
  let best = null;
  for (const t of tablesArr) {
    if (!t || typeof t !== "object") continue;
    const cols = Array.isArray(t.columns) ? t.columns : null;
    const rows = Array.isArray(t.rows) ? t.rows : null;
    if (!cols || !rows || rows.length < 2) continue;

    // month columns
    const monthIdx = {};
    for (let i = 0; i < cols.length; i++) {
      const c = String(cols[i] ?? "");
      if (monthOrder.includes(c)) monthIdx[c] = i;
    }
    const monthCols = monthOrder.filter(m => monthIdx[m] != null);

    // guess entity col: first non-month col with mostly string-ish values
    let entityColIdx = null;
    for (let i = 0; i < cols.length; i++) {
      const c = String(cols[i] ?? "");
      if (monthOrder.includes(c)) continue;

      let ok = 0, seen = 0;
      for (let r = 0; r < Math.min(rows.length, 10); r++) {
        const v = rows[r] && rows[r][i];
        if (v == null) continue;
        seen++;
        if (isStrish(v) && num(v) == null) ok++;
      }
      if (seen >= 3 && ok / seen >= 0.6) { entityColIdx = i; break; }
    }
    if (entityColIdx == null) continue;

    // fallback time cols if no months: take numeric columns (excluding risk cols)
    const isRiskCol = (name) => /risk|z[_ ]?score|empirical/i.test(String(name || ""));
    let timeCols = monthCols.map(m => monthIdx[m]);

    if (timeCols.length < 3) {
      const numericCols = [];
      for (let i = 0; i < cols.length; i++) {
        if (i === entityColIdx) continue;
        if (isRiskCol(cols[i])) continue;
        // if at least 2 numeric values exist in this column, accept it
        let nNum = 0;
        for (let r = 0; r < Math.min(rows.length, 25); r++) {
          const v = rows[r] && rows[r][i];
          if (num(v) != null) nNum++;
          if (nNum >= 2) break;
        }
        if (nNum >= 2) numericCols.push(i);
      }
      timeCols = numericCols;
    }

    if (timeCols.length < 3) continue;

    // score: more time cols is better, explicit months even better
    const score = timeCols.length + (monthCols.length ? 5 : 0);

    if (!best || score > best.score) {
      best = { t, cols, rows, entityColIdx, timeCols, score };
    }
  }

  if (!best) return;

  const { rows, entityColIdx, timeCols } = best;

  // Build series per entity
  const labels = [];
  const seriesByLabel = new Map();

  for (const row of rows) {
    if (!Array.isArray(row)) continue;
    const label = String(row[entityColIdx] ?? "");
    if (!label) continue;

    const vec = timeCols.map(idx => num(row[idx])); // keep nulls; pearson uses overlap
    labels.push(label);
    seriesByLabel.set(label, vec);
  }

  // Deduplicate labels in case table repeats
  const seen = new Set();
  const uniqLabels = [];
  for (const l of labels) {
    if (seen.has(l)) continue;
    seen.add(l);
    uniqLabels.push(l);
  }

  // Compute matrix as nested object: matrix[a][b] = corr
  const matrix = {};
  for (const a of uniqLabels) {
    matrix[a] = {};
    const xs = seriesByLabel.get(a) || [];
    for (const b of uniqLabels) {
      const ys = seriesByLabel.get(b) || [];
      const r = pearson(xs, ys);
      matrix[a][b] = (r != null && Number.isFinite(r)) ? r : null;
    }
  }

  ex.rep_correlations = { matrix, labels: uniqLabels };
}


// ===============================
// P6: UNIVERSAL FOREVER SHIELD FOR GROWTH-DERIVED OUTPUTS
// - No hard-coded key names.
// - Learns keys by inspecting monthly_trends row structure.
// - Works for both single-series and multi-entity (rep/product/district/etc).
// - Rebuilds only if the target outputs already exist.
// ===============================
function ensureGrowthDerivedOutputsDeep(out) {
  if (!out || typeof out !== "object") return;

  const series = (out.series && typeof out.series === "object") ? out.series : null;
  const tables = (out.tables && typeof out.tables === "object") ? out.tables : null;
  if (!series) return;

  const monthly = Array.isArray(series.monthly_trends) ? series.monthly_trends : null;
  if (!monthly || monthly.length === 0) return;

  // ---- helpers (do NOT rely on external underscore libs) ----
  const isObj = (x) => x && typeof x === "object" && !Array.isArray(x);
  const num = (v) => {
    const n = (typeof v === "number") ? v : (v == null ? NaN : Number(v));
    return Number.isFinite(n) ? n : null;
  };
  const uniq = (arr) => Array.from(new Set(arr));
  const safeMeanSd = (vals) => {
    const v = (vals || []).map(num).filter(x => x != null);
    const n = v.length;
    if (!n) return { n: 0, mean: null, sd: null };
    const mean = v.reduce((a,b)=>a+b,0)/n;
    if (n < 2) return { n, mean, sd: null };
    let sse = 0;
    for (const x of v) { const d = x-mean; sse += d*d; }
    const sd = Math.sqrt(sse/(n-1));
    return { n, mean, sd: Number.isFinite(sd) ? sd : null };
  };

  // Pick a representative row
  const first = monthly.find(isObj);
  if (!first) return;

  const keys = Object.keys(first);

  // ---- 1) Discover the "growth" column universally ----
  // Strategy:
  // - Prefer a numeric column that looks like a rate (mostly between -5 and +5)
  // - Prefer columns where many rows are null (because nulling prev==0 is expected)
  // - Deprioritize obvious value/amount columns (high magnitude, mostly positive)
  const candidateScores = new Map();

  for (const k of keys) {
    let nNum = 0, nNull = 0, withinRateBand = 0, largeMag = 0;

    for (const r of monthly) {
      if (!isObj(r)) continue;
      const vRaw = r[k];
      if (vRaw == null) { nNull++; continue; }
      const v = num(vRaw);
      if (v == null) continue;
      nNum++;
      if (Math.abs(v) <= 5) withinRateBand++;
      if (Math.abs(v) >= 1000) largeMag++; // likely amount
    }

    if (nNum < 2) continue;

    // Score: rate-like + has some nulling - looks like amount
    const score =
      (withinRateBand / nNum) * 3 +
      (nNull / (monthly.length || 1)) * 1.5 -
      (largeMag / nNum) * 3;

    candidateScores.set(k, score);
  }

  // Best growth key
  let growthKey = null;
  let bestScore = -Infinity;
  for (const [k, sc] of candidateScores.entries()) {
    if (sc > bestScore) { bestScore = sc; growthKey = k; }
  }

  // If we can't discover a plausible growth column, exit safely.
  if (!growthKey) return;

  // ---- 2) Discover the "entity key" (rep/product/etc) if present ----
  // Strategy:
  // - Find a low-cardinality string-like column that repeats (not unique per row)
  // - Exclude the growthKey
  // - Exclude columns that look numeric (even if stored as string)
  const tryEntityKey = () => {
    const candidates = [];

    for (const k of keys) {
      if (k === growthKey) continue;

      const vals = [];
      let numericish = 0;

      for (const r of monthly) {
        if (!isObj(r)) continue;
        const v = r[k];
        if (v == null) continue;
        // numericish detector
        if (num(v) != null) numericish++;
        vals.push(String(v));
      }

      if (vals.length < 3) continue;
      const u = uniq(vals);
      // entity key should repeat: fewer uniques than rows (but not 1 necessarily)
      const repeats = (u.length < vals.length);
      if (!repeats) continue;

      // avoid keys that are mostly numeric
      if (numericish / (vals.length || 1) > 0.5) continue;

      // prefer moderate uniqueness (like reps) rather than near-unique IDs
      const uniquenessRatio = u.length / vals.length;

      // prefer keys where uniqueness isn't too high (IDs) or too low (constant)
      const score =
        (uniquenessRatio > 0.05 && uniquenessRatio < 0.7) ? 2 : 0.5;

      candidates.push({ k, score, uniquenessRatio, uniques: u.length, total: vals.length });
    }

    // Best scored candidate
    candidates.sort((a,b)=>b.score - a.score);
    return candidates.length ? candidates[0].k : null;
  };

  const entityKey = tryEntityKey(); // may be null for single-series

  // ---- 3) Determine "period ordering" key (optional) ----
  // If we can find a key that parses as dates or looks like month/period, use it.
  const parseTime = (x) => {
    const t = Date.parse(String(x));
    return Number.isFinite(t) ? t : null;
  };

  const tryPeriodKey = () => {
    const candidates = [];
    for (const k of keys) {
      if (k === growthKey) continue;
      if (k === entityKey) continue;

      let goodDates = 0, seen = 0;
      for (const r of monthly) {
        if (!isObj(r)) continue;
        const v = r[k];
        if (v == null) continue;
        seen++;
        if (parseTime(v) != null) goodDates++;
      }
      if (seen >= 3 && goodDates >= 2) candidates.push({ k, score: goodDates / seen });
    }
    candidates.sort((a,b)=>b.score-a.score);
    return candidates.length ? candidates[0].k : null;
  };

  const periodKey = tryPeriodKey(); // ok if null

  // ---- 4) Build entity -> ordered growth vector using ONLY monthly_trends[growthKey] ----
  const groupKeyForRow = (row) => {
    if (!entityKey) return "__single__";
    const v = row[entityKey];
    return (v == null || v === "") ? "__missing_entity__" : String(v);
  };

  const grouped = new Map();
  for (const r of monthly) {
    if (!isObj(r)) continue;
    const g = num(r[growthKey]);
    const grp = groupKeyForRow(r);
    const p = (periodKey ? r[periodKey] : null);

    if (!grouped.has(grp)) grouped.set(grp, []);
    grouped.get(grp).push({ g, p, raw: r });
  }

  // Order each group if we have a periodKey with parseable dates
  if (periodKey) {
    for (const [grp, arr] of grouped.entries()) {
      const times = arr.map(x => x.p).map(parseTime).filter(t => t != null);
      if (times.length >= 2) {
        arr.sort((a,b) => {
          const A = parseTime(a.p), B = parseTime(b.p);
          if (A != null && B != null) return A - B;
          return 0;
        });
      }
    }
  }

  // Convert to validGrowth vectors
  const validGrowthByEntity = new Map();
  for (const [grp, arr] of grouped.entries()) {
    const valid = arr.map(x => num(x.g)).filter(x => x != null);
    validGrowthByEntity.set(grp, valid);
  }

  // ---- threshold: use existing extras.risk_probability.threshold if present, else -0.2 only if risk table exists ----
  out.extras ||= {};
  const rp = (out.extras.risk_probability && typeof out.extras.risk_probability === "object") ? out.extras.risk_probability : null;
  let threshold = rp ? num(rp.threshold) : null;
  const riskTableExists = tables && Array.isArray(tables.risk_assessment) && tables.risk_assessment.length > 0;
  if (threshold == null && riskTableExists) threshold = -0.2;

  // ---- 5) Rebuild series.growth_trends (ONLY if it already exists) ----
  if (Array.isArray(series.growth_trends)) {
    // We will preserve the original keys as much as possible:
    const gtFirst = series.growth_trends.find(isObj) || {};
    const gtKeys = Object.keys(gtFirst);

    // Choose output keys by â€œbest effortâ€:
    const outEntityKey =
      gtKeys.find(k => /rep|sales|agent|district|product|entity/i.test(k)) || "entity";
    const outFromKey =
      gtKeys.find(k => /from|prev/i.test(k)) || "from";
    const outToKey =
      gtKeys.find(k => /to|cur|current/i.test(k)) || "to";
    const outGrowthKey =
      gtKeys.find(k => /growth|pct|rate/i.test(k)) || "growth";

    const rebuilt = [];

    for (const [grp, arr] of grouped.entries()) {
      for (let i = 0; i < arr.length; i++) {
        const g = num(arr[i].g);
        if (g == null) continue;

        const row = {};
        row[outEntityKey] = (grp === "__single__") ? null : grp;
        row[outFromKey] = (i - 1 >= 0) ? arr[i - 1].p : null;
        row[outToKey] = arr[i].p;
        row[outGrowthKey] = g;
        rebuilt.push(row);
      }
    }

    series.growth_trends = rebuilt;
  }

  // ---- 6) Rebuild Avg MoM Growth in rep_performance (ONLY if table exists) ----
  if (tables && Array.isArray(tables.rep_performance) && tables.rep_performance.length > 0) {
    const tFirst = tables.rep_performance.find(isObj) || {};
    const tKeys = Object.keys(tFirst);

    // identify entity column in rep_performance
    const tEntityKey =
      tKeys.find(k => /sales rep|rep|agent|district|product|entity/i.test(k)) || null;

    // identify avg growth column
    const tAvgKey =
      tKeys.find(k => /avg.*growth|avg.*mom|mean.*growth/i.test(k)) || null;

    if (tEntityKey && tAvgKey) {
      for (const row of tables.rep_performance) {
        if (!isObj(row)) continue;
        const grp = row[tEntityKey] == null ? "__single__" : String(row[tEntityKey]);
        const valid = validGrowthByEntity.get(grp) || [];
        const ms = safeMeanSd(valid);
        row[tAvgKey] = (ms.mean != null) ? ms.mean : null;
      }
    }
  }

  // ---- 7) Rebuild risk_assessment (ONLY if table exists) ----
  if (tables && Array.isArray(tables.risk_assessment) && tables.risk_assessment.length > 0) {
    const rFirst = tables.risk_assessment.find(isObj) || {};
    const rKeys = Object.keys(rFirst);

    const rEntityKey =
      rKeys.find(k => /sales rep|rep|agent|district|product|entity/i.test(k)) || null;

    // empirical prob column
    const rEmpKey =
      rKeys.find(k => /empirical.*prob|historical.*freq|drop.*prob/i.test(k)) || null;

    // transitions count
    const rNKey =
      rKeys.find(k => /n.*trans|transitions|count.*trans/i.test(k)) || null;

    // drop count
    const rDropKey =
      rKeys.find(k => /drop.*count|count.*drop|drops/i.test(k)) || null;

    // z-score column
    const rZKey =
      rKeys.find(k => /z.*score|normal.*z/i.test(k)) || null;

    // If we can't locate key columns, we still wonâ€™t break anything: do nothing.
    if (rEntityKey && (rEmpKey || rNKey || rDropKey || rZKey)) {
      for (const row of tables.risk_assessment) {
        if (!isObj(row)) continue;
        const grp = row[rEntityKey] == null ? "__single__" : String(row[rEntityKey]);
        const valid = validGrowthByEntity.get(grp) || [];
        const n = valid.length;

        // empirical
        let dropCount = null, emp = null;
        if (threshold != null && n > 0) {
          let cnt = 0;
          for (const g of valid) if (g < threshold) cnt++;
          dropCount = cnt;
          emp = cnt / n;
        }

        // z-score
        let z = null;
        const ms = safeMeanSd(valid);
        if (threshold != null && ms.n >= 2 && ms.sd != null && ms.sd > 0) {
          z = (threshold - ms.mean) / ms.sd;
        }

        if (rNKey) row[rNKey] = n || 0;
        if (rDropKey) row[rDropKey] = (dropCount != null) ? dropCount : (row[rDropKey] ?? null);
        if (rEmpKey) row[rEmpKey] = (emp != null) ? emp : null;
        if (rZKey) row[rZKey] = (z != null && Number.isFinite(z)) ? z : null;
      }
    }
  }

  // ---- 8) Degrade global risk_probability if multi-entity output ----
  if (rp) {
    const entities = Array.from(grouped.keys()).filter(k => k !== "__single__");
    if (entities.length > 1) {
      rp.reasons = Array.isArray(rp.reasons) ? rp.reasons : [];
      rp.reasons.push("Degraded: multi-entity output makes a single global baseline ambiguous.");
      rp.reasons = Array.from(new Set(rp.reasons.map(s => String(s))));
    }
  }
}


// FIX: Ensure Growth_Pct exists for baseline time series-like tables
function ensureGrowthPctTableRows(rows) {
  if (!Array.isArray(rows) || rows.length === 0) return;

  const firstObj = rows.find(r => r && typeof r === "object" && !Array.isArray(r));
  if (!firstObj) return;

  const vKey = _inferValueKey(firstObj) || "value";

  // --- NEW: detect if this array actually contains multiple interleaved series (eg reps, units, crews) ---
  const groupKey = (() => {
    const direct = ["rep", "Rep", "Sales Rep", "SalesRep", "salesRep", "sales_rep", "agent", "Agent", "unit", "Unit", "crew", "Crew", "district", "District", "Sales Employee Name", "Sales Employee Code", "Salesperson", "Sales Person", "Employee", "employee"];
    for (const k of direct) if (k in firstObj) return k;

    for (const k of Object.keys(firstObj)) {
      const nk = String(k).toLowerCase().replace(/[\s_]/g, "");
      if (nk === "rep" || nk === "salesrep" || nk === "agent" || nk === "unit" || nk === "crew" || nk === "district" || nk === "salesemployeename" || nk === "salesemployeecode" || nk === "salesemployee" || nk === "employee" || nk === "salesperson") return k;
    }
    return null;
  })();

  // validate groupKey (avoid grouping on high-cardinality keys)
  let useGroupKey = null;
  if (groupKey) {
    const uniq = new Set();
    for (let i = 0; i < rows.length && i < 500; i++) {
      const r = rows[i];
      if (!r || typeof r !== "object" || Array.isArray(r)) continue;
      const gv = r[groupKey];
      if (gv == null) continue;
      uniq.add(String(gv));
      if (uniq.size > 50) break;
    }
    if (uniq.size >= 2 && uniq.size <= 50) useGroupKey = groupKey;
  }

  // --- Baseline capture wiring (ONLY for true single-series baseline arrays) ---
  const globalMv = globalThis.__seraMetaVectorsRef;
  const globalRef = globalThis.__seraBaselineSeriesRef;

  const canConsiderCapture = !!(globalMv && !useGroupKey);
  const shouldCapture = canConsiderCapture && (
    globalRef === rows ||
    (Array.isArray(globalMv.baselineTotals) && globalMv.baselineTotals.length === 0)
  );

  const mv = shouldCapture ? globalMv : null;

  const canCapture = !!(mv &&
    Array.isArray(mv.baselineTotals) &&
    Array.isArray(mv.baselineGrowth) &&
    Array.isArray(mv.baselinePeriods));

  // Prevent double-adding if we iterate the exact same array instance twice
  const alreadyBuilt = !!(canCapture &&
    mv.baselineTotals.length === rows.length &&
    mv.baselinePeriods.length === rows.length &&
    mv.baselineGrowth.length === Math.max(0, rows.length - 1));

  // Track previous value PER GROUP (or globally if ungrouped)
  const prevByGroup = new Map();

  for (let i = 0; i < rows.length; i++) {
    const r = rows[i];
    if (!r || typeof r !== "object" || Array.isArray(r)) continue;

    const groupId = useGroupKey ? String(r[useGroupKey] ?? "") : "__all__";
    const cur = safeNumber(r[vKey]);

    // choose period label
    const periodLabel =
      r.period ?? r.Period ??
      r.month ?? r.Month ??
      r.date ?? r.Date ??
      r.period_key ?? r.periodKey ?? r.PeriodKey ??
      i;

    const prev = prevByGroup.has(groupId) ? prevByGroup.get(groupId) : null;

    // First row for this group: ALWAYS null Growth_Pct (even if some earlier code set garbage)
    if (prev == null) {
      r.Growth_Pct = null;

      if (canCapture && !alreadyBuilt) {
        mv.baselineTotals.push(cur);
        mv.baselinePeriods.push(periodLabel);
      }

      prevByGroup.set(groupId, cur);
      continue;
    }

    // If row already has a valid Growth_Pct, preserve it. Otherwise compute.
    let g = null;
    if ("Growth_Pct" in r) g = safeNumber(r.Growth_Pct);
    if (g == null && "growthPct" in r) g = safeNumber(r.growthPct);
    if (g == null && "growth_pct" in r) g = safeNumber(r.growth_pct);

    if (g == null) {
      if (cur != null && prev != null && prev !== 0) g = safeNumber((cur - prev) / Math.abs(prev));
      else g = null;
    }

    r.Growth_Pct = g;

    if (canCapture && !alreadyBuilt) {
      mv.baselineTotals.push(cur);
      mv.baselinePeriods.push(periodLabel);
      mv.baselineGrowth.push(g);
    }

    prevByGroup.set(groupId, cur);
  }
}

function ensureTableColumnIntegrity(out) {
  if (!out || typeof out !== "object") return;

  const tables = out.tables;
  if (!tables || typeof tables !== "object") return;

  const t = tables.material_drivers;
  if (!t || typeof t !== "object") return;

  const cols = Array.isArray(t.columns) ? t.columns : null;
  const rows = Array.isArray(t.rows) ? t.rows : null;
  if (!cols || !rows || rows.length === 0) return;

  const needsMaterialField = cols.includes("Material_Field");
  if (!needsMaterialField) return;

  let fixed = 0;
  for (const r of rows) {
    if (!r || typeof r !== "object" || Array.isArray(r)) continue;
    if ("Material_Field" in r) continue;

    // Try common fallbacks (whatever the upstream driver object used)
    const fallback =
      (r.field != null ? r.field : null) ??
      (r.material != null ? r.material : null) ??
      (r.Material != null ? r.Material : null) ??
      (r.xField != null ? r.xField : null) ??
      null;

    r.Material_Field = fallback; // stays null if unknown (truth-safe)
    fixed++;
  }

  out.diagnostics ||= {};
  out.diagnostics.notes ||= [];
  if (fixed > 0) out.diagnostics.notes.push(`Integrity fix: material_drivers rows missing Material_Field. Patched ${fixed} rows (null if unknown).`);
}



function ensureGrowthPctDeep(out) {
  if (!out || typeof out !== "object") return;

  const series = out.series || {};
  const tables = out.tables || {};

  // Choose canonical baseline series (single-series only)
  const baselineSeriesRef =
    (Array.isArray(series.monthly_trend) && series.monthly_trend.length ? series.monthly_trend :
     Array.isArray(series.monthly_totals) && series.monthly_totals.length ? series.monthly_totals :
     Array.isArray(series.monthlyTotals) && series.monthlyTotals.length ? series.monthlyTotals :
     Array.isArray(series.monthly_total) && series.monthly_total.length ? series.monthly_total :
     Array.isArray(series.monthlyTotal) && series.monthlyTotal.length ? series.monthlyTotal :
     Array.isArray(series.baseline) && series.baseline.length ? series.baseline :
     Array.isArray(series.baseline_series) && series.baseline_series.length ? series.baseline_series :
     Array.isArray(series.time_series) && series.time_series.length ? series.time_series :
     Array.isArray(series.timeSeries) && series.timeSeries.length ? series.timeSeries :
     Array.isArray(tables.performance_baseline) && tables.performance_baseline.length ? tables.performance_baseline :
     Array.isArray(tables.baseline) && tables.baseline.length ? tables.baseline :
     Array.isArray(tables.baseline_time_series) && tables.baseline_time_series.length ? tables.baseline_time_series :
     Array.isArray(tables.baseline_timeseries) && tables.baseline_timeseries.length ? tables.baseline_timeseries :
     Array.isArray(tables.baselineTimeSeries) && tables.baselineTimeSeries.length ? tables.baselineTimeSeries :
     Array.isArray(tables.time_series) && tables.time_series.length ? tables.time_series :
     Array.isArray(tables.timeSeries) && tables.timeSeries.length ? tables.timeSeries :
     null);

  const hadMetaVectors = !!(out.metaVectors && typeof out.metaVectors === "object");
  const metaVectors = hadMetaVectors
    ? out.metaVectors
    : { baselineTotals: [], baselineGrowth: [], baselinePeriods: [] };

  // Only reset/capture if we truly have a baseline reference
  if (baselineSeriesRef) {
    metaVectors.baselineTotals = [];
    metaVectors.baselineGrowth = [];
    metaVectors.baselinePeriods = [];

    globalThis.__seraMetaVectorsRef = metaVectors;
    globalThis.__seraBaselineSeriesRef = baselineSeriesRef;

  const candidates = [
  series.monthly_trend,
  series.monthly_totals,
  series.monthlyTotals,
  series.baseline,
  series.baseline_series,
  tables.performance_baseline,
  tables.baseline,
  tables.baseline_time_series,
  tables.baseline_timeseries,
  tables.baselineTimeSeries,
  tables.time_series,
  tables.timeSeries
];


    for (const c of candidates) ensureGrowthPctTableRows(c);

    // finalize baseline vectors for downstream risk logic
    metaVectors.baselinePeriods = Array.isArray(metaVectors.baselinePeriods)
      ? metaVectors.baselinePeriods.slice(0, metaVectors.baselineTotals.length)
      : [];

    metaVectors.baselineGrowth = Array.isArray(metaVectors.baselineGrowth)
      ? metaVectors.baselineGrowth.slice(0, Math.max(0, metaVectors.baselineTotals.length - 1))
      : [];

    metaVectors.nMonths = safeInt(metaVectors.baselineTotals.length);
    metaVectors.nTransitions = safeInt(metaVectors.baselineGrowth.length);

    // Only attach metaVectors if it has real content
    if (metaVectors.baselineTotals.length > 0) {
      out.metaVectors = metaVectors;
    } else if (!hadMetaVectors) {
      // do not inject empty metaVectors
      try { delete out.metaVectors; } catch (_) {}
    }

    globalThis.__seraMetaVectorsRef = null;
    globalThis.__seraBaselineSeriesRef = null;
  }

  // Light recursive pass: only arrays that smell like period/value rows
  const seen = new WeakSet();
  const walk = (v, k) => {
    if (v == null) return;
    if (typeof v !== "object") return;
    if (seen.has(v)) return;
    seen.add(v);

    if (Array.isArray(v)) {
      const firstObj = v.find(x => x && typeof x === "object" && !Array.isArray(x));
      if (firstObj && (
        ("period" in firstObj) || ("Period" in firstObj) ||
        ("month" in firstObj) || ("Month" in firstObj) ||
        ("date" in firstObj) || ("Date" in firstObj)
      )) {
        ensureGrowthPctTableRows(v);
      }
      for (const item of v) walk(item);
      return;
    }

    for (const key of Object.keys(v)) walk(v[key], key);
  };

  walk(out, "");
}

function ensureMoMGrowthDeep(out) {
  if (!out || typeof out !== "object") return;

  const tables = (out.tables && typeof out.tables === "object") ? out.tables : {};

  // We keep the canonical keys (MoM_Growth, Growth_Pct) but also sync common aliases
  // so query-generated fields like "MoM Growth %" cannot drift to incorrect 0s.
  const MOM_ALIASES = [
    "MoM Growth %",
    "MoM Growth%",
    "MoM Growth",
    "MoM%",
    "MoM Growth Pct",
    "MoM_Growth_Pct",
    "mom_growth_pct",
    "momGrowthPct"
  ];

  const PCT_ALIASES = [
    "Growth %",
    "Growth",
    "GrowthPct",
    "Growth_Pct%",
    "growth_pct",
    "growthPct",
    "growthPercent"
  ];

  const hasOwn = (o, k) => Object.prototype.hasOwnProperty.call(o, k);

  const pullFromAliases = (row, canonicalKey, aliases) => {
    // IMPORTANT: if canonical exists (even null), do NOT overwrite from aliases.
    if (hasOwn(row, canonicalKey)) return;
    for (const ak of aliases) {
      if (hasOwn(row, ak)) { row[canonicalKey] = row[ak]; return; }
    }
  };

  const syncToAliases = (row, canonicalKey, aliases) => {
    if (!hasOwn(row, canonicalKey)) return;
    for (const ak of aliases) {
      if (hasOwn(row, ak)) row[ak] = row[canonicalKey];
    }
  };

  const aliasRow = (row) => {
    if (!row || typeof row !== "object" || Array.isArray(row)) return;

    // Pull canonical keys only when missing
    pullFromAliases(row, "MoM_Growth", MOM_ALIASES);
    pullFromAliases(row, "Growth_Pct", PCT_ALIASES);

    const hasMoM = hasOwn(row, "MoM_Growth");
    const hasPct = hasOwn(row, "Growth_Pct");

    // Mirror canonical keys
    if (hasPct && !hasMoM) row.MoM_Growth = row.Growth_Pct;
    if (hasMoM && !hasPct) row.Growth_Pct = row.MoM_Growth;

    // Sync back out (overwrites alias 0s when canonical is null)
    syncToAliases(row, "MoM_Growth", MOM_ALIASES);
    syncToAliases(row, "Growth_Pct", PCT_ALIASES);
  };

  // Walk every table array
  for (const k of Object.keys(tables)) {
    const v = tables[k];
    if (Array.isArray(v)) {
      for (const row of v) aliasRow(row);
    } else if (v && typeof v === "object" && Array.isArray(v.rows)) {
      for (const row of v.rows) aliasRow(row);
    }
  }
}

// Repair: if a query builds a "first active month growth" anomalies table using a percent field
// that incorrectly emits 0 (typically when prior month is 0/missing), recompute after canonicalization.
function repairFirstActiveMonthGrowthAnomalyTables(out) {
  if (!out || typeof out !== "object") return;

  const tables = (out.tables && typeof out.tables === "object") ? out.tables : {};
  const diag = (out.diagnostics && typeof out.diagnostics === "object") ? out.diagnostics : {};

  // Find a plausible trend table (schema-agnostic)
  const candidates = [
    tables.entity_period_trend,
    tables.rep_performance_trends,
    tables.entity_period_series,
    tables.entity_trend,
    tables.trends
  ];

  let trend = null;
  for (const c of candidates) {
    if (Array.isArray(c) && c.length) { trend = c; break; }
  }
  if (!trend) return;

  const sample = trend.find(r => r && typeof r === "object" && !Array.isArray(r)) || null;
  if (!sample) return;

  const keys = Object.keys(sample);

  const entityKey =
    (diag.chosenEntityField && keys.includes(diag.chosenEntityField)) ? diag.chosenEntityField :
    keys.find(k => /(sales\s*employee\s*name|sales\s*rep|rep|agent|employee|person|owner|entity|name)/i.test(k)) ||
    keys[0];

  const timeKey =
    keys.find(k => /^(month|period|date|time)$/i.test(k)) ||
    keys.find(k => /(month|period|date|time)/i.test(k)) ||
    null;

  const valueKey =
    keys.find(k => /(sales\s*amount|revenue|amount|amt|total|value)/i.test(k)) ||
    null;

  if (!entityKey || !timeKey || !valueKey) return;

  const monthOrder = { jan:1,feb:2,mar:3,apr:4,may:5,jun:6,jul:7,aug:8,sep:9,oct:10,nov:11,dec:12 };
  const fullMonthOrder = { january:1,february:2,march:3,april:4,may:5,june:6,july:7,august:8,september:9,october:10,november:11,december:12 };
  const toTime = (v) => {
    if (v == null) return null;
    const s = String(v).trim();
    if (!s) return null;
    const lo = s.toLowerCase();
    // 3-letter month
    const m3 = lo.slice(0,3);
    if (monthOrder[m3]) return monthOrder[m3];
    // Full month name
    if (fullMonthOrder[lo]) return fullMonthOrder[lo];
    // YYYY-MM
    const ymMatch = lo.match(/^(\d{4})[-/](\d{1,2})$/);
    if (ymMatch) return Number(ymMatch[1]) * 100 + Number(ymMatch[2]);
    // Quarter
    const qMatch = lo.match(/(?:(\d{4})\s*[-/]?\s*)?q([1-4])/);
    if (qMatch) return (qMatch[1] ? Number(qMatch[1]) * 100 : 0) + Number(qMatch[2]) * 3 - 2;
    // Full date YYYY-MM-DD
    const ymdMatch = lo.match(/^(\d{4})[-/](\d{1,2})[-/](\d{1,2})/);
    if (ymdMatch) return Number(ymdMatch[1]) * 10000 + Number(ymdMatch[2]) * 100 + Number(ymdMatch[3]);
    // Date.parse as last resort (returns ms, but only compared against other parsed dates)
    const t = Date.parse(s);
    return Number.isFinite(t) ? t : null;
  };

  const toNum = (v) => {
    try {
      const n = (globalThis._ && _.stats && typeof _.stats.toNumber === "function") ? _.stats.toNumber(v) : Number(v);
      return Number.isFinite(n) ? n : null;
    } catch (_) {
      return null;
    }
  };

  const byEntity = new Map();
  for (const row of trend) {
    if (!row || typeof row !== "object" || Array.isArray(row)) continue;
    const ent = row[entityKey];
    const ek = (ent == null) ? "" : String(ent);
    if (!byEntity.has(ek)) byEntity.set(ek, []);
    byEntity.get(ek).push(row);
  }
  if (!byEntity.size) return;

  const growthKeys = [
    "MoM_Growth",
    "Growth_Pct",
    "MoM Growth %",
    "MoM Growth%",
    "MoM Growth",
    "MoM%",
    "MoM Growth Pct",
    "MoM_Growth_Pct",
    "mom_growth_pct",
    "momGrowthPct",
    "Growth %",
    "Growth",
    "GrowthPct",
    "Growth_Pct%",
    "growth_pct",
    "growthPct",
    "growthPercent"
  ];

  const eps = 1e-12;
  const anomalies = [];

  for (const [ek, arr] of byEntity.entries()) {
    if (!Array.isArray(arr) || !arr.length) continue;

    arr.sort((a, b) => {
      const ta = toTime(a && a[timeKey]);
      const tb = toTime(b && b[timeKey]);
      if (ta == null && tb == null) return 0;
      if (ta == null) return 1;
      if (tb == null) return -1;
      return ta - tb;
    });

    // First active month: first non-zero (robust to wide-month blanks coerced to 0)
    let firstActive = null;
    for (const r of arr) {
      const v = toNum(r && r[valueKey]);
      if (v != null && Math.abs(v) > eps) { firstActive = r; break; }
    }
    if (!firstActive) continue;

    let hadFiniteGrowth = false;
    let detected = null;

    for (const gk of growthKeys) {
      if (Object.prototype.hasOwnProperty.call(firstActive, gk)) {
        const gv = toNum(firstActive[gk]);
        if (gv != null) {
          hadFiniteGrowth = true;
          detected = gv;
        }
        // Enforce: growth must be null for first active month
        firstActive[gk] = null;
      }
    }

    if (hadFiniteGrowth) {
      anomalies.push({
        [entityKey]: firstActive[entityKey],
        "First Active Month": firstActive[timeKey],
        "Detected Growth": detected,
        "Status": "Anomaly"
      });
    }
  }

  // If an existing table looks like a first-month growth anomaly table, replace it.
  const existing = tables.entity_anomalies;
  const looksLikeFirstMonth = Array.isArray(existing) && existing.some(r => r && typeof r === "object" && !Array.isArray(r) && ("First Active Month" in r || "Detected Growth" in r));
  if (looksLikeFirstMonth) {
    tables.entity_anomalies = anomalies;
  }

  if (out.extras && typeof out.extras === "object") {
    out.extras.first_month_growth_anomalies = anomalies;
  }

  // Optional: if summary claims N anomalies but we recomputed none, normalize the number.
  if (typeof out.executiveSummary === "string") {
    if (anomalies.length === 0 && /identified\s+\d+\s+anomalies/i.test(out.executiveSummary)) {
      out.executiveSummary = out.executiveSummary.replace(/identified\s+\d+\s+anomalies/i, "identified 0 anomalies");
    }
  }
}

function ensureEntityDropRiskFromTrendsDeep(out) {
  if (!out || typeof out !== "object") return;

  const tables = (out.tables && typeof out.tables === "object") ? out.tables : {};
  const diag = (out.diagnostics && typeof out.diagnostics === "object") ? out.diagnostics : {};

  const trend =
    (Array.isArray(tables.rep_performance_trends) && tables.rep_performance_trends.length ? tables.rep_performance_trends : null);

  if (!trend) return;

  // Find entity + time + value keys (schema-agnostic)
  const sample = trend.find(r => r && typeof r === "object" && !Array.isArray(r)) || null;
  if (!sample) return;

  const keys = Object.keys(sample);

  const entityKey =
    (diag.chosenEntityField && keys.includes(diag.chosenEntityField)) ? diag.chosenEntityField :
    keys.find(k => /(sales\s*rep|rep|agent|person|owner|entity|name)/i.test(k)) ||
    keys[0];

  const timeKey =
    keys.find(k => /^(month|period|date|time|week)$/i.test(k)) ||
    keys.find(k => /(month|period|date)/i.test(k)) ||
    null;

  if (!timeKey) return;

  const valueKey =
    keys.find(k => /^(sales|amount|amt|revenue|total|value)$/i.test(k)) ||
    keys.find(k => /(sales|amount|amt|revenue|total|value)/i.test(k)) ||
    null;

  if (!valueKey) return;

  const monthOrder = { jan:1,feb:2,mar:3,apr:4,may:5,jun:6,jul:7,aug:8,sep:9,oct:10,nov:11,dec:12 };
  const fullMonthOrder2 = { january:1,february:2,march:3,april:4,may:5,june:6,july:7,august:8,september:9,october:10,november:11,december:12 };
  const toTime = (v) => {
    if (v == null) return null;
    const s = String(v).trim();
    const lo = s.toLowerCase();
    const m3 = lo.slice(0,3);
    if (monthOrder[m3]) return monthOrder[m3];               // Jan..Dec
    if (fullMonthOrder2[lo]) return fullMonthOrder2[lo];     // January..December
    // YYYY-MM
    const ymMatch = lo.match(/^(\d{4})[-/](\d{1,2})$/);
    if (ymMatch) return Number(ymMatch[1]) * 100 + Number(ymMatch[2]);
    // Quarter
    const qMatch = lo.match(/(?:(\d{4})\s*[-/]?\s*)?q([1-4])/);
    if (qMatch) return (qMatch[1] ? Number(qMatch[1]) * 100 : 0) + Number(qMatch[2]) * 3 - 2;
    // Full date
    const ymdMatch = lo.match(/^(\d{4})[-/](\d{1,2})[-/](\d{1,2})/);
    if (ymdMatch) return Number(ymdMatch[1]) * 10000 + Number(ymdMatch[2]) * 100 + Number(ymdMatch[3]);
    const t = Date.parse(s);
    return Number.isFinite(t) ? t : null;               // ISO, etc.
  };

  const toNum = (x) => {
    const n = (globalThis._ && globalThis._.stats && typeof globalThis._.stats.toNumber === "function")
      ? globalThis._.stats.toNumber(x)
      : (typeof x === "number" ? x : Number(x));
    return Number.isFinite(n) ? n : null;
  };

  const normalCdf = (z) => {
    if (!Number.isFinite(z)) return null;
    // Abramowitz-Stegun-ish approximation (good enough for a proxy)
    const t = 1 / (1 + 0.2316419 * Math.abs(z));
    const d = 0.3989423 * Math.exp(-z*z/2);
    const p = d * t * (0.3193815 + t * (-0.3565638 + t * (1.781478 + t * (-1.821256 + t * 1.330274))));
    const cdf = z >= 0 ? 1 - p : p;
    return cdf;
  };

  const byEnt = new Map();
  for (const r of trend) {
    if (!r || typeof r !== "object" || Array.isArray(r)) continue;
    const ent = r[entityKey] == null ? "__null__" : String(r[entityKey]);
    const t = toTime(r[timeKey]);
    const y = toNum(r[valueKey]);
    if (t == null || y == null) continue;
    if (!byEnt.has(ent)) byEnt.set(ent, []);
    byEnt.get(ent).push({ t, y });
  }

  const threshold = -0.20;

  const riskRows = [];
  for (const [ent, pts] of byEnt.entries()) {
    pts.sort((a,b) => (a.t === b.t ? 0 : (a.t < b.t ? -1 : 1)));

    const growth = [];
    for (let i=1; i<pts.length; i++) {
      const prev = pts[i-1].y;
      const cur = pts[i].y;
      if (prev > 0 && Number.isFinite(prev) && Number.isFinite(cur)) {
        growth.push((cur - prev) / prev);
      }
    }

    const nTransitions = growth.length;
    const dropCount = growth.filter(g => Number.isFinite(g) && g <= threshold).length;
    const historicalFrequency = nTransitions > 0 ? (dropCount / nTransitions) : null;

    let mean = null, sd = null, zScoreToThreshold = null, normalApproxProbability = null;

    if (nTransitions >= 2) {
      const m = growth.reduce((a,b)=>a+b,0) / nTransitions;
      const v = growth.reduce((a,b)=>a + (b-m)*(b-m), 0) / (nTransitions - 1);
      const s = Math.sqrt(v);
      mean = Number.isFinite(m) ? m : null;
      sd = Number.isFinite(s) ? s : null;
      if (sd && sd > 0 && mean != null) {
        zScoreToThreshold = (threshold - mean) / sd;
        normalApproxProbability = normalCdf(zScoreToThreshold);
      }
    }

    const score =
      (historicalFrequency != null && normalApproxProbability != null) ? Math.max(historicalFrequency, normalApproxProbability) :
      (historicalFrequency != null ? historicalFrequency :
       (normalApproxProbability != null ? normalApproxProbability : 0));

    const status =
      (historicalFrequency == null && normalApproxProbability == null) ? "not_computable" : "ok";

    riskRows.push({
      rep: ent,
      score,
      dropThreshold: threshold,
      nTransitions,
      dropCount,
      historicalFrequency,
      zScoreToThreshold,
      normalApproxProbability,
      status
    });
  }

  out.extras = (out.extras && typeof out.extras === "object") ? out.extras : {};
  out.extras.risk_profile = riskRows;
}



// FIX: Summary strings must never contain NaN/Infinity tokens
function sanitizeSummaryStringsDeep(out) {
  const seen = new WeakSet();

  const fix = (s) => {
    if (typeof s !== "string") return s;
    return s
      .replace(/\bNaN\b/g, "Not computable from available data")
      .replace(/\b-Infinity\b/g, "Not computable from available data")
      .replace(/\bInfinity\b/g, "Not computable from available data");
  }; // IMPORTANT: this brace+semicolon must exist

  const walk = (v, key) => {
    if (typeof v === "string") {
      if (key && /summary/i.test(String(key))) return fix(v);
      return v;
    }
    if (v == null || typeof v !== "object") return v;
    if (seen.has(v)) return v;
    seen.add(v);

    if (Array.isArray(v)) {
      for (let i = 0; i < v.length; i++) v[i] = walk(v[i], key);
      return v;
    }

    for (const k of Object.keys(v)) v[k] = walk(v[k], k);
    return v;
  };

  return walk(out, "");
}

// =============================================================
// DIAGNOSTICS CONTRACT ENFORCER (Universal)
// - Ensures diagnostics.correlationBlocks exists as an array
// - Ensures wrapper-level AND inner result-level diagnostics comply
// =============================================================

function enforceDiagnosticsContract(container) {
  const toFinite = (v) => (typeof v === "number" && Number.isFinite(v)) ? v : null;
  const obj = container; // legacy alias safety: prevents "obj is not defined" crashes


  const normalizeNumericCoverage = (diag) => {
    if (!diag || typeof diag !== "object") return;

    if (!diag.numericCoverageByField || typeof diag.numericCoverageByField !== "object" || Array.isArray(diag.numericCoverageByField)) {
      diag.numericCoverageByField = {};
    }

    const totalGuess =
      (typeof diag.rowCount === "number" && Number.isFinite(diag.rowCount)) ? diag.rowCount :
      (diag && diag.meta && diag.meta.executor && typeof diag.meta.executor.rowCount === "number") ? diag.meta.executor.rowCount :
      null;

    for (const k of Object.keys(diag.numericCoverageByField)) {
      const v = diag.numericCoverageByField[k];

      if (typeof v === "number" && Number.isFinite(v)) {
        const cov = v;
        const total = totalGuess;
        const valid = (typeof total === "number" && Number.isFinite(total))
          ? Math.round(total * cov)
          : null;

        diag.numericCoverageByField[k] = { valid, total, coverage: cov };
        continue;
      }

      if (v && typeof v === "object" && !Array.isArray(v)) {
        const cov = toFinite(v.coverage);
        const total = toFinite(v.total) ?? totalGuess;
        const valid = toFinite(v.valid);

        if (cov != null && (valid == null || total == null) && typeof total === "number") {
          diag.numericCoverageByField[k] = {
            valid: Math.round(total * cov),
            total: total,
            coverage: cov
          };
        } else {
          diag.numericCoverageByField[k] = {
            valid: valid,
            total: total,
            coverage: (cov != null && Number.isFinite(cov)) ? cov : null
          };
        }
      }
    }
  };

  const isInjectedOnly = (arr) => {
    if (!Array.isArray(arr) || !arr.length) return true;
    return arr.every(b => b && (b._injected === true || (b.status === "skipped" && /injected/i.test(String(b.reason || "")))));
  };

  const ensure = (obj, reasonLabel) => {
    if (!obj || typeof obj !== "object") return;

    obj.diagnostics = (obj.diagnostics && typeof obj.diagnostics === "object") ? obj.diagnostics : {};

    // numericCoverageByField must be contract-shaped
    normalizeNumericCoverage(obj.diagnostics);

    // truncations: keep only true truncations
    if (!Array.isArray(obj.diagnostics.truncations)) obj.diagnostics.truncations = [];
    obj.diagnostics.truncations = obj.diagnostics.truncations.filter(t => {
      if (!t || typeof t !== "object") return false;
      const cap = Number(t.cap ?? t.limit);
      const actual = Number(t.actual ?? t.count ?? t.size);
      if (!Number.isFinite(cap) || !Number.isFinite(actual)) return false;
      return actual > cap;
    });

    // correlationBlocks must exist and be an array
    if (!Array.isArray(obj.diagnostics.correlationBlocks)) {
      obj.diagnostics.correlationBlocks = [];
    }

    // If totally missing AND we have an execution error, mark as failed instead of pretending "skipped"
    const execErr = obj.error || (obj.meta && obj.meta.executor && obj.meta.executor.error) || null;
    const hasErr = typeof execErr === "string" && execErr.length;

    if (!obj.diagnostics.correlationBlocks.length) {
      obj.diagnostics.correlationBlocks.push({
        blockId: "correlation_scan",
        family: "Correlation & Drivers",
        method: "none",
        nValidPairs: 0,
        nTotal: 0,
        coverage: 0,
        status: hasErr ? "failed" : "skipped",
        value: null,
        _injected: true,
        reason: hasErr
          ? `Correlation scan missing because execution errored: ${execErr}`
          : (reasonLabel || "No correlation scan emitted by generated function.")
      });
    }

    // correlationBlocks: normalize coverage semantics (rows vs pairs) safely
    // correlationBlocks: normalize coverage semantics (rows vs pairs) safely
try {
  const rc = (typeof obj.diagnostics.rowCount === "number" && Number.isFinite(obj.diagnostics.rowCount))
    ? obj.diagnostics.rowCount
    : null;

  obj.diagnostics.correlationBlocks = obj.diagnostics.correlationBlocks.map((cb) => {
    if (!cb || typeof cb !== "object") return cb;

    const nValid = (typeof cb.nValidPairs === "number" && Number.isFinite(cb.nValidPairs)) ? cb.nValidPairs : 0;

    // Preserve any existing nTotal, but interpret carefully
    const nTotalRaw = (typeof cb.nTotal === "number" && Number.isFinite(cb.nTotal)) ? cb.nTotal : null;

    // Normalize coverage into [0,1] if present
    const covRaw = (typeof cb.coverage === "number" && Number.isFinite(cb.coverage)) ? cb.coverage : null;
    const covClamped = (covRaw == null) ? null : Math.max(0, Math.min(1, covRaw));

    // Always store rowCount semantics explicitly
    if (rc != null) cb.nTotalRows = rc;

    // Derive pair semantics in a stable, non-destructive way
    // Priority:
    // 1) If coverage is a sane ratio, infer total pairs from it.
    // 2) Else if nTotal looks like a pair-total (>= nValid and not equal to rowCount), use it.
    // 3) Else fall back: assume nTotalPairs = nValid (coveragePairs=1 when nValid>0).
    let nTotalPairs = null;
    let coveragePairs = null;

    if (covClamped != null && covClamped > 0 && nValid > 0) {
      nTotalPairs = Math.max(nValid, Math.round(nValid / covClamped));
      coveragePairs = nValid / nTotalPairs;
    } else if (nTotalRaw != null && (rc == null || nTotalRaw !== rc) && nTotalRaw >= nValid) {
      nTotalPairs = nTotalRaw;
      coveragePairs = (nTotalPairs > 0) ? (nValid / nTotalPairs) : 0;
    } else {
      nTotalPairs = nValid;
      coveragePairs = (nValid > 0) ? 1 : 0;
    }

    cb.nTotalPairs = nTotalPairs;
    cb.coveragePairs = coveragePairs;

    // Keep legacy fields but make them safe
    if (cb.coverage == null) cb.coverage = coveragePairs;
    else cb.coverage = Math.max(0, Math.min(1, cb.coverage));

    return cb;
  });
} catch (_) {}


    // blockStatus must exist
    if (!Array.isArray(obj.diagnostics.blockStatus)) obj.diagnostics.blockStatus = [];

    // If execution failed, ensure a clear failure block exists
    if (hasErr && !obj.diagnostics.blockStatus.some(b => b && b.blockId === "executor_error")) {
      obj.diagnostics.blockStatus.unshift({
        blockId: "executor_error",
        family: "Executor",
        status: "failed",
        evidencePaths: [],
        reason: execErr
      });
    }
  

  // 1) Wrapper-level
  ensure(container, "Wrapper had no correlationBlocks; injected contract marker.");

  // 2) Inner result-level
  if (container && container.result && typeof container.result === "object") {
    ensure(container.result, "Inner result had no correlationBlocks; injected contract marker.");
  }

  // FINAL SYNC: prefer inner result.diagnostics as source of truth
  try {
    if (container && container.result && container.result.diagnostics) {
      const inner = container.result.diagnostics;
      container.diagnostics = container.diagnostics && typeof container.diagnostics === "object"
        ? container.diagnostics
        : {};

      const wCB = container.diagnostics.correlationBlocks;
      const wBS = container.diagnostics.blockStatus;

      if (!Array.isArray(wCB) || !wCB.length || isInjectedOnly(wCB)) {
        container.diagnostics.correlationBlocks = Array.isArray(inner.correlationBlocks) ? inner.correlationBlocks : [];
      }
      if (!Array.isArray(wBS) || !wBS.length) {
        container.diagnostics.blockStatus = Array.isArray(inner.blockStatus) ? inner.blockStatus : [];
      }
      if (!container.diagnostics.numericCoverageByField || typeof container.diagnostics.numericCoverageByField !== "object" || !Object.keys(container.diagnostics.numericCoverageByField).length) {
        container.diagnostics.numericCoverageByField = inner.numericCoverageByField && typeof inner.numericCoverageByField === "object"
          ? inner.numericCoverageByField
          : {};
      }
      if (!Array.isArray(container.diagnostics.truncations) || !container.diagnostics.truncations.length) {
        container.diagnostics.truncations = Array.isArray(inner.truncations) ? inner.truncations : [];
      }
    }
  } catch (_) {}
}


    

    // If execution failed, ensure a clear failure block exists
if (hasErr && !obj.diagnostics.blockStatus.some(b => b && b.blockId === "executor_error")) {
  obj.diagnostics.blockStatus.unshift({
    blockId: "executor_error",
    family: "Executor",
    status: "failed",
    evidencePaths: [],
    reason: execErr
  });
}


  // 1) Wrapper-level
  ensure(container, "Wrapper had no correlationBlocks; injected contract marker.");

  // 2) Inner result-level
  if (container && container.result && typeof container.result === "object") {
    ensure(container.result, "Inner result had no correlationBlocks; injected contract marker.");
  }



  // =============================================================
  // FINAL SYNC: prefer inner result.diagnostics as source of truth
  // - If wrapper is empty OR wrapper only contains injected placeholders,
  //   mirror inner across the core diagnostic surfaces.
  // =============================================================
  try {
    if (container && container.result && container.result.diagnostics) {
      const inner = container.result.diagnostics;
      container.diagnostics = container.diagnostics && typeof container.diagnostics === "object"
        ? container.diagnostics
        : {};

      const wCB = container.diagnostics.correlationBlocks;
      const wBS = container.diagnostics.blockStatus;

      if (!Array.isArray(wCB) || !wCB.length || isInjectedOnly(wCB)) {
        container.diagnostics.correlationBlocks = Array.isArray(inner.correlationBlocks) ? inner.correlationBlocks : [];
      }
      if (!Array.isArray(wBS) || !wBS.length) {
        container.diagnostics.blockStatus = Array.isArray(inner.blockStatus) ? inner.blockStatus : [];
      }
      if (!container.diagnostics.numericCoverageByField || typeof container.diagnostics.numericCoverageByField !== "object" || !Object.keys(container.diagnostics.numericCoverageByField).length) {
        container.diagnostics.numericCoverageByField = inner.numericCoverageByField && typeof inner.numericCoverageByField === "object"
          ? inner.numericCoverageByField
          : {};
      }
      if (!Array.isArray(container.diagnostics.truncations) || !container.diagnostics.truncations.length) {
        container.diagnostics.truncations = Array.isArray(inner.truncations) ? inner.truncations : [];
      }
    }
  } catch (_) {}
}

 // END enforceDiagnosticsContract

// hard stop before next function (leave this here)

// =============================================================
// OK-EVIDENCE ENFORCER (Universal)
// - If status=ok but evidencePaths empty -> downgrade/skipped appropriately
// =============================================================
function enforceOkEvidence(rootResult) {
  // Universal evidencePaths validator that understands BOTH:
  // - wrapper roots: { ok, result: {...}, diagnostics: {...} }
  // - inner roots:   { tables, extras, diagnostics, ... }
  //
  // It will validate evidencePaths against rootResult AND (if present) rootResult.result,
  // and will canonicalize paths so wrapper-level enforcement remains correct.

  if (!rootResult || typeof rootResult !== "object") return;

  const diag = (rootResult.diagnostics && typeof rootResult.diagnostics === "object")
    ? rootResult.diagnostics
    : null;
  if (!diag) return;

  const inner = (rootResult.result && typeof rootResult.result === "object") ? rootResult.result : null;

  const isAnomalyBlock = (b) => {
    const fam = String(b && b.family || "").toLowerCase();
    const bid = String(b && (b.blockId || b.block || "") || "").toLowerCase();
    return fam.includes("anomal") || bid.includes("anomal") || bid.includes("outlier") || bid.includes("spike") || bid.includes("drop");
  };

  const isTimeSeriesBlock = (b) => {
    const fam = String(b && b.family || "").toLowerCase();
    const bid = String(b && (b.blockId || b.block || "") || "").toLowerCase();
    return fam.includes("timeseries") || bid.includes("early_warning") || bid.includes("structural") || bid.includes("regime");
  };

  const _isNonEmptyEvidence = (v) => {
    if (v == null) return false;
    if (Array.isArray(v)) return v.length > 0;
    if (typeof v === "string") return v.trim().length > 0;
    if (typeof v === "object") return Object.keys(v).length > 0;
    return true;
  };

  const _getPath = (obj, path) => {
    try {
      return String(path || "")
        .split(".")
        .reduce((acc, k) => (acc && acc[k] != null ? acc[k] : undefined), obj);
    } catch (_) {
      return undefined;
    }
  };

  const _normalizeEvidencePath = (p) => {
    const s = String(p || "").trim();
    if (!s) return "";
    if (s.startsWith("results.")) return s.slice("results.".length);
    if (s.startsWith("result.")) return s.slice("result.".length);
    return s;
  };

  const collectCandidates = (obj, prefix) => {
    const c = [];
    if (!obj || typeof obj !== "object") return c;

    const tables = obj.tables && typeof obj.tables === "object" ? obj.tables : null;
    if (tables) {
      if (Array.isArray(tables)) {
        // legacy tables array form
        for (let i = 0; i < tables.length; i++) {
          const t = tables[i];
          if (!t || typeof t !== "object") continue;
          const rows = Array.isArray(t.rows) ? t.rows : null;
          if (rows && rows.length) c.push(prefix + "tables." + i);
        }
      } else {
        for (const [k, v] of Object.entries(tables)) {
          if (Array.isArray(v) && v.length) c.push(prefix + "tables." + k);
          else if (v && typeof v === "object") {
            const rows = Array.isArray(v.rows) ? v.rows : null;
            if (rows && rows.length) c.push(prefix + "tables." + k);
          }
        }
      }
    }

    const extras = obj.extras && typeof obj.extras === "object" ? obj.extras : null;
    if (extras) {
      for (const [k, v] of Object.entries(extras)) {
        if (Array.isArray(v) && v.length) c.push(prefix + "extras." + k);
        else if (v && typeof v === "object" && Object.keys(v).length) c.push(prefix + "extras." + k);
      }
    }

    return c;
  };

  const wrapperCandidates = collectCandidates(rootResult, "");
  const innerCandidates = collectCandidates(inner, "result.");

  const bs = Array.isArray(diag.blockStatus) ? diag.blockStatus : [];

  for (const b of bs) {
    if (!b || typeof b !== "object") continue;

    const status = String(b.status || "").toLowerCase();
    const rawPaths0 = Array.isArray(b.evidencePaths) ? b.evidencePaths : [];

    // If a block claims "ok" but provided no evidencePaths, try to backfill from real outputs.
    // We DO NOT do this for anomaly/time-series style blocks, because their emptiness can be legitimate.
    let rawPaths = rawPaths0;
    if (status === "ok" && rawPaths.length === 0 && !isAnomalyBlock(b) && !isTimeSeriesBlock(b)) {
      const fill = (innerCandidates.length ? innerCandidates : wrapperCandidates);
      rawPaths = fill.slice(0, 2);
    }

    const goodPaths = [];
    const seen = new Set();

    for (const p0 of rawPaths) {
      const pNorm = _normalizeEvidencePath(p0);
      if (!pNorm) continue;

      // 1) Try wrapper root
      const v1 = _getPath(rootResult, pNorm);
      if (_isNonEmptyEvidence(v1)) {
        const canon = pNorm;
        if (!seen.has(canon)) { goodPaths.push(canon); seen.add(canon); }
        continue;
      }

      // 2) Try inner root (canonicalize to wrapper-space with "result." prefix)
      if (inner) {
        const v2 = _getPath(inner, pNorm);
        if (_isNonEmptyEvidence(v2)) {
          const canon = "result." + pNorm;
          if (!seen.has(canon)) { goodPaths.push(canon); seen.add(canon); }
          continue;
        }
      }
    }

    b.evidencePaths = goodPaths;

    if (status === "ok" && goodPaths.length === 0) {
      // status=ok but nothing actually exists at the referenced paths
      if (isAnomalyBlock(b)) {
        b.status = "skipped";
        b.reason = b.reason || "No anomalies detected; evidence arrays are empty by design.";
      } else if (isTimeSeriesBlock(b)) {
        b.status = "skipped";
        b.reason = b.reason || "No qualifying time-series signals produced; output is empty.";
      } else {
        b.status = "downgraded";
        b.reason = b.reason || "status=ok but all evidencePaths are empty";
      }
    }
  }

  diag.blockStatus = bs;
} // END enforceOkEvidence




// ===============================
// P4: DIAGNOSTICS blockStatus TRUTH
// ===============================

function updateRiskBlockStatus(containerObj) {
  if (!containerObj || typeof containerObj !== "object") return;

  containerObj.extras ||= {};
  containerObj.diagnostics ||= {};
  containerObj.diagnostics.blockStatus ||= [];

  const bs = containerObj.diagnostics.blockStatus;
  const rp = (containerObj.extras.risk_probability && typeof containerObj.extras.risk_probability === "object")
      ? containerObj.extras.risk_probability
      : null;

  if (!rp) return;

  const finite = (v) => (typeof v === "number" && Number.isFinite(v)) ? v : null;
  const hasMetric = 
    finite(rp.historicalFrequency) != null ||
    finite(rp.zScoreToThreshold) != null ||
    finite(rp.normalApproxProbability) != null;

  const reasons = Array.isArray(rp.reasons)
    ? rp.reasons.filter(r => typeof r === "string" && r.trim())
    : [];
  
  const reason = (!hasMetric) ? (reasons[0] || "No computable risk metrics from baseline vectors.") : null;
  const status = hasMetric ? "ok" : "downgraded";

  // Remove old entries and push new
  for (let i = bs.length - 1; i >= 0; i--) {
    const b = bs[i] && bs[i].block;
    if (b === "risk_probability" || b === "risk_analysis") bs.splice(i, 1);
  }
  bs.push({ block: "risk_probability", status, reason, details: Array.from(new Set(reasons)) });
}

;globalThis.updateRiskBlockStatus = updateRiskBlockStatus;

  // --- EvidencePaths + Truncations Contract Enforcer (universal) ---
  function _isNonEmptyEvidence(v) {
    if (v == null) return false;
    if (Array.isArray(v)) return v.length > 0;
    if (typeof v === "string") return v.trim().length > 0;
    if (typeof v === "object") return Object.keys(v).length > 0;
    return true; // numbers/booleans count as evidence
  }

  function _getPath(obj, path) {
    try {
      return String(path || "")
        .split(".")
        .reduce((acc, k) => (acc && acc[k] != null ? acc[k] : undefined), obj);
    } catch (e) {
      return undefined;
    }
  }

  function _normalizeEvidencePath(p) {
    // tolerate common wrong prefixes from generators
    const s = String(p || "").trim();
    if (!s) return "";
    if (s.startsWith("results.")) return s.slice("results.".length);
    if (s.startsWith("result.")) return s.slice("result.".length);
    return s;
  }

  function enforceDiagnosticsContract(root) {
    const diag = (root && root.diagnostics && typeof root.diagnostics === "object") ? root.diagnostics : null;
    if (!diag) return;

    // 1) blockStatus evidencePaths must be non-empty if status=ok
    const bs = Array.isArray(diag.blockStatus) ? diag.blockStatus : [];
    for (const b of bs) {
      if (!b || typeof b !== "object") continue;

      const rawPaths = Array.isArray(b.evidencePaths) ? b.evidencePaths : [];
      const goodPaths = [];

      for (const p0 of rawPaths) {
        const p = _normalizeEvidencePath(p0);
        if (!p) continue;
        const val = _getPath(root, p);
        if (_isNonEmptyEvidence(val)) goodPaths.push(p);
      }

      b.evidencePaths = goodPaths;

      const status = String(b.status || "").toLowerCase();
      if (status === "ok" && goodPaths.length === 0) {
        const fam = String(b.family || "").toLowerCase();
        const bid = String(b.blockId || "").toLowerCase();

        // If it's an â€œokâ€ block but produced no rows/outliers, this is not a failure.
        // Mark as skipped (clean) rather than ok (invalid).
        if (fam.includes("anomal") || bid.includes("anomal") || bid.includes("outlier")) {
          b.status = "skipped";
          b.reason = b.reason || "No anomalies detected; evidence arrays are empty by design.";
        } else if (fam.includes("timeseries") || bid.includes("early_warning")) {
          b.status = "skipped";
          b.reason = b.reason || "No qualifying time-series signals produced; output is empty.";
        } else {
          b.status = "downgraded";
          b.reason = b.reason || "status=ok but all evidencePaths are empty";
        }
      }
    }
    diag.blockStatus = bs;

    // 2) truncations must only exist when actual > cap
    if (Array.isArray(diag.truncations)) {
      diag.truncations = diag.truncations.filter(t => {
        if (!t || typeof t !== "object") return false;
        const cap = Number(t.cap);
        const actual = Number(t.actual);
        if (!Number.isFinite(cap) || !Number.isFinite(actual)) return false;
        return actual > cap;
      });
    }
  }


function safeMap(input, fn) {
  if (!input) return [];
  if (Array.isArray(input)) return input.map(fn);
  if (typeof input === "object") return Object.entries(input).map(([k, v]) => fn({ key: k, value: v }));
  return [];
}

function safeSort(arr, cmp) {
  if (!Array.isArray(arr)) return [];
  const copy = arr.slice();
  if (typeof cmp === "function") return copy.sort(cmp);
  return copy.sort();
}

// ============================================================================
// FINAL SAFEGUARDS: DEFINITIONS & EXPORTS
// ============================================================================

// 1. SAFEGUARD DEFINITIONS
// We define these ONLY if they are missing to prevent "is not defined" crashes.

if (typeof safeGet !== 'function') {
  function safeGet(obj, path, fallback) {
    try {
      if (!path) return undefined;
      const keys = Array.isArray(path) ? path : path.split('.');
      let result = obj;
      for (const key of keys) {
        if (result == null) return fallback;
        result = result[key];
      }
      return result === undefined ? fallback : result;
    } catch (_) { return fallback; }
  }
}

if (typeof safeKeyFn !== 'function') {
  function safeKeyFn(item, pathOrFn) {
    try {
      if (typeof pathOrFn === 'function') return pathOrFn(item);
      if (typeof pathOrFn === 'string') return safeGet(item, pathOrFn);
      return null;
    } catch (err) { return null; }
  }
}

if (typeof safeFilter !== 'function') {
  function safeFilter(arr, predicate) {
    if (!Array.isArray(arr)) return [];
    try {
      return arr.filter(item => {
        try { return predicate(item); } catch (e) { return false; }
      });
    } catch (e) { return []; }
  }
}

// 2. THE "DOUBLE-LOCK" INJECTION
// We gather all tools and inject them into BOTH Global Scope and Data Scope.

const helpers = {
  // Use existing ones if present, otherwise use our fail-safes
  safeMap: typeof safeMap !== 'undefined' ? safeMap : (arr, fn) => (Array.isArray(arr) ? arr.map(fn) : []),
  safeSort: typeof safeSort !== 'undefined' ? safeSort : (arr) => (Array.isArray(arr) ? arr.sort() : []),
  safeKeyFn: safeKeyFn,
  safeFilter: safeFilter,
  safeGet: safeGet,
  _: (typeof _ !== 'undefined') ? _ : undefined,
  patterns: (typeof patterns !== 'undefined') ? patterns : undefined,
  dateUtils: (typeof dateUtils !== 'undefined') ? dateUtils : undefined,
};

// Inject into Global Scope (Standard)
Object.entries(helpers).forEach(([k, v]) => { 
  if(v) globalThis[k] = v; 
});

// Inject into Data Scope (Sandboxed Environment Fix)
// This forces the Executor to see 'safeKeyFn' inside its variable context.
/**
 * Expose helper modules to the executor/runtime WITHOUT leaking them as MindStudio outputs.
 * MindStudio often auto-materializes returned/assigned vars; exporting helpers as enumerable
 * properties creates unwanted {{patterns}}/{{dateUtils}} outputs and can introduce circular JSON.
 *
 * We define them as NON-ENUMERABLE so generated code can access them (ai.vars._ / ai.vars.patterns / ai.vars.dateUtils),
 * but the workflow won't try to persist them as separate variables.
 */
for (const [k, v] of Object.entries(helpers)) {
  try {
    Object.defineProperty(ai.vars, k, {
      value: v,
      writable: true,
      configurable: true,
      enumerable: false
    });
  } catch (_) {
    // fallback if defineProperty is blocked for some reason
    try { ai.vars[k] = v; } catch (_) {}
  }
}


function toPlainJSON(value) {
  const seen = new WeakSet();

  const walk = (v) => {
    if (v == null) return v;

    const t = typeof v;
    if (t === "string" || t === "number" || t === "boolean") return v;
    if (t === "bigint") return Number(v);
    if (t === "function" || t === "symbol") return undefined;

    // Errors: preserve useful info, drop circular guts
    if (v instanceof Error) {
      return { name: v.name, message: v.message, stack: String(v.stack || "") };
    }

    if (t !== "object") return String(v);

    if (seen.has(v)) return "[[Circular]]";
    seen.add(v);

    if (Array.isArray(v)) {
      const arr = [];
      for (const item of v) {
        const w = walk(item);
        if (w !== undefined) arr.push(w);
      }
      return arr;
    }

    const out = {};
    for (const k of Object.keys(v)) {
      const w = walk(v[k]);
      if (w !== undefined) out[k] = w;
    }
    return out;
  };

  return walk(value);
}


// ============================================================================
// UNIVERSAL POST-REPAIR (Schema-agnostic, Query-safe)
// - Fixes "wide month columns" cases where generated outputs are present but numeric cells are all null.
// - Mirrors inner diagnostics to wrapper diagnostics (MindStudio reads wrapper.diagnostics).
// ============================================================================

function mirrorInnerDiagnostics(wrapper) {
  if (!wrapper || typeof wrapper !== "object") return;

  // ---------- helpers (universal) ----------
  const clamp01 = (x) => (x < 0 ? 0 : x > 1 ? 1 : x);

  // If nValidPairs can exceed nTotal (wide-month data), estimate a multiplier so coverage stays 0..1.
  const coverage01FromPairs = (nValidPairs, nTotal) => {
    const nt = Number(nTotal);
    const nv = Number(nValidPairs);
    if (!Number.isFinite(nt) || nt <= 0) return 0;
    if (!Number.isFinite(nv) || nv < 0) return 0;
    const mult = nv > nt ? Math.max(1, Math.ceil(nv / nt)) : 1;
    return clamp01(nv / (nt * mult));
  };

  // Keep truncations only if they truly represent truncation.
  // Supports both schemas:
  // - classic: {cap, actual, where/note}
  // - executor: {path, originalSize, kept, reason}
  const normalizeTruncations = (arr) => {
    if (!Array.isArray(arr)) return [];
    const out = [];
    for (const t of arr) {
      if (!t || typeof t !== "object") continue;

      const cap = Number(t.cap);
      const actual = Number(t.actual);
      if (Number.isFinite(cap) && Number.isFinite(actual)) {
        if (actual > cap) out.push(t);
        continue;
      }

      const originalSize = Number(t.originalSize);
      const kept = Number(t.kept);
      if (Number.isFinite(originalSize) && Number.isFinite(kept)) {
        if (originalSize > kept) out.push(t);
        continue;
      }

      // Unknown schema: keep (better than deleting real truncation notes)
      out.push(t);
    }
    return out;
  };

  const ensureDriversBlockStatus = (diag, extras) => {
  if (!diag || typeof diag !== "object") return;

  const drivers = extras && Array.isArray(extras.drivers) ? extras.drivers : [];
  if (!drivers.length) return;

  diag.blockStatus = Array.isArray(diag.blockStatus) ? diag.blockStatus : [];

  // Compute the strongest evidence_n we have (wide-month mode can be thousands)
  let maxEvidenceN = 0;
  for (const d of drivers) {
    const ev = Number(d && d.evidence_n);
    if (Number.isFinite(ev) && ev > maxEvidenceN) maxEvidenceN = ev;
  }
  if (!maxEvidenceN) maxEvidenceN = drivers.length;

  const nReturned = drivers.length;

  // Upsert: update if it exists, otherwise add
  let b = diag.blockStatus.find(
    (x) => x && typeof x === "object" && (x.blockId === "drivers" || x.family === "Correlation Drivers")
  );

  if (!b) {
    b = { blockId: "drivers" };
    diag.blockStatus.push(b);
  }

  b.blockId = "drivers";
  b.family = "Correlation Drivers";
  b.status = "ok";

  // IMPORTANT: make n stable and meaningful across runs
  b.n = maxEvidenceN;          // consistent with evidence scale (e.g. 5302)
  b.nReturned = nReturned;     // how many drivers you output (e.g. 3)
  b.reason = null;
  b.evidencePaths = ["extras.drivers"];
};


  const normalizeCorrelationBlocks = (diag) => {
    if (!diag || typeof diag !== "object") return;
    if (!Array.isArray(diag.correlationBlocks)) return;

    const fallbackTotal =
      Number.isFinite(Number(diag.rowCount)) && Number(diag.rowCount) > 0
        ? Number(diag.rowCount)
        : null;

    for (const b of diag.correlationBlocks) {
      if (!b || typeof b !== "object") continue;

      const nTotal =
        Number.isFinite(Number(b.nTotal)) && Number(b.nTotal) > 0
          ? Number(b.nTotal)
          : fallbackTotal;

      const nValid =
        Number.isFinite(Number(b.nValidPairs)) && Number(b.nValidPairs) >= 0
          ? Number(b.nValidPairs)
          : Number.isFinite(Number(b.n)) && Number(b.n) >= 0
            ? Number(b.n)
            : null;

      if (nTotal != null) b.nTotal = nTotal;
      if (nValid != null) b.nValidPairs = nValid;

      // Fix: keep coverage in [0,1] even for wide-month pairs
      if (nTotal != null && nValid != null) {
        b.coverage = coverage01FromPairs(nValid, nTotal);
      } else if (!Number.isFinite(Number(b.coverage))) {
        b.coverage = 0;
      } else {
        b.coverage = clamp01(Number(b.coverage));
      }
    }
  };

  const normalizeDiagnosticsObject = (diag, extras) => {
    if (!diag || typeof diag !== "object") return;
    diag.truncations = normalizeTruncations(diag.truncations);
    normalizeCorrelationBlocks(diag);
    ensureDriversBlockStatus(diag, extras);
  };

  // Safe clone to prevent shared references / [[Circular]]
  const cloneSafe = (x) => {
    try {
      return toPlainJSON(x); // your executor already has this
    } catch (_) {
      try {
        return JSON.parse(JSON.stringify(x));
      } catch (__){
        return x;
      }
    }
  };

  // ---------- normalize inner first ----------
  if (wrapper.result && typeof wrapper.result === "object") {
    const innerExtras =
      wrapper.result.extras && typeof wrapper.result.extras === "object"
        ? wrapper.result.extras
        : {};
    normalizeDiagnosticsObject(wrapper.result.diagnostics, innerExtras);
  }

  // ---------- mirror into wrapper.diagnostics (CLONED) ----------
  const inner = wrapper.result && typeof wrapper.result === "object"
    ? wrapper.result.diagnostics
    : null;

  if (!inner || typeof inner !== "object") return;

  const w = (wrapper.diagnostics =
    wrapper.diagnostics && typeof wrapper.diagnostics === "object"
      ? wrapper.diagnostics
      : {});

  // Prefer inner values when wrapper is missing/empty (but clone!)
  const copyIfEmpty = (key) => {
    const v = inner[key];
    if (v == null) return;

    if (Array.isArray(v)) {
      if (!Array.isArray(w[key]) || w[key].length === 0) w[key] = cloneSafe(v);
      return;
    }

    if (typeof v === "object") {
      if (!w[key] || typeof w[key] !== "object" || Object.keys(w[key]).length === 0) {
        w[key] = cloneSafe(v);
      }
      return;
    }

    if (w[key] == null) w[key] = v;
  };

  copyIfEmpty("rowCount");
  copyIfEmpty("entityCount");
  copyIfEmpty("chosenEntityField");
  copyIfEmpty("numericCoverageByField");
  copyIfEmpty("correlationBlocks");
  copyIfEmpty("truncations");
  copyIfEmpty("blockStatus");
  copyIfEmpty("notes");

  if (w.contractEnforced == null && inner.contractEnforced != null) {
    w.contractEnforced = inner.contractEnforced;
  }

  // Normalize wrapper diagnostics too (since we just copied into it)
  const innerExtras =
    wrapper.result && wrapper.result.extras && typeof wrapper.result.extras === "object"
      ? wrapper.result.extras
      : {};
  normalizeDiagnosticsObject(w, innerExtras);
}


function repairWideTimeSeriesOutputs(wrapper, rawData) {
  try {
    const res = wrapper && wrapper.result;
    if (!res || !res.tables || typeof res.tables !== "object") return;

    // Only run when time-series is missing/empty (we don't overwrite good outputs)
    const existing = res.tables.entity_period_trend;
    const isEmptyTrend = !Array.isArray(existing) || existing.length === 0;

    // If the generator produced a non-empty trend, do nothing.
    if (!isEmptyTrend) return;

    const rows = Array.isArray(rawData)
      ? rawData
      : (rawData && typeof rawData === "object" ? Object.values(rawData).flat() : []);
    if (!rows.length) return;

    const entityKey =
      (res.diagnostics && typeof res.diagnostics === "object" && typeof res.diagnostics.chosenEntityField === "string" && res.diagnostics.chosenEntityField)
        ? res.diagnostics.chosenEntityField
        : null;
    if (!entityKey) return;

    // --- helpers ---
    const toNum = (v) => {
      if (v == null) return null;
      if (typeof v === "number") return Number.isFinite(v) ? v : null;
      if (typeof v === "string") {
        const s = v.trim();
        if (!s) return null;
        const n = Number(s.replace(/,/g, ""));
        return Number.isFinite(n) ? n : null;
      }
      return null;
    };

    const canon = (s) => String(s || "").toLowerCase().replace(/\s+/g, " ").trim();

    const slug = (s) => {
      const x = String(s || "").toLowerCase().trim().replace(/[^a-z0-9]+/g, "_").replace(/^_+|_+$/g, "");
      return x ? x : "metric";
    };

    const MONTHS = [
      { re: /\bjan(?:uary)?\b/i, m: 1, lab: "Jan" },
      { re: /\bfeb(?:ruary)?\b/i, m: 2, lab: "Feb" },
      { re: /\bmar(?:ch)?\b/i, m: 3, lab: "Mar" },
      { re: /\bapr(?:il)?\b/i, m: 4, lab: "Apr" },
      { re: /\bmay\b/i, m: 5, lab: "May" },
      { re: /\bjun(?:e)?\b/i, m: 6, lab: "Jun" },
      { re: /\bjul(?:y)?\b/i, m: 7, lab: "Jul" },
      { re: /\baug(?:ust)?\b/i, m: 8, lab: "Aug" },
      { re: /\bsep(?:t(?:ember)?)?\b/i, m: 9, lab: "Sep" },
      { re: /\boct(?:ober)?\b/i, m: 10, lab: "Oct" },
      { re: /\bnov(?:ember)?\b/i, m: 11, lab: "Nov" },
      { re: /\bdec(?:ember)?\b/i, m: 12, lab: "Dec" }
    ];

    const parsePeriodMetric = (key) => {
      const k0 = String(key || "");
      const k = canon(k0);

      // Year detection (supports 19xx/20xx)
      const yMatch = k.match(/\b(19\d{2}|20\d{2})\b/);
      const year = yMatch ? Number(yMatch[1]) : null;

      // Quarter pattern: Q1..Q4
      const qMatch = k.match(/\bq([1-4])\b/);
      if (qMatch) {
        const q = Number(qMatch[1]);
        const period = year ? `${year}-Q${q}` : `Q${q}`;
        const sort = (year ? year * 10 : 0) + q;
        let metric = k0;
        // Prefer text after last dash if present
        if (k0.includes(" - ")) metric = k0.split(" - ").slice(-1)[0];
        metric = metric.replace(/\(.*?\)/g, "").trim();
        metric = metric.replace(/^[\-\:\s]+|[\-\:\s]+$/g, "");
        if (!metric) metric = "value";
        return { period, sort, metric };
      }

      // YYYY-MM or YYYY/MM
      const ym = k.match(/\b(19\d{2}|20\d{2})[-\/](\d{1,2})\b/);
      if (ym) {
        const yy = Number(ym[1]);
        const mm = Number(ym[2]);
        if (mm >= 1 && mm <= 12) {
          const period = `${yy}-${String(mm).padStart(2, "0")}`;
          const sort = yy * 100 + mm;
          let metric = k0.includes(" - ") ? k0.split(" - ").slice(-1)[0] : k0;
          metric = metric.replace(/\(.*?\)/g, "").trim();
          metric = metric.replace(/^[\-\:\s]+|[\-\:\s]+$/g, "");
          if (!metric) metric = "value";
          return { period, sort, metric };
        }
      }

      // Month name pattern
      let mon = null;
      for (const M of MONTHS) {
        if (M.re.test(k)) { mon = M; break; }
      }
      if (mon) {
        const mm = mon.m;
        const period = year ? `${year}-${String(mm).padStart(2, "0")}` : mon.lab;
        const sort = (year ? year * 100 : 0) + mm;

        let metric = k0;
        // Prefer text after last dash if present (works for "January (2025) - Gross Profit")
        if (k0.includes(" - ")) metric = k0.split(" - ").slice(-1)[0];
        else {
          // fallback: remove obvious month/year fragments
          metric = k0.replace(/\(.*?\)/g, " ");
          metric = metric.replace(new RegExp(mon.lab, "ig"), " ");
          metric = metric.replace(/\b(19\d{2}|20\d{2})\b/g, " ");
        }

        metric = metric.replace(/\(.*?\)/g, "").replace(/\s+/g, " ").trim();
        metric = metric.replace(/^[\-\:\s]+|[\-\:\s]+$/g, "");
        if (!metric) metric = "value";
        return { period, sort, metric };
      }

      return null;
    };

    // --- scan columns ---
    const scanN = Math.min(rows.length, 40);
    const keySet = new Set();
    for (let i = 0; i < scanN; i++) {
      const r = rows[i];
      if (r && typeof r === "object") {
        for (const k of Object.keys(r)) keySet.add(k);
      }
    }

    const colMap = [];
    for (const k of keySet) {
      const pm = parsePeriodMetric(k);
      if (!pm) continue;
      colMap.push({ key: k, period: pm.period, sort: pm.sort, metric: pm.metric });
    }
    if (!colMap.length) return;

    // --- choose top metrics to avoid explosion ---
    const metricTotals = new Map(); // metric -> abs sum
    const byEnt = new Map(); // ent -> Map(period -> Map(metric -> sum))

    for (const r of rows) {
      if (!r || typeof r !== "object") continue;
      const entRaw = r[entityKey];
      const ent = (entRaw == null || String(entRaw).trim() === "") ? "-Unknown-" : String(entRaw);

      if (!byEnt.has(ent)) byEnt.set(ent, new Map());
      const entMap = byEnt.get(ent);

      for (let i = 0; i < colMap.length; i++) {
        const c = colMap[i];
        const n = toNum(r[c.key]);
        if (n == null) continue;

        if (!entMap.has(c.period)) entMap.set(c.period, new Map());
        const pMap = entMap.get(c.period);

        pMap.set(c.metric, (pMap.get(c.metric) || 0) + n);

        metricTotals.set(c.metric, (metricTotals.get(c.metric) || 0) + Math.abs(n));
      }
    }

    const metricsRanked = Array.from(metricTotals.entries()).sort((a, b) => b[1] - a[1]).map(x => x[0]);
    const keepMetrics = metricsRanked.slice(0, 6); // universal cap

    // slug map (flat columns, no nested objects)
    const metricKeyMap = {};
    const used = new Set();
    for (const m of keepMetrics) {
      let s = slug(m);
      let base = s;
      let t = 2;
      while (used.has(s)) { s = base + "_" + (t++); }
      used.add(s);
      metricKeyMap[m] = s;
    }

    // periods sorted
    const periodSortMap = new Map();
    for (const c of colMap) {
      if (!periodSortMap.has(c.period) || periodSortMap.get(c.period) > c.sort) {
        periodSortMap.set(c.period, c.sort);
      }
    }
    const periods = Array.from(periodSortMap.entries()).sort((a, b) => a[1] - b[1]).map(x => x[0]);

    // cap entities (top 50 by primary metric total)
    const primaryMetric = keepMetrics[0] || null;
    const entScores = [];
    for (const [ent, entMap] of byEnt.entries()) {
      let s = 0;
      if (primaryMetric) {
        for (const p of periods) {
          const pMap = entMap.get(p);
          if (!pMap) continue;
          const v = pMap.get(primaryMetric);
          if (typeof v === "number" && Number.isFinite(v)) s += Math.abs(v);
        }
      } else {
        // fallback: total any metric
        for (const pMap of entMap.values()) {
          for (const v of pMap.values()) if (typeof v === "number" && Number.isFinite(v)) s += Math.abs(v);
        }
      }
      entScores.push([ent, s]);
    }
    entScores.sort((a, b) => b[1] - a[1]);
    const keepEnt = new Set(entScores.slice(0, 50).map(x => x[0]));

    const trend = [];
    for (const ent of keepEnt) {
      const entMap = byEnt.get(ent);
      if (!entMap) continue;

      // build series per metric for MoM + roll3
      const seriesByMetric = {};
      for (const m of keepMetrics) seriesByMetric[m] = periods.map(p => {
        const pMap = entMap.get(p);
        const v = pMap ? pMap.get(m) : null;
        return (typeof v === "number" && Number.isFinite(v)) ? v : 0;
      });

      // derived for first two metrics (keeps table sane)
      const m1 = keepMetrics[0] || null;
      const m2 = keepMetrics[1] || null;

      const mom = (arr) => arr.map((v, i) => {
        if (i === 0) return null;
        const prev = arr[i - 1];
        if (!prev) return null;
        return (v - prev) / Math.abs(prev);
      });

      const roll3 = (arr) => arr.map((_, i) => {
        const a = [];
        for (let j = Math.max(0, i - 2); j <= i; j++) a.push(arr[j]);
        return a.length ? (a.reduce((s, x) => s + x, 0) / a.length) : null;
      });

      const m1Mom = m1 ? mom(seriesByMetric[m1]) : [];
      const m1R3  = m1 ? roll3(seriesByMetric[m1]) : [];
      const m2Mom = m2 ? mom(seriesByMetric[m2]) : [];
      const m2R3  = m2 ? roll3(seriesByMetric[m2]) : [];

      for (let i = 0; i < periods.length; i++) {
        const row = { entity: ent, period: periods[i], periodIndex: i };

        // flat metric columns
        for (const m of keepMetrics) {
          row[metricKeyMap[m]] = seriesByMetric[m][i];
        }

        // derived (only for first two metrics)
        if (m1) {
          row[metricKeyMap[m1] + "_mom_growth_pct"] = m1Mom[i];
          row[metricKeyMap[m1] + "_roll3_avg"] = m1R3[i];
        }
        if (m2) {
          row[metricKeyMap[m2] + "_mom_growth_pct"] = m2Mom[i];
          row[metricKeyMap[m2] + "_roll3_avg"] = m2R3[i];
          // ratio if meaningful
          const denom = m1 ? seriesByMetric[m1][i] : null;
          row["ratio_m2_over_m1"] = (m1 && typeof denom === "number" && Number.isFinite(denom) && denom !== 0)
            ? (seriesByMetric[m2][i] / denom)
            : null;
        }

        trend.push(row);
      }
    }

    res.tables.entity_period_trend = trend;

    res.extras = res.extras && typeof res.extras === "object" ? res.extras : {};
    res.extras.metricKeyMap = metricKeyMap;
    res.extras._timeSeriesRepaired = true;

    res.diagnostics = res.diagnostics && typeof res.diagnostics === "object" ? res.diagnostics : {};
    res.diagnostics.blockStatus = Array.isArray(res.diagnostics.blockStatus) ? res.diagnostics.blockStatus : [];
    res.diagnostics.blockStatus.push({
      blockId: "wide_time_series_repair",
      family: "timeSeries",
      status: "ok",
      n: trend.length,
      reason: "Backfilled entity_period_trend via universal wide-column time parsing + entityÃ—period aggregation.",
      evidencePaths: ["tables.entity_period_trend"]
    });

    res.diagnostics.truncations = Array.isArray(res.diagnostics.truncations) ? res.diagnostics.truncations : [];
    if (entScores.length > 50) {
      res.diagnostics.truncations.push({
        where: "tables.entity_period_trend.entities",
        cap: 50,
        actual: entScores.length,
        note: "Universal cap to prevent blowup in wide time-series backfill."
      });
    }
  } catch (_) {}
}


function postProcessEntityTrend(wrapper, opts = {}) {
  const res = wrapper && wrapper.result;
  if (!res || !res.tables) return;

  const trend = res.tables.entity_period_trend;
  if (!Array.isArray(trend) || trend.length === 0) return;

  // ----------------------------
  // Config (safe defaults)
  // ----------------------------
  const MIN_BASE = Number.isFinite(opts.minBase) ? opts.minBase : 500;      // ignore tiny reps for break flags
  const SHOCK_PCT = Number.isFinite(opts.shockPct) ? opts.shockPct : 0.30;  // 30% MoM shock
  const BREAK_PCT = Number.isFinite(opts.breakPct) ? opts.breakPct : 0.35;  // 35% vs rolling baseline

  // Ensure anomalies table exists
  if (!Array.isArray(res.tables.entity_anomalies)) res.tables.entity_anomalies = [];
  const anoms = res.tables.entity_anomalies;

  // SERA v3.0: Universal entity/period/value field detection
  const first = trend[0] || {};
  const detectField = (candidates) => {
    for (const c of candidates) {
      if (c in first) return c;
    }
    return null;
  };
  const entityField = detectField(["id", "entity", "name", "rep", "Entity", "Name", "ID", "Rep", "product", "Product"]) || "id";
  const periodField = detectField(["period", "Period", "month", "Month", "date", "Date", "quarter", "Quarter"]) || "period";
  const valueField = detectField(["value", "Value", "total", "Total", "amount", "Amount", "sales", "Sales", "revenue", "Revenue", "count", "Count"]) || "value";

  // SERA v3.0: Universal period sort key (handles months, quarters, YYYY-MM, ISO dates)
  const _periodSortKey = (period) => {
    if (period == null) return 999999;
    if (typeof period === "number") return period;
    const s = String(period).trim().toLowerCase();
    if (!s) return 999999;
    const MONTHS_MAP = { jan: 1, january: 1, feb: 2, february: 2, mar: 3, march: 3, apr: 4, april: 4,
      may: 5, jun: 6, june: 6, jul: 7, july: 7, aug: 8, august: 8, sep: 9, sept: 9, september: 9,
      oct: 10, october: 10, nov: 11, november: 11, dec: 12, december: 12 };
    if (MONTHS_MAP[s] != null) return MONTHS_MAP[s];
    const qMatch = s.match(/(?:(\d{4})\s*[-/]?\s*)?q([1-4])/);
    if (qMatch) return (qMatch[1] ? Number(qMatch[1]) * 100 : 0) + Number(qMatch[2]) * 3 - 2;
    const ymMatch = s.match(/^(\d{4})[-/](\d{1,2})$/);
    if (ymMatch) return Number(ymMatch[1]) * 100 + Number(ymMatch[2]);
    const ymdMatch = s.match(/^(\d{4})[-/](\d{1,2})[-/](\d{1,2})/);
    if (ymdMatch) return Number(ymdMatch[1]) * 10000 + Number(ymdMatch[2]) * 100 + Number(ymdMatch[3]);
    for (const [mName, mNum] of Object.entries(MONTHS_MAP)) {
      if (s.includes(mName)) { const yy = s.match(/\d{4}/); return (yy ? Number(yy[0]) * 100 : 0) + mNum; }
    }
    const d = new Date(period);
    if (!isNaN(d.getTime())) return d.getTime() / 86400000;
    return 999999;
  };

  const byId = new Map();
  for (const r of trend) {
    if (!r) continue;
    const entVal = r[entityField];
    if (entVal == null) continue;
    const id = String(entVal);
    const sortKey = _periodSortKey(r[periodField]);
    if (!byId.has(id)) byId.set(id, []);
    byId.get(id).push({ row: r, sortKey });
  }

  for (const [id, arr] of byId.entries()) {
    arr.sort((a, b) => (a.sortKey - b.sortKey) || String(a.row[periodField] || "").localeCompare(String(b.row[periodField] || "")));

    // Rolling 3-period average on the value field (null-safe)
    const values = arr.map(x => {
      const v = x.row[valueField];
      return (typeof v === "number" && Number.isFinite(v)) ? v : null;
    });

    for (let i = 0; i < arr.length; i++) {
      const v0 = values[i];
      // collect last 3 non-null including current
      const window = [];
      for (let k = i; k >= 0 && window.length < 3; k--) {
        const vk = values[k];
        if (vk != null) window.push(vk);
      }
      const rolling3 = (window.length === 3)
        ? (window[0] + window[1] + window[2]) / 3
        : null;

      arr[i].row.rolling_3m_avg = rolling3;

      // ----------------------------
      // MoM shock anomaly (uses mom_pct already computed)
      // ----------------------------
      const mom = arr[i].row.mom_pct;
      if (typeof mom === "number" && Number.isFinite(mom) && v0 != null && v0 >= MIN_BASE) {
        if (Math.abs(mom) >= SHOCK_PCT) {
          anoms.push({
            [entityField]: id,
            period: arr[i].row[periodField],
            value: v0,
            mom_pct: mom,
            type: mom >= 0 ? "Spike" : "Drop",
            method: "mom_shock"
          });
        }
      }

      // ----------------------------
      // Structural break vs baseline (prev rolling3 excluding current)
      // ----------------------------
      const prevWin = [];
      for (let k = i - 1; k >= 0 && prevWin.length < 3; k--) {
        const vk = values[k];
        if (vk != null) prevWin.push(vk);
      }
      if (v0 != null && v0 >= MIN_BASE && prevWin.length === 3) {
        const baseline = (prevWin[0] + prevWin[1] + prevWin[2]) / 3;
        if (baseline > 0) {
          const deltaPct = (v0 - baseline) / baseline;
          if (Math.abs(deltaPct) >= BREAK_PCT) {
            anoms.push({
              [entityField]: id,
              period: arr[i].row[periodField],
              value: v0,
              baseline_3m_avg: baseline,
              break_delta_pct: deltaPct,
              type: deltaPct >= 0 ? "RegimeUp" : "RegimeDown",
              method: "structural_break_3m"
            });
          }
        }
      }
    }
  }

  // Deduplicate anomalies (same entity+period+method+type)
  const seen = new Set();
  res.tables.entity_anomalies = anoms.filter(a => {
    if (!a) return false;
    const entKey = a[entityField] || a.id || "";
    const key = `${entKey}::${a.period || ""}::${a.method || ""}::${a.type || ""}`;
    if (seen.has(key)) return false;
    seen.add(key);
    return true;
  });

  // (Optional but recommended) cap anomalies so it can't explode outputs
  const CAP = Number.isFinite(opts.anomalyCap) ? opts.anomalyCap : 300;
  if (res.tables.entity_anomalies.length > CAP) {
    res.tables.entity_anomalies = res.tables.entity_anomalies.slice(0, CAP);
    res.diagnostics = res.diagnostics && typeof res.diagnostics === "object" ? res.diagnostics : {};
    res.diagnostics.truncations = Array.isArray(res.diagnostics.truncations) ? res.diagnostics.truncations : [];
    res.diagnostics.truncations.push({ where: "entity_anomalies", cap: CAP, note: "Post-processor anomaly cap" });
  }

  // Diagnostics breadcrumb
  res.diagnostics = res.diagnostics && typeof res.diagnostics === "object" ? res.diagnostics : {};
  res.diagnostics.notes = Array.isArray(res.diagnostics.notes) ? res.diagnostics.notes : [];
  res.diagnostics.notes.push("Post-processed entity_period_trend: added rolling_3m_avg + mom_shock + structural_break_3m.");
}




// ============================================================================
// MAIN ENTRY POINT
// ============================================================================

;ai.vars.firstOutput = "starting";

return (async () => {
  try {
    if (typeof ai?.vars?.safeKeyFn !== "function") throw new Error("Executor setup error: safeKeyFn missing");

    const result = await Executor.execute(ai.vars, { timeoutMs: Number(ai.vars.timeoutMs ?? 6000) });

    // SERA v3: Diagnostic logging helper — never swallow errors silently
    const _safeStep = (name, fn) => {
      try { fn(); } catch (e) {
        try {
          const diag = (result && result.diagnostics) || (result && (result.diagnostics = {}));
          if (diag) {
            diag.notes = Array.isArray(diag.notes) ? diag.notes : [];
            diag.notes.push(`[SERA-WARN] ${name}: ${String(e && e.message || e).slice(0, 200)}`);
          }
        } catch (_) {}
      }
    };

    // Core diagnostics (always run — these normalize, don't inject)
    _safeStep("sanitizeSummaryStrings", () => sanitizeSummaryStringsDeep(result));
    _safeStep("updateRiskBlockStatus", () => { if (typeof updateRiskBlockStatus === "function") updateRiskBlockStatus(result); });
    _safeStep("enforceDiagnosticsContract", () => enforceDiagnosticsContract(result));
    _safeStep("ensureBlockStatusEvidencePaths", () => {
      if (result && result.result && typeof result.result === "object" && typeof ensureBlockStatusEvidencePaths === "function") {
        ensureBlockStatusEvidencePaths(result.result);
      }
    });
    _safeStep("contractFlag", () => { (result.diagnostics = result.diagnostics || {}).contractEnforced = true; });
    _safeStep("enforceOk", () => { if (typeof enforceOk === "function") enforceOk(result); });

    // SERA v3: REPAIR FUNCTIONS — only run when the IIFE output is clearly broken
    // These no longer inject phantom analytics; they only fix structurally broken output
    _safeStep("repairWideTimeSeries", () => {
      // GATED: Only repair if the IIFE produced tables but entity_period_trend is 
      // explicitly present AND has null/empty series (i.e., the IIFE tried but failed)
      if (result && result.result && result.result.tables) {
        const trend = result.result.tables.entity_period_trend;
        if (Array.isArray(trend) && trend.length > 0) {
          // Check if the trend data is actually broken (all values null)
          const allNull = trend.every(r => r && (r.value == null || r.value === 0));
          if (allNull) {
            repairWideTimeSeriesOutputs(result, ai.vars.rawData);
          }
        }
        // DO NOT repair if entity_period_trend doesn't exist — the IIFE didn't intend it
      }
    });

    // SERA v3: Only add rolling averages if the IIFE already produced entity_period_trend
    _safeStep("postProcessEntityTrend", () => {
      if (result && result.result && result.result.tables && 
          Array.isArray(result.result.tables.entity_period_trend) &&
          result.result.tables.entity_period_trend.length > 0) {
        postProcessEntityTrend(result);
      }
    });

    // Mirror diagnostics (always safe — just copies inner to wrapper)
    _safeStep("mirrorInnerDiagnostics", () => mirrorInnerDiagnostics(result));

    // Safe log
    try { console.log("FINAL OUTPUT:", JSON.stringify(toPlainJSON(result), null, 2)); } catch (_) {}

    ai.vars.firstOutput = toPlainJSON(result);
    return ai.vars.firstOutput;
  } catch (err) {
    const msg = String(err && (err.stack || err.message || err));

    // Never allow the executor to "crash silently" without a blockStatus entry
    const failure = {
      ok: false,
      error: msg,
      extras: {},
      diagnostics: {
        notes: [
          "Executor failed before result could be produced."
        ],
        blockStatus: [
          {
            blockId: "executor_error",
            family: "Executor",
            status: "failed",
            reason: msg,
            evidencePaths: []
          }
        ],
        contractEnforced: true
      }
    };

    try { console.error("FATAL ERROR:", msg); } catch (_) {}
    ai.vars.firstOutput = toPlainJSON(failure);
    return ai.vars.firstOutput;
  }
})();
